{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "p8I7pSgw3uOe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.utils.data\n",
    "import torch.nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPykBUDQ3xiX"
   },
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7X10WoG3x7J",
    "outputId": "55a5f326-c789-4083-969e-cd73449b6d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS_NUMBER = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "RESNET_50_MODEL_NAME = \"ResNet50\"\n",
    "SWIN_V2_MODEL_NAME = \"SwinV2\"\n",
    "GOOGLENET_MODEL_NAME = \"GoogLeNet\"\n",
    "SHUFFLENET_V2_MODEL_NAME = \"ShuffleNet_V2\"\n",
    "model_names = (RESNET_50_MODEL_NAME, SWIN_V2_MODEL_NAME, GOOGLENET_MODEL_NAME, SHUFFLENET_V2_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "yYfrtdnT9Xnl"
   },
   "outputs": [],
   "source": [
    "def get_datasets(model_name):\n",
    "  model_transforms = None\n",
    "  if (model_name == RESNET_50_MODEL_NAME):\n",
    "    model_transforms = models.ResNet50_Weights.DEFAULT.transforms()\n",
    "  elif (model_name == SWIN_V2_MODEL_NAME):\n",
    "    model_transforms = models.Swin_V2_T_Weights.DEFAULT.transforms()\n",
    "  elif (model_name == GOOGLENET_MODEL_NAME):\n",
    "    model_tranforms = models.GoogLeNet_Weights.DEFAULT.transforms()\n",
    "  elif (model_name == SHUFFLENET_V2_MODEL_NAME):\n",
    "    model_tranfroms = models.ShuffleNet_V2_X2_0_Weights.DEFAULT.transforms()\n",
    "  else:\n",
    "    raise ValueError(f\"Model name {model_name} is not supported\")\n",
    "\n",
    "  train_dataset = torchvision.datasets.CIFAR10(\n",
    "      root = PATH, train = True, download = True,\n",
    "      transform = model_transforms\n",
    "  )\n",
    "\n",
    "  test_dataset = torchvision.datasets.CIFAR10(\n",
    "      root = PATH, train = False, download = True,\n",
    "      transform = model_transforms\n",
    "  )\n",
    "\n",
    "  return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def get_dataset_loaders(train_dataset, test_dataset):\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "      train_dataset, batch_size = BATCH_SIZE, shuffle = True\n",
    "      )\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "      test_dataset, batch_size = BATCH_SIZE, shuffle = False\n",
    "      )\n",
    "    return train_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTeyJesnEIAK",
    "outputId": "44c4b255-e583-4217-e401-c3f8b165101d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "resnet_train_dataset, resnet_test_dataset = get_datasets(RESNET_50_MODEL_NAME)\n",
    "resnet_train_data_loader, resnet_test_data_loader = get_dataset_loaders(resnet_train_dataset, resnet_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AO9jQk6iTkA",
    "outputId": "f9cbefae-9304-4eab-a45d-8e46f51743e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "swin_train_dataset, swin_test_dataset = get_datasets(SWIN_V2_MODEL_NAME)\n",
    "swin_train_data_loader, swin_test_data_loader = get_dataset_loaders(swin_train_dataset, swin_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUh8NjwyH0Mk",
    "outputId": "a8a8e2d9-add9-4f60-8d8d-dd5df8464303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "googlenet_train_dataset, googlenet_test_dataset = get_datasets(GOOGLENET_MODEL_NAME)\n",
    "googlenet_train_data_loader, googlenet_test_data_loader = get_dataset_loaders(googlenet_train_dataset, googlenet_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFxo6LrUH0f4",
    "outputId": "ab442f1a-6c5b-476d-fd5f-912a00427426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "shufflenet_train_dataset, shufflenet_test_dataset = get_datasets(SHUFFLENET_V2_MODEL_NAME)\n",
    "shufflenet_train_data_loader, shufflenet_test_data_loader = get_dataset_loaders(shufflenet_train_dataset, shufflenet_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ4alCXBGrM4"
   },
   "source": [
    "# Построение архитектуры сверточной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "_88InEnzHdL2"
   },
   "outputs": [],
   "source": [
    "def create_first_model_config(model, weights, is_swin_model=False):\n",
    "  cnn_model = model(weights)\n",
    "\n",
    "  for params in cnn_model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "  if not is_swin_model:\n",
    "    input_layers = cnn_model.fc.in_features\n",
    "    cnn_model.fc = torch.nn.Linear(input_layers, 10)\n",
    "  else:\n",
    "    input_layers = cnn_model.head.in_features\n",
    "    cnn_model.head = torch.nn.Linear(input_layers, 10)\n",
    "  return cnn_model.to(device)\n",
    "\n",
    "\n",
    "def create_second_model_config(model, weights, is_swin_model=False):\n",
    "  cnn_model = model(weights)\n",
    "\n",
    "  for params in cnn_model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "  if not is_swin_model:\n",
    "    input_layers = cnn_model.fc.in_features\n",
    "    cnn_model.fc = torch.nn.Sequential(\n",
    "      torch.nn.Linear(input_layers, input_layers//2),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Linear(input_layers//2, 10),\n",
    "      )\n",
    "  else:\n",
    "    input_layers = cnn_model.head.in_features\n",
    "    cnn_model.head = torch.nn.Sequential(\n",
    "      torch.nn.Linear(input_layers, input_layers//2),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Linear(input_layers//2, 10),\n",
    "      )\n",
    "  return cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "I4UyTzPREVaI"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, model_name, input_size = (3,32,32)):\n",
    "  print(f\"Model: {model_name}\")\n",
    "  print(model)\n",
    "  print(\"Summary:\")\n",
    "  summary(model, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLAqeKcpJzWE"
   },
   "source": [
    "# Обучение и тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "LSk-pcCIJxq3"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader, device):\n",
    "    tp = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            labels = labels.to(device)\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n += labels.size(0)\n",
    "            tp += (predicted == labels).sum()\n",
    "    return tp / n\n",
    "\n",
    "def get_loss(model, data_loader, device):\n",
    "    loss = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            labels = labels.to(device)\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            loss += loss_function(outputs, labels)\n",
    "            n += labels.size(0)\n",
    "    return loss / n\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "  _, predicted = torch.max(outputs.data, 1)\n",
    "  return torch.tensor(torch.sum(predicted == labels).item() / len(predicted))\n",
    "\n",
    "def epoch_acc(accuracies):\n",
    "  return torch.stack(accuracies).mean()\n",
    "\n",
    "def epoch_loss(losses):\n",
    "  return torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "J-tWJpjlJ227"
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, epochs, loss_function, optimizer, device):\n",
    "  print (\"Train started\")\n",
    "  start_time = time.time()\n",
    "  for epoch in range(epochs):\n",
    "    start_epoch = time.time()\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        acc = accuracy(outputs, labels)\n",
    "\n",
    "        losses.append(loss)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_time_epoch = time.time() - start_epoch\n",
    "    print(f\"Epoch[{epoch + 1}/{EPOCHS_NUMBER}]: Loss = {epoch_loss(losses):.4f}, Train accuracy = {epoch_acc(accuracies):.4f}, Time epoch = {total_time_epoch:.2f} sec.\")\n",
    "\n",
    "  total_time = time.time() - start_time\n",
    "  print(\"Train ended\")\n",
    "  print(f\"Total train time: {total_time:.2f} sec.\")\n",
    "\n",
    "def test(model, data_loader, device):\n",
    "    print(\"Validation model on test data\")\n",
    "    test_loss = get_loss(model, data_loader, device)\n",
    "    test_accuracy = get_accuracy(model, data_loader, device)\n",
    "    print(f\"Test Loss = {test_loss:.4f}, Test accuracy = {test_accuracy:.4f}\")\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "0RF7HYIbKzck"
   },
   "outputs": [],
   "source": [
    "def run_testing_model_with_config(model, train_dataset, test_dataset, is_swin_model=False):\n",
    "  train_data_loader, test_data_loader = get_dataset_loaders(train_dataset, test_dataset)\n",
    "  model.to(device)\n",
    "  if not is_swin_model:\n",
    "      optimizer = torch.optim.Adam(model.fc.parameters(), lr = LEARNING_RATE)\n",
    "  else:\n",
    "      optimizer = torch.optim.Adam(model.head.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "  train(model, train_data_loader, EPOCHS_NUMBER, loss_function, optimizer, device)\n",
    "  return test(model, test_data_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_G9QqnmQMfI"
   },
   "source": [
    "# Представление результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "el6_PgEXS__N"
   },
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQmTFH5SQSO-"
   },
   "source": [
    "### 1) ResNet50 first config (one transformed layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5yKzMgOQLXC",
    "outputId": "45c6fea9-258e-4f2b-e0ed-824a0672aaeb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resnet_first_config_model = create_first_model_config(models.resnet50, models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9tbTiy8QzdF",
    "outputId": "8901f792-3180-47fd-ae55-8874c1461ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet50: one transformed layer\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,528,522\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.86\n",
      "Params size (MB): 89.75\n",
      "Estimated Total Size (MB): 95.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(resnet_first_config_model, f\"{RESNET_50_MODEL_NAME}: one transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAFV-_BkRGwS",
    "outputId": "d4826082-9887-4640-d9b9-cc8da147c1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started\n",
      "Epoch[1/4]: Loss = 1.0476, Train accuracy = 0.6944, Time epoch = 285.95 sec.\n",
      "Epoch[2/4]: Loss = 0.6880, Train accuracy = 0.7814, Time epoch = 285.61 sec.\n",
      "Epoch[3/4]: Loss = 0.6117, Train accuracy = 0.8006, Time epoch = 285.70 sec.\n",
      "Epoch[4/4]: Loss = 0.5692, Train accuracy = 0.8127, Time epoch = 285.87 sec.\n",
      "Train ended\n",
      "Total train time: 1143.13 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0024, Test accuracy = 0.7950\n"
     ]
    }
   ],
   "source": [
    "resnet_first_config_test_acc = run_testing_model_with_config(resnet_first_config_model, resnet_train_dataset, resnet_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uup9ocxRjyr"
   },
   "source": [
    "### ResNet50 second config (two transformed layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "xGXzV8OoRp1z"
   },
   "outputs": [],
   "source": [
    "resnet_second_config_model = create_second_model_config(models.resnet50, models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhvqVgVdR0XD",
    "outputId": "15c72eac-355e-4130-9e85-223a724f72e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet50: two transformed layer\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1024]       2,098,176\n",
      "            ReLU-175                 [-1, 1024]               0\n",
      "          Linear-176                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 25,616,458\n",
      "Trainable params: 2,108,426\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.88\n",
      "Params size (MB): 97.72\n",
      "Estimated Total Size (MB): 103.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(resnet_second_config_model, f\"{RESNET_50_MODEL_NAME}: two transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTeDf35OR11l",
    "outputId": "30bbfa61-c944-4fdf-9af0-787718528e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started\n",
      "Epoch[1/4]: Loss = 0.7422, Train accuracy = 0.7493, Time epoch = 285.26 sec.\n",
      "Epoch[2/4]: Loss = 0.5378, Train accuracy = 0.8154, Time epoch = 285.26 sec.\n",
      "Epoch[3/4]: Loss = 0.4725, Train accuracy = 0.8358, Time epoch = 285.47 sec.\n",
      "Epoch[4/4]: Loss = 0.4276, Train accuracy = 0.8502, Time epoch = 286.51 sec.\n",
      "Train ended\n",
      "Total train time: 1142.50 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0023, Test accuracy = 0.8071\n"
     ]
    }
   ],
   "source": [
    "resnet_second_config_test_acc = run_testing_model_with_config(resnet_second_config_model, resnet_train_dataset, resnet_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0kSsokESJkB"
   },
   "source": [
    "## Swin_V2_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhPIKiy7T0Sz"
   },
   "source": [
    "### Swin_V2_S first config (one transformed layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "PROrS4v8SJ1H"
   },
   "outputs": [],
   "source": [
    "swin_first_config_model = create_first_model_config(models.swin_v2_t, models.Swin_V2_T_Weights.DEFAULT, is_swin_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQTqyps6SKJ6",
    "outputId": "9bae5b49-960f-48ff-94f8-e92908aef966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SwinV2: one transformed layer\n",
      "SwinTransformer(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): Permute()\n",
      "      (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
      "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
      "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
      "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (permute): Permute()\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (head): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 96, 8, 8]           4,704\n",
      "           Permute-2             [-1, 8, 8, 96]               0\n",
      "         LayerNorm-3             [-1, 8, 8, 96]             192\n",
      "            Linear-4          [-1, 15, 15, 512]           1,536\n",
      "              ReLU-5          [-1, 15, 15, 512]               0\n",
      "            Linear-6            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-7             [-1, 8, 8, 96]               0\n",
      "         LayerNorm-8             [-1, 8, 8, 96]             192\n",
      "   StochasticDepth-9             [-1, 8, 8, 96]               0\n",
      "           Linear-10            [-1, 8, 8, 384]          37,248\n",
      "             GELU-11            [-1, 8, 8, 384]               0\n",
      "          Dropout-12            [-1, 8, 8, 384]               0\n",
      "           Linear-13             [-1, 8, 8, 96]          36,960\n",
      "          Dropout-14             [-1, 8, 8, 96]               0\n",
      "        LayerNorm-15             [-1, 8, 8, 96]             192\n",
      "  StochasticDepth-16             [-1, 8, 8, 96]               0\n",
      "SwinTransformerBlockV2-17             [-1, 8, 8, 96]               0\n",
      "           Linear-18          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-19          [-1, 15, 15, 512]               0\n",
      "           Linear-20            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-21             [-1, 8, 8, 96]               0\n",
      "        LayerNorm-22             [-1, 8, 8, 96]             192\n",
      "  StochasticDepth-23             [-1, 8, 8, 96]               0\n",
      "           Linear-24            [-1, 8, 8, 384]          37,248\n",
      "             GELU-25            [-1, 8, 8, 384]               0\n",
      "          Dropout-26            [-1, 8, 8, 384]               0\n",
      "           Linear-27             [-1, 8, 8, 96]          36,960\n",
      "          Dropout-28             [-1, 8, 8, 96]               0\n",
      "        LayerNorm-29             [-1, 8, 8, 96]             192\n",
      "  StochasticDepth-30             [-1, 8, 8, 96]               0\n",
      "SwinTransformerBlockV2-31             [-1, 8, 8, 96]               0\n",
      "           Linear-32            [-1, 4, 4, 192]          73,728\n",
      "        LayerNorm-33            [-1, 4, 4, 192]             384\n",
      "   PatchMergingV2-34            [-1, 4, 4, 192]               0\n",
      "           Linear-35          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-36          [-1, 15, 15, 512]               0\n",
      "           Linear-37            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-38            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-39            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-40            [-1, 4, 4, 192]               0\n",
      "           Linear-41            [-1, 4, 4, 768]         148,224\n",
      "             GELU-42            [-1, 4, 4, 768]               0\n",
      "          Dropout-43            [-1, 4, 4, 768]               0\n",
      "           Linear-44            [-1, 4, 4, 192]         147,648\n",
      "          Dropout-45            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-46            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-47            [-1, 4, 4, 192]               0\n",
      "SwinTransformerBlockV2-48            [-1, 4, 4, 192]               0\n",
      "           Linear-49          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-50          [-1, 15, 15, 512]               0\n",
      "           Linear-51            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-52            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-53            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-54            [-1, 4, 4, 192]               0\n",
      "           Linear-55            [-1, 4, 4, 768]         148,224\n",
      "             GELU-56            [-1, 4, 4, 768]               0\n",
      "          Dropout-57            [-1, 4, 4, 768]               0\n",
      "           Linear-58            [-1, 4, 4, 192]         147,648\n",
      "          Dropout-59            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-60            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-61            [-1, 4, 4, 192]               0\n",
      "SwinTransformerBlockV2-62            [-1, 4, 4, 192]               0\n",
      "           Linear-63            [-1, 2, 2, 384]         294,912\n",
      "        LayerNorm-64            [-1, 2, 2, 384]             768\n",
      "   PatchMergingV2-65            [-1, 2, 2, 384]               0\n",
      "           Linear-66          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-67          [-1, 15, 15, 512]               0\n",
      "           Linear-68           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-69            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-70            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-71            [-1, 2, 2, 384]               0\n",
      "           Linear-72           [-1, 2, 2, 1536]         591,360\n",
      "             GELU-73           [-1, 2, 2, 1536]               0\n",
      "          Dropout-74           [-1, 2, 2, 1536]               0\n",
      "           Linear-75            [-1, 2, 2, 384]         590,208\n",
      "          Dropout-76            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-77            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-78            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-79            [-1, 2, 2, 384]               0\n",
      "           Linear-80          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-81          [-1, 15, 15, 512]               0\n",
      "           Linear-82           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-83            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-84            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-85            [-1, 2, 2, 384]               0\n",
      "           Linear-86           [-1, 2, 2, 1536]         591,360\n",
      "             GELU-87           [-1, 2, 2, 1536]               0\n",
      "          Dropout-88           [-1, 2, 2, 1536]               0\n",
      "           Linear-89            [-1, 2, 2, 384]         590,208\n",
      "          Dropout-90            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-91            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-92            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-93            [-1, 2, 2, 384]               0\n",
      "           Linear-94          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-95          [-1, 15, 15, 512]               0\n",
      "           Linear-96           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-97            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-98            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-99            [-1, 2, 2, 384]               0\n",
      "          Linear-100           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-101           [-1, 2, 2, 1536]               0\n",
      "         Dropout-102           [-1, 2, 2, 1536]               0\n",
      "          Linear-103            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-104            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-105            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-106            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-107            [-1, 2, 2, 384]               0\n",
      "          Linear-108          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-109          [-1, 15, 15, 512]               0\n",
      "          Linear-110           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-111            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-112            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-113            [-1, 2, 2, 384]               0\n",
      "          Linear-114           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-115           [-1, 2, 2, 1536]               0\n",
      "         Dropout-116           [-1, 2, 2, 1536]               0\n",
      "          Linear-117            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-118            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-119            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-120            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-121            [-1, 2, 2, 384]               0\n",
      "          Linear-122          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-123          [-1, 15, 15, 512]               0\n",
      "          Linear-124           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-125            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-126            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-127            [-1, 2, 2, 384]               0\n",
      "          Linear-128           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-129           [-1, 2, 2, 1536]               0\n",
      "         Dropout-130           [-1, 2, 2, 1536]               0\n",
      "          Linear-131            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-132            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-133            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-134            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-135            [-1, 2, 2, 384]               0\n",
      "          Linear-136          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-137          [-1, 15, 15, 512]               0\n",
      "          Linear-138           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-139            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-140            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-141            [-1, 2, 2, 384]               0\n",
      "          Linear-142           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-143           [-1, 2, 2, 1536]               0\n",
      "         Dropout-144           [-1, 2, 2, 1536]               0\n",
      "          Linear-145            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-146            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-147            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-148            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-149            [-1, 2, 2, 384]               0\n",
      "          Linear-150            [-1, 1, 1, 768]       1,179,648\n",
      "       LayerNorm-151            [-1, 1, 1, 768]           1,536\n",
      "  PatchMergingV2-152            [-1, 1, 1, 768]               0\n",
      "          Linear-153          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-154          [-1, 15, 15, 512]               0\n",
      "          Linear-155           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-156            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-157            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-158            [-1, 1, 1, 768]               0\n",
      "          Linear-159           [-1, 1, 1, 3072]       2,362,368\n",
      "            GELU-160           [-1, 1, 1, 3072]               0\n",
      "         Dropout-161           [-1, 1, 1, 3072]               0\n",
      "          Linear-162            [-1, 1, 1, 768]       2,360,064\n",
      "         Dropout-163            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-164            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-165            [-1, 1, 1, 768]               0\n",
      "SwinTransformerBlockV2-166            [-1, 1, 1, 768]               0\n",
      "          Linear-167          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-168          [-1, 15, 15, 512]               0\n",
      "          Linear-169           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-170            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-171            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-172            [-1, 1, 1, 768]               0\n",
      "          Linear-173           [-1, 1, 1, 3072]       2,362,368\n",
      "            GELU-174           [-1, 1, 1, 3072]               0\n",
      "         Dropout-175           [-1, 1, 1, 3072]               0\n",
      "          Linear-176            [-1, 1, 1, 768]       2,360,064\n",
      "         Dropout-177            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-178            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-179            [-1, 1, 1, 768]               0\n",
      "SwinTransformerBlockV2-180            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-181            [-1, 1, 1, 768]           1,536\n",
      "         Permute-182            [-1, 768, 1, 1]               0\n",
      "AdaptiveAvgPool2d-183            [-1, 768, 1, 1]               0\n",
      "         Flatten-184                  [-1, 768]               0\n",
      "          Linear-185                   [-1, 10]           7,690\n",
      "================================================================\n",
      "Total params: 18,946,282\n",
      "Trainable params: 7,690\n",
      "Non-trainable params: 18,938,592\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 26.07\n",
      "Params size (MB): 72.27\n",
      "Estimated Total Size (MB): 98.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(swin_first_config_model, f\"{SWIN_V2_MODEL_NAME}: one transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5kqyi9YSKVb",
    "outputId": "55dbe286-c381-4635-ffc6-bbdb04d4e388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started\n",
      "Epoch[1/4]: Loss = 0.5796, Train accuracy = 0.8414, Time epoch = 484.27 sec.\n",
      "Epoch[2/4]: Loss = 0.3239, Train accuracy = 0.8949, Time epoch = 484.27 sec.\n",
      "Epoch[3/4]: Loss = 0.2933, Train accuracy = 0.9034, Time epoch = 483.84 sec.\n",
      "Epoch[4/4]: Loss = 0.2782, Train accuracy = 0.9076, Time epoch = 486.00 sec.\n",
      "Train ended\n",
      "Total train time: 1938.39 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0012, Test accuracy = 0.9030\n"
     ]
    }
   ],
   "source": [
    "swin_first_config_test_acc = run_testing_model_with_config(swin_first_config_model, swin_train_dataset, swin_test_dataset, is_swin_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14mNdB8sSKrX"
   },
   "source": [
    "### Swin_V2_S second config (two transformed layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "9RHPN-arSLF0"
   },
   "outputs": [],
   "source": [
    "swin_second_config_model = create_second_model_config(models.swin_v2_t, models.Swin_V2_T_Weights.DEFAULT, is_swin_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdNAPm0kSLa-",
    "outputId": "58a46530-ae08-452d-cf22-b618e3a8c43b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SwinV2: two transformed layer\n",
      "SwinTransformer(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): Permute()\n",
      "      (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
      "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): PatchMergingV2(\n",
      "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
      "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerBlockV2(\n",
      "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ShiftedWindowAttentionV2(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (cpb_mlp): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
      "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (permute): Permute()\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=384, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 96, 8, 8]           4,704\n",
      "           Permute-2             [-1, 8, 8, 96]               0\n",
      "         LayerNorm-3             [-1, 8, 8, 96]             192\n",
      "            Linear-4          [-1, 15, 15, 512]           1,536\n",
      "              ReLU-5          [-1, 15, 15, 512]               0\n",
      "            Linear-6            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-7             [-1, 8, 8, 96]               0\n",
      "         LayerNorm-8             [-1, 8, 8, 96]             192\n",
      "   StochasticDepth-9             [-1, 8, 8, 96]               0\n",
      "           Linear-10            [-1, 8, 8, 384]          37,248\n",
      "             GELU-11            [-1, 8, 8, 384]               0\n",
      "          Dropout-12            [-1, 8, 8, 384]               0\n",
      "           Linear-13             [-1, 8, 8, 96]          36,960\n",
      "          Dropout-14             [-1, 8, 8, 96]               0\n",
      "        LayerNorm-15             [-1, 8, 8, 96]             192\n",
      "  StochasticDepth-16             [-1, 8, 8, 96]               0\n",
      "SwinTransformerBlockV2-17             [-1, 8, 8, 96]               0\n",
      "           Linear-18          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-19          [-1, 15, 15, 512]               0\n",
      "           Linear-20            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-21             [-1, 8, 8, 96]               0\n",
      "        LayerNorm-22             [-1, 8, 8, 96]             192\n",
      "  StochasticDepth-23             [-1, 8, 8, 96]               0\n",
      "           Linear-24            [-1, 8, 8, 384]          37,248\n",
      "             GELU-25            [-1, 8, 8, 384]               0\n",
      "          Dropout-26            [-1, 8, 8, 384]               0\n",
      "           Linear-27             [-1, 8, 8, 96]          36,960\n",
      "          Dropout-28             [-1, 8, 8, 96]               0\n",
      "        LayerNorm-29             [-1, 8, 8, 96]             192\n",
      "  StochasticDepth-30             [-1, 8, 8, 96]               0\n",
      "SwinTransformerBlockV2-31             [-1, 8, 8, 96]               0\n",
      "           Linear-32            [-1, 4, 4, 192]          73,728\n",
      "        LayerNorm-33            [-1, 4, 4, 192]             384\n",
      "   PatchMergingV2-34            [-1, 4, 4, 192]               0\n",
      "           Linear-35          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-36          [-1, 15, 15, 512]               0\n",
      "           Linear-37            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-38            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-39            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-40            [-1, 4, 4, 192]               0\n",
      "           Linear-41            [-1, 4, 4, 768]         148,224\n",
      "             GELU-42            [-1, 4, 4, 768]               0\n",
      "          Dropout-43            [-1, 4, 4, 768]               0\n",
      "           Linear-44            [-1, 4, 4, 192]         147,648\n",
      "          Dropout-45            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-46            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-47            [-1, 4, 4, 192]               0\n",
      "SwinTransformerBlockV2-48            [-1, 4, 4, 192]               0\n",
      "           Linear-49          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-50          [-1, 15, 15, 512]               0\n",
      "           Linear-51            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-52            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-53            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-54            [-1, 4, 4, 192]               0\n",
      "           Linear-55            [-1, 4, 4, 768]         148,224\n",
      "             GELU-56            [-1, 4, 4, 768]               0\n",
      "          Dropout-57            [-1, 4, 4, 768]               0\n",
      "           Linear-58            [-1, 4, 4, 192]         147,648\n",
      "          Dropout-59            [-1, 4, 4, 192]               0\n",
      "        LayerNorm-60            [-1, 4, 4, 192]             384\n",
      "  StochasticDepth-61            [-1, 4, 4, 192]               0\n",
      "SwinTransformerBlockV2-62            [-1, 4, 4, 192]               0\n",
      "           Linear-63            [-1, 2, 2, 384]         294,912\n",
      "        LayerNorm-64            [-1, 2, 2, 384]             768\n",
      "   PatchMergingV2-65            [-1, 2, 2, 384]               0\n",
      "           Linear-66          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-67          [-1, 15, 15, 512]               0\n",
      "           Linear-68           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-69            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-70            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-71            [-1, 2, 2, 384]               0\n",
      "           Linear-72           [-1, 2, 2, 1536]         591,360\n",
      "             GELU-73           [-1, 2, 2, 1536]               0\n",
      "          Dropout-74           [-1, 2, 2, 1536]               0\n",
      "           Linear-75            [-1, 2, 2, 384]         590,208\n",
      "          Dropout-76            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-77            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-78            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-79            [-1, 2, 2, 384]               0\n",
      "           Linear-80          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-81          [-1, 15, 15, 512]               0\n",
      "           Linear-82           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-83            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-84            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-85            [-1, 2, 2, 384]               0\n",
      "           Linear-86           [-1, 2, 2, 1536]         591,360\n",
      "             GELU-87           [-1, 2, 2, 1536]               0\n",
      "          Dropout-88           [-1, 2, 2, 1536]               0\n",
      "           Linear-89            [-1, 2, 2, 384]         590,208\n",
      "          Dropout-90            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-91            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-92            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-93            [-1, 2, 2, 384]               0\n",
      "           Linear-94          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-95          [-1, 15, 15, 512]               0\n",
      "           Linear-96           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-97            [-1, 2, 2, 384]               0\n",
      "        LayerNorm-98            [-1, 2, 2, 384]             768\n",
      "  StochasticDepth-99            [-1, 2, 2, 384]               0\n",
      "          Linear-100           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-101           [-1, 2, 2, 1536]               0\n",
      "         Dropout-102           [-1, 2, 2, 1536]               0\n",
      "          Linear-103            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-104            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-105            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-106            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-107            [-1, 2, 2, 384]               0\n",
      "          Linear-108          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-109          [-1, 15, 15, 512]               0\n",
      "          Linear-110           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-111            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-112            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-113            [-1, 2, 2, 384]               0\n",
      "          Linear-114           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-115           [-1, 2, 2, 1536]               0\n",
      "         Dropout-116           [-1, 2, 2, 1536]               0\n",
      "          Linear-117            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-118            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-119            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-120            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-121            [-1, 2, 2, 384]               0\n",
      "          Linear-122          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-123          [-1, 15, 15, 512]               0\n",
      "          Linear-124           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-125            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-126            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-127            [-1, 2, 2, 384]               0\n",
      "          Linear-128           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-129           [-1, 2, 2, 1536]               0\n",
      "         Dropout-130           [-1, 2, 2, 1536]               0\n",
      "          Linear-131            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-132            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-133            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-134            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-135            [-1, 2, 2, 384]               0\n",
      "          Linear-136          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-137          [-1, 15, 15, 512]               0\n",
      "          Linear-138           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-139            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-140            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-141            [-1, 2, 2, 384]               0\n",
      "          Linear-142           [-1, 2, 2, 1536]         591,360\n",
      "            GELU-143           [-1, 2, 2, 1536]               0\n",
      "         Dropout-144           [-1, 2, 2, 1536]               0\n",
      "          Linear-145            [-1, 2, 2, 384]         590,208\n",
      "         Dropout-146            [-1, 2, 2, 384]               0\n",
      "       LayerNorm-147            [-1, 2, 2, 384]             768\n",
      " StochasticDepth-148            [-1, 2, 2, 384]               0\n",
      "SwinTransformerBlockV2-149            [-1, 2, 2, 384]               0\n",
      "          Linear-150            [-1, 1, 1, 768]       1,179,648\n",
      "       LayerNorm-151            [-1, 1, 1, 768]           1,536\n",
      "  PatchMergingV2-152            [-1, 1, 1, 768]               0\n",
      "          Linear-153          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-154          [-1, 15, 15, 512]               0\n",
      "          Linear-155           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-156            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-157            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-158            [-1, 1, 1, 768]               0\n",
      "          Linear-159           [-1, 1, 1, 3072]       2,362,368\n",
      "            GELU-160           [-1, 1, 1, 3072]               0\n",
      "         Dropout-161           [-1, 1, 1, 3072]               0\n",
      "          Linear-162            [-1, 1, 1, 768]       2,360,064\n",
      "         Dropout-163            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-164            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-165            [-1, 1, 1, 768]               0\n",
      "SwinTransformerBlockV2-166            [-1, 1, 1, 768]               0\n",
      "          Linear-167          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-168          [-1, 15, 15, 512]               0\n",
      "          Linear-169           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-170            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-171            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-172            [-1, 1, 1, 768]               0\n",
      "          Linear-173           [-1, 1, 1, 3072]       2,362,368\n",
      "            GELU-174           [-1, 1, 1, 3072]               0\n",
      "         Dropout-175           [-1, 1, 1, 3072]               0\n",
      "          Linear-176            [-1, 1, 1, 768]       2,360,064\n",
      "         Dropout-177            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-178            [-1, 1, 1, 768]           1,536\n",
      " StochasticDepth-179            [-1, 1, 1, 768]               0\n",
      "SwinTransformerBlockV2-180            [-1, 1, 1, 768]               0\n",
      "       LayerNorm-181            [-1, 1, 1, 768]           1,536\n",
      "         Permute-182            [-1, 768, 1, 1]               0\n",
      "AdaptiveAvgPool2d-183            [-1, 768, 1, 1]               0\n",
      "         Flatten-184                  [-1, 768]               0\n",
      "          Linear-185                  [-1, 384]         295,296\n",
      "            ReLU-186                  [-1, 384]               0\n",
      "          Linear-187                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 19,237,738\n",
      "Trainable params: 299,146\n",
      "Non-trainable params: 18,938,592\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 26.08\n",
      "Params size (MB): 73.39\n",
      "Estimated Total Size (MB): 99.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(swin_second_config_model, f\"{SWIN_V2_MODEL_NAME}: two transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hwj8h_CiSLtX",
    "outputId": "a300a31a-b430-4b1a-c624-db2ab1b6ef6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started\n",
      "Epoch[1/4]: Loss = 0.3990, Train accuracy = 0.8759, Time epoch = 487.36 sec.\n",
      "Epoch[2/4]: Loss = 0.2744, Train accuracy = 0.9072, Time epoch = 487.53 sec.\n",
      "Epoch[3/4]: Loss = 0.2534, Train accuracy = 0.9133, Time epoch = 485.73 sec.\n",
      "Epoch[4/4]: Loss = 0.2375, Train accuracy = 0.9187, Time epoch = 484.36 sec.\n",
      "Train ended\n",
      "Total train time: 1944.98 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0011, Test accuracy = 0.9072\n"
     ]
    }
   ],
   "source": [
    "swin_second_config_test_acc = run_testing_model_with_config(swin_second_config_model, swin_train_dataset, swin_test_dataset, is_swin_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxiiKvJpR5gy"
   },
   "source": [
    "## GoogleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vQeu1DSTQvk"
   },
   "source": [
    "### GoogleNet first config (one transformed layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxPVYpDLSBLZ",
    "outputId": "4aaa14bb-a98d-45b5-da3f-58ecf1a2d09d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
      "100%|██████████| 49.7M/49.7M [00:00<00:00, 110MB/s]\n"
     ]
    }
   ],
   "source": [
    "googlenet_first_config_model = create_first_model_config(models.googlenet, models.GoogLeNet_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gm42EiTvSCF8",
    "outputId": "b4f4b308-8d3f-4986-999a-51875b81f255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GoogLeNet: one transformed layer\n",
      "GoogLeNet(\n",
      "  (conv1): BasicConv2d(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): BasicConv2d(\n",
      "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception3a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception3b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception4a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4c): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4d): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4e): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception5a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception5b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (aux1): None\n",
      "  (aux2): None\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "       BasicConv2d-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "       BasicConv2d-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8            [-1, 192, 8, 8]         110,592\n",
      "       BatchNorm2d-9            [-1, 192, 8, 8]             384\n",
      "      BasicConv2d-10            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-11            [-1, 192, 4, 4]               0\n",
      "           Conv2d-12             [-1, 64, 4, 4]          12,288\n",
      "      BatchNorm2d-13             [-1, 64, 4, 4]             128\n",
      "      BasicConv2d-14             [-1, 64, 4, 4]               0\n",
      "           Conv2d-15             [-1, 96, 4, 4]          18,432\n",
      "      BatchNorm2d-16             [-1, 96, 4, 4]             192\n",
      "      BasicConv2d-17             [-1, 96, 4, 4]               0\n",
      "           Conv2d-18            [-1, 128, 4, 4]         110,592\n",
      "      BatchNorm2d-19            [-1, 128, 4, 4]             256\n",
      "      BasicConv2d-20            [-1, 128, 4, 4]               0\n",
      "           Conv2d-21             [-1, 16, 4, 4]           3,072\n",
      "      BatchNorm2d-22             [-1, 16, 4, 4]              32\n",
      "      BasicConv2d-23             [-1, 16, 4, 4]               0\n",
      "           Conv2d-24             [-1, 32, 4, 4]           4,608\n",
      "      BatchNorm2d-25             [-1, 32, 4, 4]              64\n",
      "      BasicConv2d-26             [-1, 32, 4, 4]               0\n",
      "        MaxPool2d-27            [-1, 192, 4, 4]               0\n",
      "           Conv2d-28             [-1, 32, 4, 4]           6,144\n",
      "      BatchNorm2d-29             [-1, 32, 4, 4]              64\n",
      "      BasicConv2d-30             [-1, 32, 4, 4]               0\n",
      "        Inception-31            [-1, 256, 4, 4]               0\n",
      "           Conv2d-32            [-1, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-33            [-1, 128, 4, 4]             256\n",
      "      BasicConv2d-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
      "      BasicConv2d-37            [-1, 128, 4, 4]               0\n",
      "           Conv2d-38            [-1, 192, 4, 4]         221,184\n",
      "      BatchNorm2d-39            [-1, 192, 4, 4]             384\n",
      "      BasicConv2d-40            [-1, 192, 4, 4]               0\n",
      "           Conv2d-41             [-1, 32, 4, 4]           8,192\n",
      "      BatchNorm2d-42             [-1, 32, 4, 4]              64\n",
      "      BasicConv2d-43             [-1, 32, 4, 4]               0\n",
      "           Conv2d-44             [-1, 96, 4, 4]          27,648\n",
      "      BatchNorm2d-45             [-1, 96, 4, 4]             192\n",
      "      BasicConv2d-46             [-1, 96, 4, 4]               0\n",
      "        MaxPool2d-47            [-1, 256, 4, 4]               0\n",
      "           Conv2d-48             [-1, 64, 4, 4]          16,384\n",
      "      BatchNorm2d-49             [-1, 64, 4, 4]             128\n",
      "      BasicConv2d-50             [-1, 64, 4, 4]               0\n",
      "        Inception-51            [-1, 480, 4, 4]               0\n",
      "        MaxPool2d-52            [-1, 480, 2, 2]               0\n",
      "           Conv2d-53            [-1, 192, 2, 2]          92,160\n",
      "      BatchNorm2d-54            [-1, 192, 2, 2]             384\n",
      "      BasicConv2d-55            [-1, 192, 2, 2]               0\n",
      "           Conv2d-56             [-1, 96, 2, 2]          46,080\n",
      "      BatchNorm2d-57             [-1, 96, 2, 2]             192\n",
      "      BasicConv2d-58             [-1, 96, 2, 2]               0\n",
      "           Conv2d-59            [-1, 208, 2, 2]         179,712\n",
      "      BatchNorm2d-60            [-1, 208, 2, 2]             416\n",
      "      BasicConv2d-61            [-1, 208, 2, 2]               0\n",
      "           Conv2d-62             [-1, 16, 2, 2]           7,680\n",
      "      BatchNorm2d-63             [-1, 16, 2, 2]              32\n",
      "      BasicConv2d-64             [-1, 16, 2, 2]               0\n",
      "           Conv2d-65             [-1, 48, 2, 2]           6,912\n",
      "      BatchNorm2d-66             [-1, 48, 2, 2]              96\n",
      "      BasicConv2d-67             [-1, 48, 2, 2]               0\n",
      "        MaxPool2d-68            [-1, 480, 2, 2]               0\n",
      "           Conv2d-69             [-1, 64, 2, 2]          30,720\n",
      "      BatchNorm2d-70             [-1, 64, 2, 2]             128\n",
      "      BasicConv2d-71             [-1, 64, 2, 2]               0\n",
      "        Inception-72            [-1, 512, 2, 2]               0\n",
      "           Conv2d-73            [-1, 160, 2, 2]          81,920\n",
      "      BatchNorm2d-74            [-1, 160, 2, 2]             320\n",
      "      BasicConv2d-75            [-1, 160, 2, 2]               0\n",
      "           Conv2d-76            [-1, 112, 2, 2]          57,344\n",
      "      BatchNorm2d-77            [-1, 112, 2, 2]             224\n",
      "      BasicConv2d-78            [-1, 112, 2, 2]               0\n",
      "           Conv2d-79            [-1, 224, 2, 2]         225,792\n",
      "      BatchNorm2d-80            [-1, 224, 2, 2]             448\n",
      "      BasicConv2d-81            [-1, 224, 2, 2]               0\n",
      "           Conv2d-82             [-1, 24, 2, 2]          12,288\n",
      "      BatchNorm2d-83             [-1, 24, 2, 2]              48\n",
      "      BasicConv2d-84             [-1, 24, 2, 2]               0\n",
      "           Conv2d-85             [-1, 64, 2, 2]          13,824\n",
      "      BatchNorm2d-86             [-1, 64, 2, 2]             128\n",
      "      BasicConv2d-87             [-1, 64, 2, 2]               0\n",
      "        MaxPool2d-88            [-1, 512, 2, 2]               0\n",
      "           Conv2d-89             [-1, 64, 2, 2]          32,768\n",
      "      BatchNorm2d-90             [-1, 64, 2, 2]             128\n",
      "      BasicConv2d-91             [-1, 64, 2, 2]               0\n",
      "        Inception-92            [-1, 512, 2, 2]               0\n",
      "           Conv2d-93            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-94            [-1, 128, 2, 2]             256\n",
      "      BasicConv2d-95            [-1, 128, 2, 2]               0\n",
      "           Conv2d-96            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-97            [-1, 128, 2, 2]             256\n",
      "      BasicConv2d-98            [-1, 128, 2, 2]               0\n",
      "           Conv2d-99            [-1, 256, 2, 2]         294,912\n",
      "     BatchNorm2d-100            [-1, 256, 2, 2]             512\n",
      "     BasicConv2d-101            [-1, 256, 2, 2]               0\n",
      "          Conv2d-102             [-1, 24, 2, 2]          12,288\n",
      "     BatchNorm2d-103             [-1, 24, 2, 2]              48\n",
      "     BasicConv2d-104             [-1, 24, 2, 2]               0\n",
      "          Conv2d-105             [-1, 64, 2, 2]          13,824\n",
      "     BatchNorm2d-106             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-107             [-1, 64, 2, 2]               0\n",
      "       MaxPool2d-108            [-1, 512, 2, 2]               0\n",
      "          Conv2d-109             [-1, 64, 2, 2]          32,768\n",
      "     BatchNorm2d-110             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-111             [-1, 64, 2, 2]               0\n",
      "       Inception-112            [-1, 512, 2, 2]               0\n",
      "          Conv2d-113            [-1, 112, 2, 2]          57,344\n",
      "     BatchNorm2d-114            [-1, 112, 2, 2]             224\n",
      "     BasicConv2d-115            [-1, 112, 2, 2]               0\n",
      "          Conv2d-116            [-1, 144, 2, 2]          73,728\n",
      "     BatchNorm2d-117            [-1, 144, 2, 2]             288\n",
      "     BasicConv2d-118            [-1, 144, 2, 2]               0\n",
      "          Conv2d-119            [-1, 288, 2, 2]         373,248\n",
      "     BatchNorm2d-120            [-1, 288, 2, 2]             576\n",
      "     BasicConv2d-121            [-1, 288, 2, 2]               0\n",
      "          Conv2d-122             [-1, 32, 2, 2]          16,384\n",
      "     BatchNorm2d-123             [-1, 32, 2, 2]              64\n",
      "     BasicConv2d-124             [-1, 32, 2, 2]               0\n",
      "          Conv2d-125             [-1, 64, 2, 2]          18,432\n",
      "     BatchNorm2d-126             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-127             [-1, 64, 2, 2]               0\n",
      "       MaxPool2d-128            [-1, 512, 2, 2]               0\n",
      "          Conv2d-129             [-1, 64, 2, 2]          32,768\n",
      "     BatchNorm2d-130             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-131             [-1, 64, 2, 2]               0\n",
      "       Inception-132            [-1, 528, 2, 2]               0\n",
      "          Conv2d-133            [-1, 256, 2, 2]         135,168\n",
      "     BatchNorm2d-134            [-1, 256, 2, 2]             512\n",
      "     BasicConv2d-135            [-1, 256, 2, 2]               0\n",
      "          Conv2d-136            [-1, 160, 2, 2]          84,480\n",
      "     BatchNorm2d-137            [-1, 160, 2, 2]             320\n",
      "     BasicConv2d-138            [-1, 160, 2, 2]               0\n",
      "          Conv2d-139            [-1, 320, 2, 2]         460,800\n",
      "     BatchNorm2d-140            [-1, 320, 2, 2]             640\n",
      "     BasicConv2d-141            [-1, 320, 2, 2]               0\n",
      "          Conv2d-142             [-1, 32, 2, 2]          16,896\n",
      "     BatchNorm2d-143             [-1, 32, 2, 2]              64\n",
      "     BasicConv2d-144             [-1, 32, 2, 2]               0\n",
      "          Conv2d-145            [-1, 128, 2, 2]          36,864\n",
      "     BatchNorm2d-146            [-1, 128, 2, 2]             256\n",
      "     BasicConv2d-147            [-1, 128, 2, 2]               0\n",
      "       MaxPool2d-148            [-1, 528, 2, 2]               0\n",
      "          Conv2d-149            [-1, 128, 2, 2]          67,584\n",
      "     BatchNorm2d-150            [-1, 128, 2, 2]             256\n",
      "     BasicConv2d-151            [-1, 128, 2, 2]               0\n",
      "       Inception-152            [-1, 832, 2, 2]               0\n",
      "       MaxPool2d-153            [-1, 832, 1, 1]               0\n",
      "          Conv2d-154            [-1, 256, 1, 1]         212,992\n",
      "     BatchNorm2d-155            [-1, 256, 1, 1]             512\n",
      "     BasicConv2d-156            [-1, 256, 1, 1]               0\n",
      "          Conv2d-157            [-1, 160, 1, 1]         133,120\n",
      "     BatchNorm2d-158            [-1, 160, 1, 1]             320\n",
      "     BasicConv2d-159            [-1, 160, 1, 1]               0\n",
      "          Conv2d-160            [-1, 320, 1, 1]         460,800\n",
      "     BatchNorm2d-161            [-1, 320, 1, 1]             640\n",
      "     BasicConv2d-162            [-1, 320, 1, 1]               0\n",
      "          Conv2d-163             [-1, 32, 1, 1]          26,624\n",
      "     BatchNorm2d-164             [-1, 32, 1, 1]              64\n",
      "     BasicConv2d-165             [-1, 32, 1, 1]               0\n",
      "          Conv2d-166            [-1, 128, 1, 1]          36,864\n",
      "     BatchNorm2d-167            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-168            [-1, 128, 1, 1]               0\n",
      "       MaxPool2d-169            [-1, 832, 1, 1]               0\n",
      "          Conv2d-170            [-1, 128, 1, 1]         106,496\n",
      "     BatchNorm2d-171            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-172            [-1, 128, 1, 1]               0\n",
      "       Inception-173            [-1, 832, 1, 1]               0\n",
      "          Conv2d-174            [-1, 384, 1, 1]         319,488\n",
      "     BatchNorm2d-175            [-1, 384, 1, 1]             768\n",
      "     BasicConv2d-176            [-1, 384, 1, 1]               0\n",
      "          Conv2d-177            [-1, 192, 1, 1]         159,744\n",
      "     BatchNorm2d-178            [-1, 192, 1, 1]             384\n",
      "     BasicConv2d-179            [-1, 192, 1, 1]               0\n",
      "          Conv2d-180            [-1, 384, 1, 1]         663,552\n",
      "     BatchNorm2d-181            [-1, 384, 1, 1]             768\n",
      "     BasicConv2d-182            [-1, 384, 1, 1]               0\n",
      "          Conv2d-183             [-1, 48, 1, 1]          39,936\n",
      "     BatchNorm2d-184             [-1, 48, 1, 1]              96\n",
      "     BasicConv2d-185             [-1, 48, 1, 1]               0\n",
      "          Conv2d-186            [-1, 128, 1, 1]          55,296\n",
      "     BatchNorm2d-187            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-188            [-1, 128, 1, 1]               0\n",
      "       MaxPool2d-189            [-1, 832, 1, 1]               0\n",
      "          Conv2d-190            [-1, 128, 1, 1]         106,496\n",
      "     BatchNorm2d-191            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-192            [-1, 128, 1, 1]               0\n",
      "       Inception-193           [-1, 1024, 1, 1]               0\n",
      "AdaptiveAvgPool2d-194           [-1, 1024, 1, 1]               0\n",
      "         Dropout-195                 [-1, 1024]               0\n",
      "          Linear-196                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 5,610,154\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 5,599,904\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.94\n",
      "Params size (MB): 21.40\n",
      "Estimated Total Size (MB): 23.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(googlenet_first_config_model, f\"{GOOGLENET_MODEL_NAME}: one transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWf40JP2SB7e",
    "outputId": "e747add1-c4c7-4b18-b789-c61e58c5e2e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train started\n",
      "Epoch[1/4]: Loss = 1.1603, Train accuracy = 0.6603, Time epoch = 208.90 sec.\n",
      "Epoch[2/4]: Loss = 0.7901, Train accuracy = 0.7417, Time epoch = 207.47 sec.\n",
      "Epoch[3/4]: Loss = 0.7329, Train accuracy = 0.7536, Time epoch = 200.24 sec.\n",
      "Epoch[4/4]: Loss = 0.7019, Train accuracy = 0.7616, Time epoch = 197.99 sec.\n",
      "Train ended\n",
      "Total train time: 814.61 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0029, Test accuracy = 0.7470\n"
     ]
    }
   ],
   "source": [
    "def get_datasets(transform):\n",
    "  train_dataset = torchvision.datasets.CIFAR10(\n",
    "      root = PATH, train = True, download = True,\n",
    "      transform = transform\n",
    "  )\n",
    "  test_dataset = torchvision.datasets.CIFAR10(\n",
    "      root = PATH, train = False, download = True,\n",
    "      transform = transform\n",
    "  )\n",
    "  return train_dataset, test_dataset\n",
    "\n",
    "googlenet_train_dataset, googlenet_test_dataset = get_datasets(models.GoogLeNet_Weights.DEFAULT.transforms())\n",
    "googlenet_first_config_test_acc = run_testing_model_with_config(googlenet_first_config_model, googlenet_train_dataset, googlenet_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9kG72DfSCcH"
   },
   "source": [
    "### GoogleNet second config (two transformed layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JW9qCVPrSDXY",
    "outputId": "5dac1187-3abf-41b3-b3fd-5835e36df50a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "googlenet_second_config_model = create_second_model_config(models.googlenet, models.GoogLeNet_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIk-phrWSDmJ",
    "outputId": "238067bf-8319-4a17-c58d-3e708bf7238d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GoogLeNet: two transformed layer\n",
      "GoogLeNet(\n",
      "  (conv1): BasicConv2d(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): BasicConv2d(\n",
      "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception3a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception3b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception4a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4c): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4d): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4e): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception5a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception5b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (aux1): None\n",
      "  (aux2): None\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "       BasicConv2d-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "       BasicConv2d-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8            [-1, 192, 8, 8]         110,592\n",
      "       BatchNorm2d-9            [-1, 192, 8, 8]             384\n",
      "      BasicConv2d-10            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-11            [-1, 192, 4, 4]               0\n",
      "           Conv2d-12             [-1, 64, 4, 4]          12,288\n",
      "      BatchNorm2d-13             [-1, 64, 4, 4]             128\n",
      "      BasicConv2d-14             [-1, 64, 4, 4]               0\n",
      "           Conv2d-15             [-1, 96, 4, 4]          18,432\n",
      "      BatchNorm2d-16             [-1, 96, 4, 4]             192\n",
      "      BasicConv2d-17             [-1, 96, 4, 4]               0\n",
      "           Conv2d-18            [-1, 128, 4, 4]         110,592\n",
      "      BatchNorm2d-19            [-1, 128, 4, 4]             256\n",
      "      BasicConv2d-20            [-1, 128, 4, 4]               0\n",
      "           Conv2d-21             [-1, 16, 4, 4]           3,072\n",
      "      BatchNorm2d-22             [-1, 16, 4, 4]              32\n",
      "      BasicConv2d-23             [-1, 16, 4, 4]               0\n",
      "           Conv2d-24             [-1, 32, 4, 4]           4,608\n",
      "      BatchNorm2d-25             [-1, 32, 4, 4]              64\n",
      "      BasicConv2d-26             [-1, 32, 4, 4]               0\n",
      "        MaxPool2d-27            [-1, 192, 4, 4]               0\n",
      "           Conv2d-28             [-1, 32, 4, 4]           6,144\n",
      "      BatchNorm2d-29             [-1, 32, 4, 4]              64\n",
      "      BasicConv2d-30             [-1, 32, 4, 4]               0\n",
      "        Inception-31            [-1, 256, 4, 4]               0\n",
      "           Conv2d-32            [-1, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-33            [-1, 128, 4, 4]             256\n",
      "      BasicConv2d-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
      "      BasicConv2d-37            [-1, 128, 4, 4]               0\n",
      "           Conv2d-38            [-1, 192, 4, 4]         221,184\n",
      "      BatchNorm2d-39            [-1, 192, 4, 4]             384\n",
      "      BasicConv2d-40            [-1, 192, 4, 4]               0\n",
      "           Conv2d-41             [-1, 32, 4, 4]           8,192\n",
      "      BatchNorm2d-42             [-1, 32, 4, 4]              64\n",
      "      BasicConv2d-43             [-1, 32, 4, 4]               0\n",
      "           Conv2d-44             [-1, 96, 4, 4]          27,648\n",
      "      BatchNorm2d-45             [-1, 96, 4, 4]             192\n",
      "      BasicConv2d-46             [-1, 96, 4, 4]               0\n",
      "        MaxPool2d-47            [-1, 256, 4, 4]               0\n",
      "           Conv2d-48             [-1, 64, 4, 4]          16,384\n",
      "      BatchNorm2d-49             [-1, 64, 4, 4]             128\n",
      "      BasicConv2d-50             [-1, 64, 4, 4]               0\n",
      "        Inception-51            [-1, 480, 4, 4]               0\n",
      "        MaxPool2d-52            [-1, 480, 2, 2]               0\n",
      "           Conv2d-53            [-1, 192, 2, 2]          92,160\n",
      "      BatchNorm2d-54            [-1, 192, 2, 2]             384\n",
      "      BasicConv2d-55            [-1, 192, 2, 2]               0\n",
      "           Conv2d-56             [-1, 96, 2, 2]          46,080\n",
      "      BatchNorm2d-57             [-1, 96, 2, 2]             192\n",
      "      BasicConv2d-58             [-1, 96, 2, 2]               0\n",
      "           Conv2d-59            [-1, 208, 2, 2]         179,712\n",
      "      BatchNorm2d-60            [-1, 208, 2, 2]             416\n",
      "      BasicConv2d-61            [-1, 208, 2, 2]               0\n",
      "           Conv2d-62             [-1, 16, 2, 2]           7,680\n",
      "      BatchNorm2d-63             [-1, 16, 2, 2]              32\n",
      "      BasicConv2d-64             [-1, 16, 2, 2]               0\n",
      "           Conv2d-65             [-1, 48, 2, 2]           6,912\n",
      "      BatchNorm2d-66             [-1, 48, 2, 2]              96\n",
      "      BasicConv2d-67             [-1, 48, 2, 2]               0\n",
      "        MaxPool2d-68            [-1, 480, 2, 2]               0\n",
      "           Conv2d-69             [-1, 64, 2, 2]          30,720\n",
      "      BatchNorm2d-70             [-1, 64, 2, 2]             128\n",
      "      BasicConv2d-71             [-1, 64, 2, 2]               0\n",
      "        Inception-72            [-1, 512, 2, 2]               0\n",
      "           Conv2d-73            [-1, 160, 2, 2]          81,920\n",
      "      BatchNorm2d-74            [-1, 160, 2, 2]             320\n",
      "      BasicConv2d-75            [-1, 160, 2, 2]               0\n",
      "           Conv2d-76            [-1, 112, 2, 2]          57,344\n",
      "      BatchNorm2d-77            [-1, 112, 2, 2]             224\n",
      "      BasicConv2d-78            [-1, 112, 2, 2]               0\n",
      "           Conv2d-79            [-1, 224, 2, 2]         225,792\n",
      "      BatchNorm2d-80            [-1, 224, 2, 2]             448\n",
      "      BasicConv2d-81            [-1, 224, 2, 2]               0\n",
      "           Conv2d-82             [-1, 24, 2, 2]          12,288\n",
      "      BatchNorm2d-83             [-1, 24, 2, 2]              48\n",
      "      BasicConv2d-84             [-1, 24, 2, 2]               0\n",
      "           Conv2d-85             [-1, 64, 2, 2]          13,824\n",
      "      BatchNorm2d-86             [-1, 64, 2, 2]             128\n",
      "      BasicConv2d-87             [-1, 64, 2, 2]               0\n",
      "        MaxPool2d-88            [-1, 512, 2, 2]               0\n",
      "           Conv2d-89             [-1, 64, 2, 2]          32,768\n",
      "      BatchNorm2d-90             [-1, 64, 2, 2]             128\n",
      "      BasicConv2d-91             [-1, 64, 2, 2]               0\n",
      "        Inception-92            [-1, 512, 2, 2]               0\n",
      "           Conv2d-93            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-94            [-1, 128, 2, 2]             256\n",
      "      BasicConv2d-95            [-1, 128, 2, 2]               0\n",
      "           Conv2d-96            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-97            [-1, 128, 2, 2]             256\n",
      "      BasicConv2d-98            [-1, 128, 2, 2]               0\n",
      "           Conv2d-99            [-1, 256, 2, 2]         294,912\n",
      "     BatchNorm2d-100            [-1, 256, 2, 2]             512\n",
      "     BasicConv2d-101            [-1, 256, 2, 2]               0\n",
      "          Conv2d-102             [-1, 24, 2, 2]          12,288\n",
      "     BatchNorm2d-103             [-1, 24, 2, 2]              48\n",
      "     BasicConv2d-104             [-1, 24, 2, 2]               0\n",
      "          Conv2d-105             [-1, 64, 2, 2]          13,824\n",
      "     BatchNorm2d-106             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-107             [-1, 64, 2, 2]               0\n",
      "       MaxPool2d-108            [-1, 512, 2, 2]               0\n",
      "          Conv2d-109             [-1, 64, 2, 2]          32,768\n",
      "     BatchNorm2d-110             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-111             [-1, 64, 2, 2]               0\n",
      "       Inception-112            [-1, 512, 2, 2]               0\n",
      "          Conv2d-113            [-1, 112, 2, 2]          57,344\n",
      "     BatchNorm2d-114            [-1, 112, 2, 2]             224\n",
      "     BasicConv2d-115            [-1, 112, 2, 2]               0\n",
      "          Conv2d-116            [-1, 144, 2, 2]          73,728\n",
      "     BatchNorm2d-117            [-1, 144, 2, 2]             288\n",
      "     BasicConv2d-118            [-1, 144, 2, 2]               0\n",
      "          Conv2d-119            [-1, 288, 2, 2]         373,248\n",
      "     BatchNorm2d-120            [-1, 288, 2, 2]             576\n",
      "     BasicConv2d-121            [-1, 288, 2, 2]               0\n",
      "          Conv2d-122             [-1, 32, 2, 2]          16,384\n",
      "     BatchNorm2d-123             [-1, 32, 2, 2]              64\n",
      "     BasicConv2d-124             [-1, 32, 2, 2]               0\n",
      "          Conv2d-125             [-1, 64, 2, 2]          18,432\n",
      "     BatchNorm2d-126             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-127             [-1, 64, 2, 2]               0\n",
      "       MaxPool2d-128            [-1, 512, 2, 2]               0\n",
      "          Conv2d-129             [-1, 64, 2, 2]          32,768\n",
      "     BatchNorm2d-130             [-1, 64, 2, 2]             128\n",
      "     BasicConv2d-131             [-1, 64, 2, 2]               0\n",
      "       Inception-132            [-1, 528, 2, 2]               0\n",
      "          Conv2d-133            [-1, 256, 2, 2]         135,168\n",
      "     BatchNorm2d-134            [-1, 256, 2, 2]             512\n",
      "     BasicConv2d-135            [-1, 256, 2, 2]               0\n",
      "          Conv2d-136            [-1, 160, 2, 2]          84,480\n",
      "     BatchNorm2d-137            [-1, 160, 2, 2]             320\n",
      "     BasicConv2d-138            [-1, 160, 2, 2]               0\n",
      "          Conv2d-139            [-1, 320, 2, 2]         460,800\n",
      "     BatchNorm2d-140            [-1, 320, 2, 2]             640\n",
      "     BasicConv2d-141            [-1, 320, 2, 2]               0\n",
      "          Conv2d-142             [-1, 32, 2, 2]          16,896\n",
      "     BatchNorm2d-143             [-1, 32, 2, 2]              64\n",
      "     BasicConv2d-144             [-1, 32, 2, 2]               0\n",
      "          Conv2d-145            [-1, 128, 2, 2]          36,864\n",
      "     BatchNorm2d-146            [-1, 128, 2, 2]             256\n",
      "     BasicConv2d-147            [-1, 128, 2, 2]               0\n",
      "       MaxPool2d-148            [-1, 528, 2, 2]               0\n",
      "          Conv2d-149            [-1, 128, 2, 2]          67,584\n",
      "     BatchNorm2d-150            [-1, 128, 2, 2]             256\n",
      "     BasicConv2d-151            [-1, 128, 2, 2]               0\n",
      "       Inception-152            [-1, 832, 2, 2]               0\n",
      "       MaxPool2d-153            [-1, 832, 1, 1]               0\n",
      "          Conv2d-154            [-1, 256, 1, 1]         212,992\n",
      "     BatchNorm2d-155            [-1, 256, 1, 1]             512\n",
      "     BasicConv2d-156            [-1, 256, 1, 1]               0\n",
      "          Conv2d-157            [-1, 160, 1, 1]         133,120\n",
      "     BatchNorm2d-158            [-1, 160, 1, 1]             320\n",
      "     BasicConv2d-159            [-1, 160, 1, 1]               0\n",
      "          Conv2d-160            [-1, 320, 1, 1]         460,800\n",
      "     BatchNorm2d-161            [-1, 320, 1, 1]             640\n",
      "     BasicConv2d-162            [-1, 320, 1, 1]               0\n",
      "          Conv2d-163             [-1, 32, 1, 1]          26,624\n",
      "     BatchNorm2d-164             [-1, 32, 1, 1]              64\n",
      "     BasicConv2d-165             [-1, 32, 1, 1]               0\n",
      "          Conv2d-166            [-1, 128, 1, 1]          36,864\n",
      "     BatchNorm2d-167            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-168            [-1, 128, 1, 1]               0\n",
      "       MaxPool2d-169            [-1, 832, 1, 1]               0\n",
      "          Conv2d-170            [-1, 128, 1, 1]         106,496\n",
      "     BatchNorm2d-171            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-172            [-1, 128, 1, 1]               0\n",
      "       Inception-173            [-1, 832, 1, 1]               0\n",
      "          Conv2d-174            [-1, 384, 1, 1]         319,488\n",
      "     BatchNorm2d-175            [-1, 384, 1, 1]             768\n",
      "     BasicConv2d-176            [-1, 384, 1, 1]               0\n",
      "          Conv2d-177            [-1, 192, 1, 1]         159,744\n",
      "     BatchNorm2d-178            [-1, 192, 1, 1]             384\n",
      "     BasicConv2d-179            [-1, 192, 1, 1]               0\n",
      "          Conv2d-180            [-1, 384, 1, 1]         663,552\n",
      "     BatchNorm2d-181            [-1, 384, 1, 1]             768\n",
      "     BasicConv2d-182            [-1, 384, 1, 1]               0\n",
      "          Conv2d-183             [-1, 48, 1, 1]          39,936\n",
      "     BatchNorm2d-184             [-1, 48, 1, 1]              96\n",
      "     BasicConv2d-185             [-1, 48, 1, 1]               0\n",
      "          Conv2d-186            [-1, 128, 1, 1]          55,296\n",
      "     BatchNorm2d-187            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-188            [-1, 128, 1, 1]               0\n",
      "       MaxPool2d-189            [-1, 832, 1, 1]               0\n",
      "          Conv2d-190            [-1, 128, 1, 1]         106,496\n",
      "     BatchNorm2d-191            [-1, 128, 1, 1]             256\n",
      "     BasicConv2d-192            [-1, 128, 1, 1]               0\n",
      "       Inception-193           [-1, 1024, 1, 1]               0\n",
      "AdaptiveAvgPool2d-194           [-1, 1024, 1, 1]               0\n",
      "         Dropout-195                 [-1, 1024]               0\n",
      "          Linear-196                  [-1, 512]         524,800\n",
      "            ReLU-197                  [-1, 512]               0\n",
      "          Linear-198                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 6,129,834\n",
      "Trainable params: 529,930\n",
      "Non-trainable params: 5,599,904\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.94\n",
      "Params size (MB): 23.38\n",
      "Estimated Total Size (MB): 25.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(googlenet_second_config_model, f\"{GOOGLENET_MODEL_NAME}: two transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_EEXxy5SEGL",
    "outputId": "480ca93f-2cb1-486d-8a38-d72fbe1c5e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started\n",
      "Epoch[1/4]: Loss = 0.8924, Train accuracy = 0.7006, Time epoch = 198.81 sec.\n",
      "Epoch[2/4]: Loss = 0.7092, Train accuracy = 0.7559, Time epoch = 194.82 sec.\n",
      "Epoch[3/4]: Loss = 0.6866, Train accuracy = 0.7615, Time epoch = 194.45 sec.\n",
      "Epoch[4/4]: Loss = 0.6672, Train accuracy = 0.7698, Time epoch = 194.62 sec.\n",
      "Train ended\n",
      "Total train time: 782.70 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0028, Test accuracy = 0.7616\n"
     ]
    }
   ],
   "source": [
    "googlenet_second_config_test_acc = run_testing_model_with_config(googlenet_second_config_model, googlenet_train_dataset, googlenet_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekCDX9bjSEjw"
   },
   "source": [
    "## ShuffleNet_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VaxiSA6Tb8Y"
   },
   "source": [
    "### ShuffleNet_V2 first config (one transformed layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pLRF10CSFBA",
    "outputId": "6adcc6c1-5470-4f6d-b3da-3f0badc922d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x2_0-8be3c8ee.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x2_0-8be3c8ee.pth\n",
      "100%|██████████| 28.4M/28.4M [00:03<00:00, 8.58MB/s]\n"
     ]
    }
   ],
   "source": [
    "shufflenet_first_config_model = create_first_model_config(models.shufflenet_v2_x2_0, models.ShuffleNet_V2_X2_0_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbLha4UWSFQ7",
    "outputId": "3015ba1e-f94f-43b9-ee05-d881e55d45b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ShuffleNet_V2: one transformed layer\n",
      "ShuffleNetV2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 16, 16]             648\n",
      "       BatchNorm2d-2           [-1, 24, 16, 16]              48\n",
      "              ReLU-3           [-1, 24, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 24, 8, 8]               0\n",
      "            Conv2d-5             [-1, 24, 4, 4]             216\n",
      "       BatchNorm2d-6             [-1, 24, 4, 4]              48\n",
      "            Conv2d-7            [-1, 122, 4, 4]           2,928\n",
      "       BatchNorm2d-8            [-1, 122, 4, 4]             244\n",
      "              ReLU-9            [-1, 122, 4, 4]               0\n",
      "           Conv2d-10            [-1, 122, 8, 8]           2,928\n",
      "      BatchNorm2d-11            [-1, 122, 8, 8]             244\n",
      "             ReLU-12            [-1, 122, 8, 8]               0\n",
      "           Conv2d-13            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-14            [-1, 122, 4, 4]             244\n",
      "           Conv2d-15            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-16            [-1, 122, 4, 4]             244\n",
      "             ReLU-17            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-18            [-1, 244, 4, 4]               0\n",
      "           Conv2d-19            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-20            [-1, 122, 4, 4]             244\n",
      "             ReLU-21            [-1, 122, 4, 4]               0\n",
      "           Conv2d-22            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-23            [-1, 122, 4, 4]             244\n",
      "           Conv2d-24            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-25            [-1, 122, 4, 4]             244\n",
      "             ReLU-26            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-27            [-1, 244, 4, 4]               0\n",
      "           Conv2d-28            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-29            [-1, 122, 4, 4]             244\n",
      "             ReLU-30            [-1, 122, 4, 4]               0\n",
      "           Conv2d-31            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-32            [-1, 122, 4, 4]             244\n",
      "           Conv2d-33            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-34            [-1, 122, 4, 4]             244\n",
      "             ReLU-35            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-36            [-1, 244, 4, 4]               0\n",
      "           Conv2d-37            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-38            [-1, 122, 4, 4]             244\n",
      "             ReLU-39            [-1, 122, 4, 4]               0\n",
      "           Conv2d-40            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-41            [-1, 122, 4, 4]             244\n",
      "           Conv2d-42            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-43            [-1, 122, 4, 4]             244\n",
      "             ReLU-44            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-45            [-1, 244, 4, 4]               0\n",
      "           Conv2d-46            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-47            [-1, 244, 2, 2]             488\n",
      "           Conv2d-48            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-49            [-1, 244, 2, 2]             488\n",
      "             ReLU-50            [-1, 244, 2, 2]               0\n",
      "           Conv2d-51            [-1, 244, 4, 4]          59,536\n",
      "      BatchNorm2d-52            [-1, 244, 4, 4]             488\n",
      "             ReLU-53            [-1, 244, 4, 4]               0\n",
      "           Conv2d-54            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-55            [-1, 244, 2, 2]             488\n",
      "           Conv2d-56            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-57            [-1, 244, 2, 2]             488\n",
      "             ReLU-58            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-59            [-1, 488, 2, 2]               0\n",
      "           Conv2d-60            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-61            [-1, 244, 2, 2]             488\n",
      "             ReLU-62            [-1, 244, 2, 2]               0\n",
      "           Conv2d-63            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-64            [-1, 244, 2, 2]             488\n",
      "           Conv2d-65            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-66            [-1, 244, 2, 2]             488\n",
      "             ReLU-67            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-68            [-1, 488, 2, 2]               0\n",
      "           Conv2d-69            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-70            [-1, 244, 2, 2]             488\n",
      "             ReLU-71            [-1, 244, 2, 2]               0\n",
      "           Conv2d-72            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-73            [-1, 244, 2, 2]             488\n",
      "           Conv2d-74            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-75            [-1, 244, 2, 2]             488\n",
      "             ReLU-76            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-77            [-1, 488, 2, 2]               0\n",
      "           Conv2d-78            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-79            [-1, 244, 2, 2]             488\n",
      "             ReLU-80            [-1, 244, 2, 2]               0\n",
      "           Conv2d-81            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-82            [-1, 244, 2, 2]             488\n",
      "           Conv2d-83            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-84            [-1, 244, 2, 2]             488\n",
      "             ReLU-85            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-86            [-1, 488, 2, 2]               0\n",
      "           Conv2d-87            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-88            [-1, 244, 2, 2]             488\n",
      "             ReLU-89            [-1, 244, 2, 2]               0\n",
      "           Conv2d-90            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-91            [-1, 244, 2, 2]             488\n",
      "           Conv2d-92            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-93            [-1, 244, 2, 2]             488\n",
      "             ReLU-94            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-95            [-1, 488, 2, 2]               0\n",
      "           Conv2d-96            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-97            [-1, 244, 2, 2]             488\n",
      "             ReLU-98            [-1, 244, 2, 2]               0\n",
      "           Conv2d-99            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-100            [-1, 244, 2, 2]             488\n",
      "          Conv2d-101            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-102            [-1, 244, 2, 2]             488\n",
      "            ReLU-103            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-104            [-1, 488, 2, 2]               0\n",
      "          Conv2d-105            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-106            [-1, 244, 2, 2]             488\n",
      "            ReLU-107            [-1, 244, 2, 2]               0\n",
      "          Conv2d-108            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-109            [-1, 244, 2, 2]             488\n",
      "          Conv2d-110            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-111            [-1, 244, 2, 2]             488\n",
      "            ReLU-112            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-113            [-1, 488, 2, 2]               0\n",
      "          Conv2d-114            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-115            [-1, 244, 2, 2]             488\n",
      "            ReLU-116            [-1, 244, 2, 2]               0\n",
      "          Conv2d-117            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-118            [-1, 244, 2, 2]             488\n",
      "          Conv2d-119            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-120            [-1, 244, 2, 2]             488\n",
      "            ReLU-121            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-122            [-1, 488, 2, 2]               0\n",
      "          Conv2d-123            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-124            [-1, 488, 1, 1]             976\n",
      "          Conv2d-125            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-126            [-1, 488, 1, 1]             976\n",
      "            ReLU-127            [-1, 488, 1, 1]               0\n",
      "          Conv2d-128            [-1, 488, 2, 2]         238,144\n",
      "     BatchNorm2d-129            [-1, 488, 2, 2]             976\n",
      "            ReLU-130            [-1, 488, 2, 2]               0\n",
      "          Conv2d-131            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-132            [-1, 488, 1, 1]             976\n",
      "          Conv2d-133            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-134            [-1, 488, 1, 1]             976\n",
      "            ReLU-135            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-136            [-1, 976, 1, 1]               0\n",
      "          Conv2d-137            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-138            [-1, 488, 1, 1]             976\n",
      "            ReLU-139            [-1, 488, 1, 1]               0\n",
      "          Conv2d-140            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-141            [-1, 488, 1, 1]             976\n",
      "          Conv2d-142            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-143            [-1, 488, 1, 1]             976\n",
      "            ReLU-144            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-145            [-1, 976, 1, 1]               0\n",
      "          Conv2d-146            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-147            [-1, 488, 1, 1]             976\n",
      "            ReLU-148            [-1, 488, 1, 1]               0\n",
      "          Conv2d-149            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-150            [-1, 488, 1, 1]             976\n",
      "          Conv2d-151            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-152            [-1, 488, 1, 1]             976\n",
      "            ReLU-153            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-154            [-1, 976, 1, 1]               0\n",
      "          Conv2d-155            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-156            [-1, 488, 1, 1]             976\n",
      "            ReLU-157            [-1, 488, 1, 1]               0\n",
      "          Conv2d-158            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-159            [-1, 488, 1, 1]             976\n",
      "          Conv2d-160            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-161            [-1, 488, 1, 1]             976\n",
      "            ReLU-162            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-163            [-1, 976, 1, 1]               0\n",
      "          Conv2d-164           [-1, 2048, 1, 1]       1,998,848\n",
      "     BatchNorm2d-165           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-166           [-1, 2048, 1, 1]               0\n",
      "          Linear-167                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 5,365,486\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 5,344,996\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.88\n",
      "Params size (MB): 20.47\n",
      "Estimated Total Size (MB): 22.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(shufflenet_first_config_model, f\"{SHUFFLENET_V2_MODEL_NAME}: one transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amyq5SBKSFtT",
    "outputId": "bc0fbcc9-2755-4baf-868b-d56a2ceb674f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train started\n",
      "Epoch[1/4]: Loss = 0.9079, Train accuracy = 0.7434, Time epoch = 185.87 sec.\n",
      "Epoch[2/4]: Loss = 0.5566, Train accuracy = 0.8225, Time epoch = 186.30 sec.\n",
      "Epoch[3/4]: Loss = 0.4867, Train accuracy = 0.8428, Time epoch = 183.84 sec.\n",
      "Epoch[4/4]: Loss = 0.4497, Train accuracy = 0.8511, Time epoch = 185.29 sec.\n",
      "Train ended\n",
      "Total train time: 741.30 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0019, Test accuracy = 0.8422\n"
     ]
    }
   ],
   "source": [
    "shufflenet_train_dataset, shufflenet_test_dataset = get_datasets(models.ShuffleNet_V2_X2_0_Weights.DEFAULT.transforms())\n",
    "shufflenet_first_config_test_acc = run_testing_model_with_config(shufflenet_first_config_model, shufflenet_train_dataset, shufflenet_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_BxLEMgSGGr"
   },
   "source": [
    "### ShuffleNet_V2 second config (two transformed layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxWhCLIUSG59",
    "outputId": "893b41eb-03a4-4a52-c6d9-8f234821212b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "shufflenet_second_config_model = create_second_model_config(models.shufflenet_v2_x2_0, models.ShuffleNet_V2_X2_0_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-v5wukUSSHIG",
    "outputId": "588bbf3a-1844-4339-e801-689969747914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ShuffleNet_V2: two transformed layer\n",
      "ShuffleNetV2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(122, 122, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=122, bias=False)\n",
      "        (4): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(122, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=244, bias=False)\n",
      "        (4): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(244, 244, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(244, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=488, bias=False)\n",
      "        (4): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(488, 488, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(976, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 16, 16]             648\n",
      "       BatchNorm2d-2           [-1, 24, 16, 16]              48\n",
      "              ReLU-3           [-1, 24, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 24, 8, 8]               0\n",
      "            Conv2d-5             [-1, 24, 4, 4]             216\n",
      "       BatchNorm2d-6             [-1, 24, 4, 4]              48\n",
      "            Conv2d-7            [-1, 122, 4, 4]           2,928\n",
      "       BatchNorm2d-8            [-1, 122, 4, 4]             244\n",
      "              ReLU-9            [-1, 122, 4, 4]               0\n",
      "           Conv2d-10            [-1, 122, 8, 8]           2,928\n",
      "      BatchNorm2d-11            [-1, 122, 8, 8]             244\n",
      "             ReLU-12            [-1, 122, 8, 8]               0\n",
      "           Conv2d-13            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-14            [-1, 122, 4, 4]             244\n",
      "           Conv2d-15            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-16            [-1, 122, 4, 4]             244\n",
      "             ReLU-17            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-18            [-1, 244, 4, 4]               0\n",
      "           Conv2d-19            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-20            [-1, 122, 4, 4]             244\n",
      "             ReLU-21            [-1, 122, 4, 4]               0\n",
      "           Conv2d-22            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-23            [-1, 122, 4, 4]             244\n",
      "           Conv2d-24            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-25            [-1, 122, 4, 4]             244\n",
      "             ReLU-26            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-27            [-1, 244, 4, 4]               0\n",
      "           Conv2d-28            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-29            [-1, 122, 4, 4]             244\n",
      "             ReLU-30            [-1, 122, 4, 4]               0\n",
      "           Conv2d-31            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-32            [-1, 122, 4, 4]             244\n",
      "           Conv2d-33            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-34            [-1, 122, 4, 4]             244\n",
      "             ReLU-35            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-36            [-1, 244, 4, 4]               0\n",
      "           Conv2d-37            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-38            [-1, 122, 4, 4]             244\n",
      "             ReLU-39            [-1, 122, 4, 4]               0\n",
      "           Conv2d-40            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-41            [-1, 122, 4, 4]             244\n",
      "           Conv2d-42            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-43            [-1, 122, 4, 4]             244\n",
      "             ReLU-44            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-45            [-1, 244, 4, 4]               0\n",
      "           Conv2d-46            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-47            [-1, 244, 2, 2]             488\n",
      "           Conv2d-48            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-49            [-1, 244, 2, 2]             488\n",
      "             ReLU-50            [-1, 244, 2, 2]               0\n",
      "           Conv2d-51            [-1, 244, 4, 4]          59,536\n",
      "      BatchNorm2d-52            [-1, 244, 4, 4]             488\n",
      "             ReLU-53            [-1, 244, 4, 4]               0\n",
      "           Conv2d-54            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-55            [-1, 244, 2, 2]             488\n",
      "           Conv2d-56            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-57            [-1, 244, 2, 2]             488\n",
      "             ReLU-58            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-59            [-1, 488, 2, 2]               0\n",
      "           Conv2d-60            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-61            [-1, 244, 2, 2]             488\n",
      "             ReLU-62            [-1, 244, 2, 2]               0\n",
      "           Conv2d-63            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-64            [-1, 244, 2, 2]             488\n",
      "           Conv2d-65            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-66            [-1, 244, 2, 2]             488\n",
      "             ReLU-67            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-68            [-1, 488, 2, 2]               0\n",
      "           Conv2d-69            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-70            [-1, 244, 2, 2]             488\n",
      "             ReLU-71            [-1, 244, 2, 2]               0\n",
      "           Conv2d-72            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-73            [-1, 244, 2, 2]             488\n",
      "           Conv2d-74            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-75            [-1, 244, 2, 2]             488\n",
      "             ReLU-76            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-77            [-1, 488, 2, 2]               0\n",
      "           Conv2d-78            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-79            [-1, 244, 2, 2]             488\n",
      "             ReLU-80            [-1, 244, 2, 2]               0\n",
      "           Conv2d-81            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-82            [-1, 244, 2, 2]             488\n",
      "           Conv2d-83            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-84            [-1, 244, 2, 2]             488\n",
      "             ReLU-85            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-86            [-1, 488, 2, 2]               0\n",
      "           Conv2d-87            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-88            [-1, 244, 2, 2]             488\n",
      "             ReLU-89            [-1, 244, 2, 2]               0\n",
      "           Conv2d-90            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-91            [-1, 244, 2, 2]             488\n",
      "           Conv2d-92            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-93            [-1, 244, 2, 2]             488\n",
      "             ReLU-94            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-95            [-1, 488, 2, 2]               0\n",
      "           Conv2d-96            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-97            [-1, 244, 2, 2]             488\n",
      "             ReLU-98            [-1, 244, 2, 2]               0\n",
      "           Conv2d-99            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-100            [-1, 244, 2, 2]             488\n",
      "          Conv2d-101            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-102            [-1, 244, 2, 2]             488\n",
      "            ReLU-103            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-104            [-1, 488, 2, 2]               0\n",
      "          Conv2d-105            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-106            [-1, 244, 2, 2]             488\n",
      "            ReLU-107            [-1, 244, 2, 2]               0\n",
      "          Conv2d-108            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-109            [-1, 244, 2, 2]             488\n",
      "          Conv2d-110            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-111            [-1, 244, 2, 2]             488\n",
      "            ReLU-112            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-113            [-1, 488, 2, 2]               0\n",
      "          Conv2d-114            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-115            [-1, 244, 2, 2]             488\n",
      "            ReLU-116            [-1, 244, 2, 2]               0\n",
      "          Conv2d-117            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-118            [-1, 244, 2, 2]             488\n",
      "          Conv2d-119            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-120            [-1, 244, 2, 2]             488\n",
      "            ReLU-121            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-122            [-1, 488, 2, 2]               0\n",
      "          Conv2d-123            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-124            [-1, 488, 1, 1]             976\n",
      "          Conv2d-125            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-126            [-1, 488, 1, 1]             976\n",
      "            ReLU-127            [-1, 488, 1, 1]               0\n",
      "          Conv2d-128            [-1, 488, 2, 2]         238,144\n",
      "     BatchNorm2d-129            [-1, 488, 2, 2]             976\n",
      "            ReLU-130            [-1, 488, 2, 2]               0\n",
      "          Conv2d-131            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-132            [-1, 488, 1, 1]             976\n",
      "          Conv2d-133            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-134            [-1, 488, 1, 1]             976\n",
      "            ReLU-135            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-136            [-1, 976, 1, 1]               0\n",
      "          Conv2d-137            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-138            [-1, 488, 1, 1]             976\n",
      "            ReLU-139            [-1, 488, 1, 1]               0\n",
      "          Conv2d-140            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-141            [-1, 488, 1, 1]             976\n",
      "          Conv2d-142            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-143            [-1, 488, 1, 1]             976\n",
      "            ReLU-144            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-145            [-1, 976, 1, 1]               0\n",
      "          Conv2d-146            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-147            [-1, 488, 1, 1]             976\n",
      "            ReLU-148            [-1, 488, 1, 1]               0\n",
      "          Conv2d-149            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-150            [-1, 488, 1, 1]             976\n",
      "          Conv2d-151            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-152            [-1, 488, 1, 1]             976\n",
      "            ReLU-153            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-154            [-1, 976, 1, 1]               0\n",
      "          Conv2d-155            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-156            [-1, 488, 1, 1]             976\n",
      "            ReLU-157            [-1, 488, 1, 1]               0\n",
      "          Conv2d-158            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-159            [-1, 488, 1, 1]             976\n",
      "          Conv2d-160            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-161            [-1, 488, 1, 1]             976\n",
      "            ReLU-162            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-163            [-1, 976, 1, 1]               0\n",
      "          Conv2d-164           [-1, 2048, 1, 1]       1,998,848\n",
      "     BatchNorm2d-165           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-166           [-1, 2048, 1, 1]               0\n",
      "          Linear-167                 [-1, 1024]       2,098,176\n",
      "            ReLU-168                 [-1, 1024]               0\n",
      "          Linear-169                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 7,453,422\n",
      "Trainable params: 2,108,426\n",
      "Non-trainable params: 5,344,996\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.90\n",
      "Params size (MB): 28.43\n",
      "Estimated Total Size (MB): 30.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "visualize_model(shufflenet_second_config_model, f\"{SHUFFLENET_V2_MODEL_NAME}: two transformed layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nj8tl0ESHXD",
    "outputId": "b1b956af-17eb-4d77-ef89-6c312eb24533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started\n",
      "Epoch[1/4]: Loss = 0.6118, Train accuracy = 0.7965, Time epoch = 181.32 sec.\n",
      "Epoch[2/4]: Loss = 0.4181, Train accuracy = 0.8558, Time epoch = 181.39 sec.\n",
      "Epoch[3/4]: Loss = 0.3650, Train accuracy = 0.8715, Time epoch = 180.66 sec.\n",
      "Epoch[4/4]: Loss = 0.3194, Train accuracy = 0.8879, Time epoch = 182.85 sec.\n",
      "Train ended\n",
      "Total train time: 726.23 sec.\n",
      "Validation model on test data\n",
      "Test Loss = 0.0018, Test accuracy = 0.8497\n"
     ]
    }
   ],
   "source": [
    "shufflenet_second_config_test_acc = run_testing_model_with_config(shufflenet_second_config_model, shufflenet_train_dataset, shufflenet_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chv94dt4SMpK"
   },
   "source": [
    "## Статистика полученных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "OBUCkITEScwp",
    "outputId": "740424a8-7ce3-4d91-e96e-31b4a389f3cf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "for_gist = {\n",
    "    \"ResNet9\\n(Prac 1)\": 0.9073,\n",
    "    \"ResNet50\\nconfig 1\": resnet_first_config_test_acc.item(),\n",
    "    \"ResNet50\\nconfig 2\": resnet_second_config_test_acc.item(),\n",
    "    \"Swin_V2\\nconfig 1\": swin_first_config_test_acc.item(),\n",
    "    \"Swin_V2\\nconfig 2\": swin_second_config_test_acc.item(),\n",
    "    \"GoogLeNet\\nconfig 1\": googlenet_first_config_test_acc.item(),\n",
    "    \"GoogLeNet\\nconfig 2\": googlenet_second_config_test_acc.item(),\n",
    "    \"ShuffleNet_\\nV2_X2_0\\nconfig 1\": shufflenet_first_config_test_acc.item(),\n",
    "    \"ShuffleNet_\\nV2_X2_0\\nconfig 2\": shufflenet_second_config_test_acc.item(),\n",
    "}\n",
    "\n",
    "seaborn.set(rc={'figure.figsize': (15, 5)})\n",
    "\n",
    "ax = seaborn.barplot(x=list(for_gist.keys()), y=list(for_gist.values()))\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOJ14OZZSdcg"
   },
   "source": [
    "## Вывод лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amm0w1K9SjgO",
    "outputId": "b3354423-544d-452c-d36f-f24e665f4323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: ResNet9\n",
      "(Prac 1)\n",
      "Achived test accuracy: 0.9073\n",
      "Learning rate: 0.001\n",
      "Number of epochs: 4\n",
      "Batch size: 256\n",
      "Optimizer - Adam, params from fc layer\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(for_gist, key=lambda key: for_gist[key])\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Achived test accuracy: {for_gist[best_model_name]}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Number of epochs: {EPOCHS_NUMBER}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(\"Optimizer - Adam, params from fc layer\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "el6_PgEXS__N"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
