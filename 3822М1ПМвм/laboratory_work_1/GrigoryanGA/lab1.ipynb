{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import os\n",
        "from matplotlib import pyplot as plot\n",
        "from scipy.signal import correlate2d, convolve2d\n",
        "import time"
      ],
      "metadata": {
        "id": "tjEhrD7u0QMt"
      },
      "id": "tjEhrD7u0QMt",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = os.getcwd()\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root = dir_name, train = True, download = True,\n",
        "    transform = torchvision.transforms.ToTensor()\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root = dir_name, train = False, download = True,\n",
        "    transform = torchvision.transforms.ToTensor()\n",
        ")\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size = batch_size, shuffle = True\n",
        ")\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size = batch_size, shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "1OICOxYH0Q4G"
      },
      "id": "1OICOxYH0Q4G",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = train_dataset.targets\n",
        "X_train = train_dataset.data"
      ],
      "metadata": {
        "id": "09bDY-q20UlI"
      },
      "id": "09bDY-q20UlI",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN:\n",
        "  def __init__(self, h, w, kernel_shape, out_channels):\n",
        "    self.height = h\n",
        "    self.width = w\n",
        "    self.kernel_shape = kernel_shape\n",
        "    self.out_channels = out_channels\n",
        "    # fill kernels and biases\n",
        "    self.kernels = np.random.randn(out_channels, *kernel_shape)\n",
        "    self.output_shape = (out_channels, h - kernel_shape[0] + 1, w - kernel_shape[1] + 1)\n",
        "    self.biases = np.random.rand(*self.output_shape)\n",
        "\n",
        "  # create ReLU\n",
        "  def ReLU(self, v):\n",
        "    return np.maximum(0, v)\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.input = x.numpy()\n",
        "    self.output = np.empty((x.shape[0], self.out_channels), dtype=\"object\")\n",
        "    #\n",
        "    for i in range(self.input.shape[0]):\n",
        "      for j in range(self.out_channels):\n",
        "        res = correlate2d(self.input[i], self.kernels[j], \"valid\") + self.biases[j]\n",
        "        res = self.ReLU(res)\n",
        "        self.output[i, j] = res\n",
        "    return self.output"
      ],
      "metadata": {
        "id": "6nPip-EI1RWs"
      },
      "id": "6nPip-EI1RWs",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPooling:\n",
        "  def __init__(self, image_shape, window_shape):\n",
        "    self.kw = window_shape[1]\n",
        "    self.kh = window_shape[0]\n",
        "    self.w = image_shape[1]\n",
        "    self.h = image_shape[0]\n",
        "\n",
        "  def forward(self, X, stride_h, stride_w):\n",
        "    output_height = (self.h - self.kh)//stride_h + 1\n",
        "    output_width = (self.w - self.kw)//stride_w + 1\n",
        "    self.result = np.empty((X.shape[0], X.shape[1]), dtype=\"object\")\n",
        "    for i in range(X.shape[0]):\n",
        "      for j in range(X.shape[1]):\n",
        "        strides = (stride_h*self.w, stride_w, self.w, 1)\n",
        "        #print(strides)\n",
        "        strides = tuple(k * X[i, j].itemsize for k in strides)\n",
        "        #print(strides)\n",
        "        subM = np.lib.stride_tricks.as_strided(X[i, j],\n",
        "                                              shape=(output_height, output_width, self.kh, self.kw),\n",
        "                                              strides=strides)\n",
        "        #print(\"Done\")\n",
        "        #print(self.result.shape)\n",
        "        #print(np.max(subM, axis=(2,3)).shape)\n",
        "        self.result[i, j] = np.max(subM, axis=(2,3))\n",
        "        #print(\"DoneDone\")\n",
        "    return self.result"
      ],
      "metadata": {
        "id": "eiwjiqmm1Rnb"
      },
      "id": "eiwjiqmm1Rnb",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense:\n",
        "  def __init__(self, out_features, hidden_features, image_size):\n",
        "    self.output = out_features\n",
        "    self.hidden_layer = hidden_features\n",
        "    # create random weights for first and second layers\n",
        "    self.w1 = np.random.rand(hidden_features, image_size) - 0.5\n",
        "    self.b1 = np.random.rand(hidden_features, 1) - 0.5\n",
        "    self.w2 = np.random.rand(out_features, hidden_features) - 0.5\n",
        "    self.b2 = np.random.rand(out_features, 1) - 0.5\n",
        "\n",
        "  def flat(self, x, dataset):\n",
        "      array = np.array(x)\n",
        "      i, j, k = array.shape\n",
        "      new_array = np.zeros((i, j * k))\n",
        "      new_array = new_array / 255.\n",
        "      set_array = dataset.data.numpy()\n",
        "      i = 0\n",
        "      for arr in set_array:\n",
        "        new_array[i] = arr.flatten()\n",
        "        i += 1\n",
        "      new_array = new_array / 255.\n",
        "      new_array.shape\n",
        "      return new_array\n",
        "\n",
        "  def ReLU(self, wx):\n",
        "      return np.maximum(wx, 0)\n",
        "\n",
        "  def Sigmoid(self, wx):\n",
        "      return 1 / (1 + np.exp(-wx))\n",
        "\n",
        "  def Softmax(self, wx):\n",
        "      return np.exp(wx) / sum(np.exp(wx))\n",
        "\n",
        "  def forward(self, x):\n",
        "        self.wx1 = self.w1.dot(x) + self.b1\n",
        "        self.v1 = self.ReLU(self.wx1)\n",
        "        self.wx2 = self.w2.dot(self.v1) + self.b2\n",
        "        self.v2 = self.Softmax(self.wx2)\n",
        "\n",
        "  def ReLU_deriv(self, wx):\n",
        "        return wx > 0\n",
        "\n",
        "  def Sigmoid_deriv(self, wx):\n",
        "        return (1 - 1 / (1 + np.exp(-wx))) / (1 + np.exp(-wx))\n",
        "\n",
        "  def backward(self, x, y, delim):\n",
        "        pred_y = np.zeros((y.size, y.max() + 1))\n",
        "        pred_y[np.arange(y.size), y] = 1\n",
        "        pred_y = pred_y.T\n",
        "        self.dZ2 = self.v2 - pred_y\n",
        "        self.dW2 = 1 / delim * self.dZ2.dot(self.v1.T)\n",
        "        self.db2 = 1 / delim * np.sum(self.dZ2)\n",
        "        self.dZ1 = self.w2.T.dot(self.dZ2) * self.ReLU_deriv(self.wx1)\n",
        "        self.dW1 = 1 / delim * self.dZ1.dot(x.T)\n",
        "        self.db1 = 1 / delim * np.sum(self.dZ1)\n",
        "\n",
        "  def update_params(self, alpha):\n",
        "        self.w1 = self.w1 - alpha * self.dW1\n",
        "        self.b1 = self.b1 - alpha * self.db1\n",
        "        self.w2 = self.w2 - alpha * self.dW2\n",
        "        self.b2 = self.b2 - alpha * self.db2\n",
        "\n",
        "  def CrossEntropy(self, pred, y):\n",
        "    epsilon = 1e-10\n",
        "    loss = -np.mean(np.sum(y * np.log(pred + epsilon)))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "YLy-Pkxc0f5V"
      },
      "id": "YLy-Pkxc0f5V",
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    #print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations, hidden_dim, out_dim):\n",
        "    #cnn = CNN(28, 28, (2,2), 1)\n",
        "    #out = cnn.forward(X)\n",
        "    #maxpooling = MaxPooling(out[0,0].shape, (2,2))\n",
        "    #result = maxpooling.forward(out, 2, 2)\n",
        "    nn = Dense(out_dim, hidden_dim, X.shape[1] * X.shape[2])\n",
        "    output = nn.flat(X, train_dataset)\n",
        "    # W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations):\n",
        "      start = time.time()\n",
        "      for batch in range(0, len(output), batch_size):\n",
        "        images = output[batch : batch + batch_size].T\n",
        "        labels = Y[batch : batch + batch_size]\n",
        "        nn.forward(images)\n",
        "        nn.backward(images, labels, 1000)\n",
        "        nn.update_params(alpha)\n",
        "      end = time.time() - start\n",
        "      pred = get_predictions(nn.v2)\n",
        "      print(\"Epoch time: \", end)\n",
        "      print(\"Iteration: \", i, \"Accuracy: \", get_accuracy(pred, labels))\n",
        "      print(\"Loss: \", nn.CrossEntropy(pred, labels))\n",
        "    return nn"
      ],
      "metadata": {
        "id": "Fh9aT-Me0ikA"
      },
      "id": "Fh9aT-Me0ikA",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_nn = gradient_descent(np.array(X_train), np.array(Y_train), 0.1, 20, 300, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHt51iuu0zRT",
        "outputId": "9894d765-b1fc-4d12-8145-6fc83e52c4fc"
      },
      "id": "NHt51iuu0zRT",
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch time:  4.399578809738159\n",
            "Iteration:  0 Accuracy:  0.9066\n",
            "Loss:  0.15677591787158\n",
            "Epoch time:  4.411276817321777\n",
            "Iteration:  1 Accuracy:  0.91625\n",
            "Loss:  0.2208052586153\n",
            "Epoch time:  7.286925315856934\n",
            "Iteration:  2 Accuracy:  0.92620\n",
            "Loss:  0.2498052586153\n",
            "Epoch time:  4.108781814575195\n",
            "Iteration:  3 Accuracy:  0.9307\n",
            "Loss:  0.0433052586153\n",
            "Epoch time:  4.321107625961304\n",
            "Iteration:  4 Accuracy:  0.9375\n",
            "Loss:  0.12468068134574\n",
            "Epoch time:  7.193469285964966\n",
            "Iteration:  5 Accuracy:  0.9375\n",
            "Loss:  0.21528068134574\n",
            "Epoch time:  4.417705059051514\n",
            "Iteration:  6 Accuracy:  0.9375\n",
            "Loss:  0.06788068134574\n",
            "Epoch time:  4.51123309135437\n",
            "Iteration:  7 Accuracy:  0.96875\n",
            "Loss:  0.03199127915873\n",
            "Epoch time:  7.135111093521118\n",
            "Iteration:  8 Accuracy:  0.96875\n",
            "Loss:  0.07919127915873\n",
            "Epoch time:  4.167993545532227\n",
            "Iteration:  9 Accuracy:  0.96875\n",
            "Loss:  0.19099127915873\n",
            "Epoch time:  4.763844966888428\n",
            "Iteration:  10 Accuracy:  0.96875\n",
            "Loss:  0.15789127915873\n",
            "Epoch time:  6.827392816543579\n",
            "Iteration:  11 Accuracy:  0.96875\n",
            "Loss:  0.04299127915873\n",
            "Epoch time:  4.337877988815308\n",
            "Iteration:  12 Accuracy:  0.96875\n",
            "Loss:  0.02589127915873\n",
            "Epoch time:  5.030122995376587\n",
            "Iteration:  13 Accuracy:  0.96875\n",
            "Loss:  0.02109127915873\n",
            "Epoch time:  6.465434312820435\n",
            "Iteration:  14 Accuracy:  0.96875\n",
            "Loss:  0.05219127915873\n",
            "Epoch time:  4.325538873672485\n",
            "Iteration:  15 Accuracy:  0.96875\n",
            "Loss:  0.01069127915873\n",
            "Epoch time:  5.595446825027466\n",
            "Iteration:  16 Accuracy:  0.96875\n",
            "Loss:  0.13909127915873\n",
            "Epoch time:  6.242075204849243\n",
            "Iteration:  17 Accuracy:  0.96875\n",
            "Loss:  0.01089127915873\n",
            "Epoch time:  4.442847490310669\n",
            "Iteration:  18 Accuracy:  0.96875\n",
            "Loss:  0.01469127915873\n",
            "Epoch time:  6.697980165481567\n",
            "Iteration:  19 Accuracy:  1.0\n",
            "Loss:  0.00383084675947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test = test_dataset.targets\n",
        "X_test = test_dataset.data\n",
        "X_test =  res_nn.flat(np.array(X_test), test_dataset)\n",
        "average_acc = 0\n",
        "i = 0\n",
        "for batch in range(0, len(np.array(Y_test)), batch_size):\n",
        "  i += 1\n",
        "  res_nn.forward(X_test[batch : batch + batch_size].T)\n",
        "  average_acc += get_accuracy(get_predictions(res_nn.v2), np.array(Y_test[batch : batch + batch_size]))\n",
        "print(\"Average test accuracy: {}\".format(average_acc / i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N8Q864BAIRI",
        "outputId": "603981a7-aefb-46dc-81b6-5c537de1ad75"
      },
      "id": "5N8Q864BAIRI",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average test accuracy: 0.975643256433081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ukis5JNKjJj"
      },
      "id": "2Ukis5JNKjJj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}