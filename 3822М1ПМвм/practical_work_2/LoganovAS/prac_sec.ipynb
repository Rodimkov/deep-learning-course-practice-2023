{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a998ebb",
      "metadata": {
        "id": "0a998ebb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms\n",
        "import torch.utils.data\n",
        "import torch.nn\n",
        "import os\n",
        "from matplotlib import pyplot as plot\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "804c76ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "804c76ee",
        "outputId": "9f53fa9c-4e15-41a4-9179-abf7b7fd3a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(f'Device: {torch.cuda.get_device_name(device)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3527e80a",
      "metadata": {
        "id": "3527e80a"
      },
      "outputs": [],
      "source": [
        "lrate = 0.001\n",
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "dir_name = os.getcwd()\n",
        "res_names = []\n",
        "res_valuse = []\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "cftransforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bf413ac1",
      "metadata": {
        "id": "bf413ac1"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    tp = 0\n",
        "    n = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            labels, images = labels.to(device), images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            n += labels.size(0)\n",
        "            tp += (predicted == labels).sum()\n",
        "    return tp / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6954a0bb",
      "metadata": {
        "id": "6954a0bb"
      },
      "outputs": [],
      "source": [
        "class Worker():\n",
        "    def __init__(self, name_of_model, weights_of_model, transforms):\n",
        "        self.name = name_of_model\n",
        "        self.weights = weights_of_model\n",
        "        train_dataset = torchvision.datasets.CIFAR10( root = dir_name, train = True,\n",
        "        download = True, transform = transforms ) # fix\n",
        "        test_dataset = torchvision.datasets.CIFAR10( root = dir_name, train = False,\n",
        "        download = True, transform = transforms ) # fix\n",
        "        self.train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size = batch_size, shuffle = True )\n",
        "        self.test_data_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size = batch_size, shuffle = False )\n",
        "        self.model = getattr(torchvision.models, name_of_model)(weights=weights_of_model)\n",
        "\n",
        "    def train_and_test(self, optimizer, loss_function):\n",
        "        self.model = self.model.to(device)\n",
        "        tg0 = time.time()\n",
        "        for epoch in range(num_epochs):\n",
        "            t0 = time.time()\n",
        "            for images, labels in self.train_data_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                new_m = self.model(images)\n",
        "                loss = loss_function(new_m, labels)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            t1 = time.time()\n",
        "            print(f'Epoch[{epoch}]: acc = {get_accuracy(self.model, self.train_data_loader)}, time = {t1 - t0}')\n",
        "        tg1 = time.time()\n",
        "        print(\"Time: \", {tg1-tg0});\n",
        "        acc = get_accuracy(self.model, self.test_data_loader)\n",
        "        res_names.append(self.name)\n",
        "        res_valuse.append(acc)\n",
        "        print('Test acc: {}'.format(acc))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "236e6c57",
      "metadata": {
        "id": "236e6c57"
      },
      "outputs": [],
      "source": [
        "def start_one(wrk):\n",
        "    print(wrk.name)\n",
        "    for prm_of_model in wrk.model.parameters():\n",
        "        prm_of_model.requires_grad = False\n",
        "    if wrk.name == \"resnet18\" or wrk.name == \"googlenet\" or wrk.name == \"resnet50\":\n",
        "        features_count = wrk.model.fc.in_features\n",
        "        wrk.model.fc = torch.nn.Linear(features_count, 10)\n",
        "        optimizer = torch.optim.Adam(wrk.model.fc.parameters(), lr=lrate)\n",
        "        wrk.train_and_test( optimizer, loss_function )\n",
        "    if wrk.name == \"mobilenet_v3_small\":\n",
        "        features_count = wrk.model.classifier[-1].in_features\n",
        "        wrk.model.classifier[-1] = torch.nn.Linear(features_count, 10)\n",
        "        optimizer = torch.optim.Adam(wrk.model.classifier[-1].parameters(), lr=lrate)\n",
        "        wrk.train_and_test( optimizer, loss_function )\n",
        "    if wrk.name == \"vit_b_16\":\n",
        "        features_count = wrk.model.heads[0].in_features\n",
        "        wrk.model.heads = torch.nn.Linear(features_count, 10)\n",
        "        print(features_count)\n",
        "        optimizer = torch.optim.Adam(wrk.model.heads.parameters(), lr=lrate)\n",
        "        wrk.train_and_test( optimizer, loss_function )\n",
        "\n",
        "    print(wrk.model)\n",
        "def start_two(wrk):\n",
        "    print(wrk.name)\n",
        "    for prm_of_model in wrk.model.parameters():\n",
        "        prm_of_model.requires_grad = False\n",
        "    if wrk.name == \"resnet18\" or wrk.name == \"resnet50\":\n",
        "        features_count = wrk.model.fc.in_features\n",
        "        wrk.model.fc = torch.nn.Sequential(\n",
        "        torch.nn.Linear(features_count, features_count//2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(features_count//2, 10),\n",
        "        )\n",
        "        print(features_count)\n",
        "        optimizer = torch.optim.Adam(wrk.model.fc.parameters(), lr=lrate)\n",
        "        wrk.train_and_test( optimizer, loss_function )\n",
        "    if wrk.name == \"mobilenet_v3_small\":\n",
        "        features_count = wrk.model.classifier[-1].in_features\n",
        "        wrk.model.classifier[-1] = torch.nn.Sequential(\n",
        "        torch.nn.Linear(features_count, features_count//2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(features_count//2, 10),\n",
        "        )\n",
        "        print(features_count)\n",
        "        optimizer = torch.optim.Adam(wrk.model.fc.parameters(), lr=lrate)\n",
        "        wrk.train_and_test( optimizer, loss_function )\n",
        "    if wrk.name == \"vit_b_16\":\n",
        "        features_count = wrk.model.heads[0].in_features\n",
        "        wrk.model.heads = torch.nn.Sequential(\n",
        "        torch.nn.Linear(features_count, features_count//2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(features_count//2, 10),\n",
        "        )\n",
        "        print(features_count)\n",
        "        optimizer = torch.optim.Adam(wrk.model.heads.parameters(), lr=lrate)\n",
        "        wrk.train_and_test( optimizer, loss_function )\n",
        "    print(wrk.model)\n",
        "def start_three(wrk):\n",
        "    print(wrk.name)\n",
        "    optimizer = torch.optim.Adam(wrk.model.parameters(), lr=lrate)\n",
        "    wrk.train_and_test( optimizer, loss_function )\n",
        "    print(wrk.model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca02990",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ca02990",
        "outputId": "2f554df4-99bd-4862-9169-7ee2c9c31671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "resnet18\n",
            "512\n",
            "Epoch[0]: acc = 0.7708199620246887, time = 138.37115120887756\n",
            "Epoch[1]: acc = 0.7821199893951416, time = 138.09055924415588\n",
            "Epoch[2]: acc = 0.7829399704933167, time = 134.9507396221161\n",
            "Epoch[3]: acc = 0.7817599773406982, time = 136.34877252578735\n",
            "Epoch[4]: acc = 0.7989599704742432, time = 140.91054368019104\n",
            "Time:  {1370.4095239639282}\n",
            "Test acc: 0.7795999646186829\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "resnet18\n",
            "Epoch[0]: acc = 0.754859983921051, time = 133.52695989608765\n",
            "Epoch[1]: acc = 0.7739599943161011, time = 138.5334987640381\n",
            "Epoch[2]: acc = 0.7757599949836731, time = 134.6009862422943\n",
            "Epoch[3]: acc = 0.7848599553108215, time = 134.48463773727417\n",
            "Epoch[4]: acc = 0.7870599627494812, time = 136.7384696006775\n",
            "Time:  {1355.515950202942}\n",
            "Test acc: 0.7781999707221985\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "[tensor(0.7796, device='cuda:0'), tensor(0.7782, device='cuda:0')]\n",
            "resnet18_one\n",
            "resnet18_deep\n"
          ]
        }
      ],
      "source": [
        "worker_resnet18 = Worker(\"resnet18\", \"ResNet18_Weights.IMAGENET1K_V1\", torchvision.models.ResNet18_Weights.IMAGENET1K_V1.transforms())\n",
        "start_two(worker_resnet18)\n",
        "worker_resnet18_sec = Worker(\"resnet18\", \"ResNet18_Weights.IMAGENET1K_V1\", torchvision.models.ResNet18_Weights.IMAGENET1K_V1.transforms())\n",
        "start_one(worker_resnet18_sec)\n",
        "print(res_valuse)\n",
        "print(res_names[0]+\"_one\")\n",
        "print(res_names[1]+\"_deep\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ba5e15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07ba5e15",
        "outputId": "d80c549c-f10c-402b-b11e-22d9062839e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 63.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mobilenet_v3_small\n",
            "Epoch[0]: acc = 0.8077999949455261, time = 137.06814861297607\n",
            "Epoch[1]: acc = 0.8209199905395508, time = 139.84806442260742\n",
            "Epoch[2]: acc = 0.8269000053405762, time = 139.56226706504822\n",
            "Epoch[3]: acc = 0.8294199705123901, time = 136.40933632850647\n",
            "Epoch[4]: acc = 0.8319999575614929, time = 137.88065886497498\n",
            "Time:  {1376.224886417389}\n",
            "Test acc: 0.8111000061035156\n",
            "MobileNetV3(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
            "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
            "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (12): Conv2dNormActivation(\n",
            "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
            "    (1): Hardswish()\n",
            "    (2): Dropout(p=0.2, inplace=True)\n",
            "    (3): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "mobilenet_v3_small\n",
            "Epoch[0]: acc = 0.5064399838447571, time = 22.145615100860596\n",
            "Epoch[1]: acc = 0.5719199776649475, time = 22.305394887924194\n",
            "Epoch[2]: acc = 0.6287800073623657, time = 21.259592533111572\n",
            "Epoch[3]: acc = 0.6683200001716614, time = 20.641916751861572\n",
            "Epoch[4]: acc = 0.7028200030326843, time = 21.072794675827026\n",
            "Time:  {187.98984098434448}\n",
            "Test acc: 0.6317999958992004\n",
            "MobileNetV3(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
            "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
            "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (12): Conv2dNormActivation(\n",
            "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
            "    (1): Hardswish()\n",
            "    (2): Dropout(p=0.2, inplace=True)\n",
            "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "[tensor(0.7796, device='cuda:0'), tensor(0.7782, device='cuda:0'), tensor(0.8111, device='cuda:0'), tensor(0.6318, device='cuda:0')]\n",
            "mobilenet_v3_small_one\n",
            "mobilenet_v3_small_full\n"
          ]
        }
      ],
      "source": [
        "worker_mibilenet = Worker(\"mobilenet_v3_small\", \"MobileNet_V3_Small_Weights.IMAGENET1K_V1\", torchvision.models.MobileNet_V3_Small_Weights.IMAGENET1K_V1.transforms())\n",
        "start_one(worker_mibilenet)\n",
        "worker_mibilenet_sec = Worker(\"mobilenet_v3_small\", \"MobileNet_V3_Small_Weights.IMAGENET1K_V1\", cftransforms)\n",
        "start_three(worker_mibilenet_sec)\n",
        "print(res_valuse)\n",
        "print(res_names[2]+\"_one\")\n",
        "print(res_names[3]+\"_full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2bfbea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e2bfbea",
        "outputId": "d32a666e-ecf9-42ea-ae51-9ce1ae5e41a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 90.4MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "googlenet\n",
            "Epoch[0]: acc = 0.7420799732208252, time = 140.03120279312134\n",
            "Epoch[1]: acc = 0.751039981842041, time = 137.8761785030365\n",
            "Epoch[2]: acc = 0.7638999819755554, time = 142.07433891296387\n",
            "Epoch[3]: acc = 0.7675399780273438, time = 138.9849669933319\n",
            "Epoch[4]: acc = 0.7731599807739258, time = 138.4294171333313\n",
            "Time:  {1392.5280103683472}\n",
            "Test acc: 0.7547999620437622\n",
            "GoogLeNet(\n",
            "  (conv1): BasicConv2d(\n",
            "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (conv2): BasicConv2d(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): BasicConv2d(\n",
            "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception3a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception3b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception4a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4c): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4d): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4e): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception5a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception5b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (aux1): None\n",
            "  (aux2): None\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "googlenet\n",
            "Epoch[0]: acc = 0.8039000034332275, time = 24.573229551315308\n",
            "Epoch[1]: acc = 0.8549000024795532, time = 26.817800521850586\n",
            "Epoch[2]: acc = 0.8877399563789368, time = 27.128965377807617\n",
            "Epoch[3]: acc = 0.9090999960899353, time = 25.600598573684692\n",
            "Epoch[4]: acc = 0.9327399730682373, time = 24.9470796585083\n",
            "Time:  {219.58842253684998}\n",
            "Test acc: 0.8114999532699585\n",
            "GoogLeNet(\n",
            "  (conv1): BasicConv2d(\n",
            "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (conv2): BasicConv2d(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): BasicConv2d(\n",
            "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception3a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception3b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception4a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4c): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4d): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4e): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception5a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception5b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (aux1): None\n",
            "  (aux2): None\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n",
            "[tensor(0.7796, device='cuda:0'), tensor(0.7782, device='cuda:0'), tensor(0.8111, device='cuda:0'), tensor(0.6318, device='cuda:0'), tensor(0.7548, device='cuda:0'), tensor(0.8115, device='cuda:0')]\n",
            "googlenet_one\n",
            "googlenet_full\n"
          ]
        }
      ],
      "source": [
        "worker_googlenet = Worker(\"googlenet\",\"GoogLeNet_Weights.IMAGENET1K_V1\",torchvision.models.GoogLeNet_Weights.IMAGENET1K_V1.transforms())\n",
        "start_one(worker_googlenet)\n",
        "worker_googlenet_sec = Worker(\"googlenet\", \"GoogLeNet_Weights.IMAGENET1K_V1\", cftransforms)\n",
        "start_three(worker_googlenet_sec)\n",
        "print(res_valuse)\n",
        "print(res_names[4]+\"_one\")\n",
        "print(res_names[5]+\"_full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2cc4d7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2cc4d7d",
        "outputId": "9a96326e-9826-49f4-8576-9f95b8ae6c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 147MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resnet50\n",
            "Epoch[0]: acc = 0.7817800045013428, time = 167.220764875412\n",
            "Epoch[1]: acc = 0.8096199631690979, time = 167.70978307724\n",
            "Epoch[2]: acc = 0.8217200040817261, time = 168.1025915145874\n",
            "Epoch[3]: acc = 0.8294599652290344, time = 169.13328409194946\n",
            "Epoch[4]: acc = 0.8393200039863586, time = 167.88271689414978\n",
            "Time:  {1681.0802376270294}\n",
            "Test acc: 0.8071999549865723\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "resnet50\n",
            "2048\n",
            "Epoch[0]: acc = 0.8240599632263184, time = 167.8517768383026\n",
            "Epoch[1]: acc = 0.8457599878311157, time = 166.76351380348206\n",
            "Epoch[2]: acc = 0.8477999567985535, time = 168.96933007240295\n",
            "Epoch[3]: acc = 0.8723399639129639, time = 166.80960154533386\n",
            "Epoch[4]: acc = 0.8896799683570862, time = 167.28989553451538\n",
            "Time:  {1675.2298941612244}\n",
            "Test acc: 0.8036999702453613\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "[tensor(0.7796, device='cuda:0'), tensor(0.7782, device='cuda:0'), tensor(0.8111, device='cuda:0'), tensor(0.6318, device='cuda:0'), tensor(0.7548, device='cuda:0'), tensor(0.8115, device='cuda:0'), tensor(0.8072, device='cuda:0'), tensor(0.8037, device='cuda:0')]\n",
            "mobilenet_v3_small_one\n",
            "mobilenet_v3_small_deep\n"
          ]
        }
      ],
      "source": [
        "worker_resnet50 = Worker(\"resnet50\", \"ResNet50_Weights.IMAGENET1K_V2\", torchvision.models.ResNet50_Weights.IMAGENET1K_V2.transforms())\n",
        "start_one(worker_resnet50)\n",
        "worker_resnet50_sec = Worker(\"resnet50\", \"ResNet50_Weights.IMAGENET1K_V2\", torchvision.models.ResNet50_Weights.IMAGENET1K_V2.transforms())\n",
        "start_two(worker_resnet50_sec)\n",
        "print(res_valuse)\n",
        "print(res_names[2]+\"_one\")\n",
        "print(res_names[3]+\"_deep\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "921a6051",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "921a6051",
        "outputId": "0f476936-7859-46af-fc62-75ce5d9f78a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BarContainer object of 8 artists>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2400x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plot\n",
        "result_names = [\"resnet18_deep\", \"resnet18_one\",\"mobilenet_v3_small_one\",\"mobilenet_v3_small_full\", \"googlenet_one\", \"googlenet_full\",\"resnet50_one\",\"resnet50_deep\" ]\n",
        "result_values = [0.7796, 0.7782, 0.8111, 0.6318, 0.7548, 0.8115, 0.8072, 0.8037]\n",
        "plot.figure(figsize = (24, 10))\n",
        "plot.bar(result_names, result_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "02e678e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02e678e7",
        "outputId": "749ea7b3-be92-440f-cd81-7625a62eff74"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13278006.53it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/cifar-10-python.tar.gz to /content\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:05<00:00, 65.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vit_b_16\n",
            "768\n",
            "Epoch[0]: acc = 0.9603999853134155, time = 592.4060637950897\n",
            "Epoch[1]: acc = 0.9706199765205383, time = 592.0329320430756\n",
            "Epoch[2]: acc = 0.9794999957084656, time = 591.5894939899445\n",
            "Epoch[3]: acc = 0.9865599870681763, time = 591.6757760047913\n",
            "Epoch[4]: acc = 0.987339973449707, time = 590.2111518383026\n",
            "Time:  {5924.538775444031}\n",
            "Test acc: 0.9505999684333801\n",
            "VisionTransformer(\n",
            "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "  (encoder): Encoder(\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): Sequential(\n",
            "      (encoder_layer_0): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_1): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_2): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_3): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_4): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_5): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_6): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_7): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_8): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_9): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_10): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_11): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (heads): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=384, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "worker_vit = Worker(\"vit_b_16\", \"ViT_B_16_Weights.DEFAULT\", torchvision.models.ViT_B_16_Weights.DEFAULT.transforms())\n",
        "start_two(worker_vit)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "worker_vit_sec = Worker(\"vit_b_16\", \"ViT_B_16_Weights.DEFAULT\", torchvision.models.ViT_B_16_Weights.DEFAULT.transforms())\n",
        "start_one(worker_vit_sec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GjUJ7QNKigq",
        "outputId": "f04b80b5-51f2-4f8b-d31d-2a6b6eb2d212"
      },
      "id": "2GjUJ7QNKigq",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "vit_b_16\n",
            "768\n",
            "Epoch[0]: acc = 0.9480199813842773, time = 590.2733819484711\n",
            "Epoch[1]: acc = 0.9548199772834778, time = 588.7941012382507\n",
            "Epoch[2]: acc = 0.9598599672317505, time = 590.2820425033569\n",
            "Epoch[3]: acc = 0.9627400040626526, time = 591.1582546234131\n",
            "Epoch[4]: acc = 0.9645799994468689, time = 590.2547073364258\n",
            "Time:  {5911.526317358017}\n",
            "Test acc: 0.9490000009536743\n",
            "VisionTransformer(\n",
            "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "  (encoder): Encoder(\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): Sequential(\n",
            "      (encoder_layer_0): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_1): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_2): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_3): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_4): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_5): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_6): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_7): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_8): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_9): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_10): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (encoder_layer_11): EncoderBlock(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (self_attention): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): MLPBlock(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (heads): Linear(in_features=768, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plot\n",
        "result_names = [\"resnet18_deep\", \"resnet18_one\",\"mobilenet_v3_small_one\",\"mobilenet_v3_small_full\", \"googlenet_one\", \"googlenet_full\", \"resnet50_one\", \"resnet50_deep\", \"vit_b_16_deep\", \"vit_b_16_one\" ]\n",
        "result_values = [0.7796, 0.7782, 0.8111, 0.6318, 0.7548, 0.8115, 0.8072, 0.8037, 0.95059, 0.9490]\n",
        "plot.figure(figsize = (24, 10))\n",
        "plot.bar(result_names, result_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "dXX1Eg3KKirF",
        "outputId": "1d9290a3-1c02-4628-ead6-1c50031e182c"
      },
      "id": "dXX1Eg3KKirF",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}