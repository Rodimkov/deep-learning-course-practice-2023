<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>87183a656960471b99d428bb8a2d1a0d</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="36215ee6" class="cell code" data-execution_count="3"
id="36215ee6">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.init <span class="im">as</span> init</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> functional <span class="im">as</span> F</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models <span class="im">as</span> models</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> Resize, Normalize, ToTensor, Compose, RandomHorizontalFlip</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> CIFAR10</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchsummary <span class="im">import</span> summary</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tabulate <span class="im">import</span> tabulate</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> clear_output</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> urllib.parse <span class="im">import</span> urlencode</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lion_pytorch <span class="im">import</span> Lion</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> lr_scheduler</span></code></pre></div>
</div>
<div id="4054f3e8" class="cell markdown" id="4054f3e8">
<h3 id="загрузка-данных">Загрузка данных.</h3>
</div>
<div id="160a84e9" class="cell code" id="160a84e9"
data-outputId="d7a664d5-1f08-4393-d070-794d54a88cd9">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified
</code></pre>
</div>
</div>
<div id="e7e38543" class="cell code" id="e7e38543"
data-outputId="87c1df00-a37f-4cab-95af-b6d83855a297">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Размер обучающей выборки: </span><span class="sc">{</span><span class="bu">len</span>(train_dataset)<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Размер тестовой выборки: </span><span class="sc">{</span><span class="bu">len</span>(test_dataset)<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Классы:&#39;</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tabulate(</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">list</span>(train_dataset.class_to_idx.items()), headers<span class="op">=</span>[<span class="st">&#39;Название&#39;</span>, <span class="st">&#39;Индекс&#39;</span>],</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    tablefmt<span class="op">=</span><span class="st">&#39;pretty&#39;</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Размер обучающей выборки: 50000
Размер тестовой выборки: 10000

Классы:
+------------+--------+
|  Название  | Индекс |
+------------+--------+
|  airplane  |   0    |
| automobile |   1    |
|    bird    |   2    |
|    cat     |   3    |
|    deer    |   4    |
|    dog     |   5    |
|    frog    |   6    |
|   horse    |   7    |
|    ship    |   8    |
|   truck    |   9    |
+------------+--------+
</code></pre>
</div>
</div>
<div id="403a8e9e" class="cell code" id="403a8e9e"
data-outputId="23d1c4c3-b646-4aca-ce44-c851100fbd6a">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>index_to_label <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> train_dataset.class_to_idx.items()}</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>class_labels_train <span class="op">=</span> [index_to_label[idx] <span class="cf">for</span> idx <span class="kw">in</span> train_dataset.targets]</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>unique_labels_train <span class="op">=</span> <span class="bu">list</span>(index_to_label.values())</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span>class_labels_train, order<span class="op">=</span>unique_labels_train)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Распределение классов в обучающей выборке&#39;</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>class_labels_test <span class="op">=</span> [index_to_label[idx] <span class="cf">for</span> idx <span class="kw">in</span> test_dataset.targets]</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>unique_labels_test <span class="op">=</span> <span class="bu">list</span>(index_to_label.values())</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span>class_labels_test, order<span class="op">=</span>unique_labels_test)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Распределение классов в тестовой выборке&#39;</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/ee6e8d3ed325b4665ad4e1ea4287210d8a43c554.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/345c46b022b571d3ac3ddf52025d8c6cd7fe2b50.png" /></p>
</div>
</div>
<div id="dd290573" class="cell code" id="dd290573"
data-outputId="e5e7b367-3838-4947-b846-1894f2004f10">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> test_dataset.classes</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_images(images, labels):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        plt.title(class_names[labels[i]])</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        plt.imshow(np.clip(np.transpose(images[i], (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)), <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>data_iter <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>images, labels <span class="op">=</span> <span class="bu">next</span>(data_iter)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>show_images(images, labels)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/4e8080655f0fa31a951db90b5c4e6b0301705a71.png" /></p>
</div>
</div>
<div id="6b8be3b3" class="cell markdown" id="6b8be3b3">
<p><strong>Вывод</strong>:</p>
<ol>
<li>Мы имеем 50 000 в обучающей выборки и 10 000 в тестовой</li>
<li>В каждом классе одинаковое количество классов, дисбаланса не
наблюдается</li>
<li>Изображения полностью соответствуют меткам класса</li>
</ol>
</div>
<div id="e5b3be49" class="cell markdown" id="e5b3be49">
<h3 id="построение-архитектуры-сверточной-сети">Построение архитектуры
сверточной сети.</h3>
<h4
id="требуется-вывести-информацию-об-архитектуре-опционально-выполнить-визуализацию-сети">Требуется
вывести информацию об архитектуре, опционально выполнить визуализацию
сети.</h4>
</div>
<div id="0fed2e8e" class="cell code" id="0fed2e8e"
data-outputId="7d79e526-35ec-431d-c83e-9d517f8501e0">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="dv">224</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>height <span class="op">=</span> <span class="dv">224</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([Resize((width,height)),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>                                transforms.ToTensor()])</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>cifar10_train <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&quot;./data&quot;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(cifar10_train, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>total_samples <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data, _ <span class="kw">in</span> train_loader:</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    batch_samples <span class="op">=</span> data.size(<span class="dv">0</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.view(batch_samples, data.size(<span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">+=</span> data.mean(<span class="dv">2</span>).<span class="bu">sum</span>(<span class="dv">0</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    std <span class="op">+=</span> data.std(<span class="dv">2</span>).<span class="bu">sum</span>(<span class="dv">0</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    total_samples <span class="op">+=</span> batch_samples</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>mean <span class="op">/=</span> total_samples</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>std <span class="op">/=</span> total_samples</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Mean:&quot;</span>, mean.tolist())</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Std:&quot;</span>, std.tolist())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Files already downloaded and verified
Mean: [0.4913995563983917, 0.48215848207473755, 0.44653093814849854]
Std: [0.19525285065174103, 0.19247294962406158, 0.1941993534564972]
</code></pre>
</div>
</div>
<div id="6d6e8da5" class="cell code" id="6d6e8da5"
data-outputId="78502157-6192-4143-a142-22885b61e894">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>train_transform <span class="op">=</span> transforms.Compose(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        Resize((width,height)),</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        transforms.RandomHorizontalFlip(),</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        transforms.RandomRotation(degrees<span class="op">=</span><span class="dv">15</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(mean, std)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>test_transform <span class="op">=</span> torchvision.transforms.Compose(</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        Resize((width,height)),</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(mean, std)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>train_transform)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>test_transform)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified
</code></pre>
</div>
</div>
<div id="c90d2a8e" class="cell code" id="c90d2a8e">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomEarlyStopping():</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, patience<span class="op">=</span><span class="dv">5</span>, min_delta<span class="op">=</span><span class="dv">0</span>, path<span class="op">=</span><span class="st">&quot;best_model.pt&quot;</span>, path_model<span class="op">=</span><span class="st">&quot;best_model&quot;</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.patience <span class="op">=</span> patience</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.min_delta <span class="op">=</span> min_delta</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.best_accuracy <span class="op">=</span> <span class="va">None</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.early_stop <span class="op">=</span> <span class="va">False</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path <span class="op">=</span> path</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path_model <span class="op">=</span> path_model</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, test_accuracy, model, optimizer):</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.best_accuracy <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_accuracy <span class="op">=</span> test_accuracy</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>            torch.save({</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;model_state_dict&#39;</span>: model.state_dict(),</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;optimizer_state_dict&#39;</span>: optimizer.state_dict(),</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;best_accuracy&#39;</span>: test_accuracy,}, <span class="va">self</span>.path)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>            torch.save(model, <span class="va">self</span>.path_model)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> test_accuracy <span class="op">-</span> <span class="va">self</span>.best_accuracy <span class="op">&gt;</span> <span class="va">self</span>.min_delta:</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_accuracy <span class="op">=</span> test_accuracy</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> os.path.exists(<span class="va">self</span>.path):</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>                checkpoint <span class="op">=</span> torch.load(<span class="va">self</span>.path)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> test_accuracy <span class="op">&gt;</span> checkpoint[<span class="st">&#39;best_accuracy&#39;</span>]:</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>                    torch.save({</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;model_state_dict&#39;</span>: model.state_dict(),</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;optimizer_state_dict&#39;</span>: optimizer.state_dict(),</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;best_accuracy&#39;</span>: test_accuracy,</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>                    }, <span class="va">self</span>.path)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>                    torch.save(model, <span class="va">self</span>.path_model)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>                torch.save({</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;model_state_dict&#39;</span>: model.state_dict(),</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;optimizer_state_dict&#39;</span>: optimizer.state_dict(),</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;best_accuracy&#39;</span>: test_accuracy,</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>                }, <span class="va">self</span>.path)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>                torch.save(model, <span class="va">self</span>.path_model)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> test_accuracy <span class="op">-</span> <span class="va">self</span>.best_accuracy <span class="op">&lt;</span> <span class="va">self</span>.min_delta:</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;INFO: Early stopping counter </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>counter<span class="sc">}</span><span class="ss"> of </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>patience<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Best accuracy </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>best_accuracy<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.counter <span class="op">&gt;=</span> <span class="va">self</span>.patience:</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&#39;INFO: Early stopping&#39;</span>)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.early_stop <span class="op">=</span> <span class="va">True</span></span></code></pre></div>
</div>
<div id="11c513e0" class="cell code" id="11c513e0">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ClassificationTrainer:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model: nn.Module, name_optimizer: <span class="bu">str</span>, scheduler: <span class="bu">bool</span>, train_dataset: Dataset,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                 test_dataset: Dataset, batch_size:<span class="bu">int</span>, learning_rate: <span class="bu">float</span>, num_epochs: <span class="bu">int</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>                 coef<span class="op">=</span><span class="fl">0.85</span>, step_size<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size, num_workers<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_epochs <span class="op">=</span> num_epochs</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> name_optimizer <span class="op">==</span> <span class="st">&#39;Lion&#39;</span>:</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer <span class="op">=</span> Lion(<span class="va">self</span>.model.parameters(), lr<span class="op">=</span>learning_rate, weight_decay<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> name_optimizer <span class="op">==</span> <span class="st">&#39;AdamW&#39;</span>:</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer <span class="op">=</span> optim.AdamW(<span class="va">self</span>.model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">NotImplementedError</span>()</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> scheduler:</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scheduler <span class="op">=</span> lr_scheduler.StepLR(<span class="va">self</span>.optimizer, step_size<span class="op">=</span>step_size, gamma<span class="op">=</span>coef)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scheduler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> torch.device(<span class="st">&quot;cuda:0&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path <span class="op">=</span> <span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.model).<span class="va">__name__</span>) <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.optimizer).<span class="va">__name__</span>) <span class="op">+</span> <span class="st">&quot;.pt&quot;</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path_model <span class="op">=</span><span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.model).<span class="va">__name__</span>) <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.optimizer).<span class="va">__name__</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.losses <span class="op">=</span> {<span class="st">&#39;train&#39;</span>: [], <span class="st">&#39;test&#39;</span>: []}</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.accuracies <span class="op">=</span> {<span class="st">&#39;train&#39;</span>: [], <span class="st">&#39;test&#39;</span>: []}</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time <span class="op">=</span> []</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_one_epoch(<span class="va">self</span>):</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.to(<span class="va">self</span>.device).train()</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>        epoch_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        epoch_start_time <span class="op">=</span> time.time()</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> tqdm(total<span class="op">=</span><span class="bu">len</span>(<span class="va">self</span>.train_loader)) <span class="im">as</span> pbar:</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.train_loader):</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>                inputs, labels <span class="op">=</span> batch</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>                inputs, labels <span class="op">=</span> inputs.to(<span class="va">self</span>.device), labels.to(<span class="va">self</span>.device)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> <span class="va">self</span>.model(inputs)</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> <span class="va">self</span>.criterion(output, labels)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.optimizer.step()</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>                _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(output.detach(), <span class="dv">1</span>)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>                accuracy <span class="op">=</span> accuracy_score(predicted.cpu().numpy(), labels.cpu().numpy())</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>                epoch_accuracy <span class="op">+=</span> accuracy</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>                epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>                pbar.set_description(<span class="ss">f&#39;Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">; Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>                pbar.update()</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>        epoch_end_time <span class="op">=</span> time.time()</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.losses[<span class="st">&#39;train&#39;</span>].append(epoch_loss <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.train_loader))</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.accuracies[<span class="st">&#39;train&#39;</span>].append(epoch_accuracy <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.train_loader))</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time.append(epoch_end_time <span class="op">-</span> epoch_start_time)</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> validate(<span class="va">self</span>):</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.to(<span class="va">self</span>.device).<span class="bu">eval</span>()</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>        losses <span class="op">=</span> []</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>        predicted_classes <span class="op">=</span> []</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>        true_classes <span class="op">=</span> []</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> tqdm(total<span class="op">=</span><span class="bu">len</span>(<span class="va">self</span>.test_loader)) <span class="im">as</span> pbar:</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.test_loader):</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>                    inputs, labels <span class="op">=</span> batch</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>                    inputs, labels <span class="op">=</span> inputs.to(<span class="va">self</span>.device), labels.to(<span class="va">self</span>.device)</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>                    output <span class="op">=</span> <span class="va">self</span>.model(inputs)</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> <span class="va">self</span>.criterion(output, labels)</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>                    losses.append(loss.item())</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>                    _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(output.detach(), <span class="dv">1</span>)</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>                    predicted_classes.append(predicted)</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>                    true_classes.append(labels)</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>                    accuracy <span class="op">=</span> accuracy_score(predicted.cpu().numpy(), labels.cpu().numpy())</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>                    pbar.set_description(<span class="ss">f&#39;Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">; Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>                    pbar.update()</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>        predicted_classes <span class="op">=</span> torch.cat(predicted_classes).detach().to(<span class="st">&#39;cpu&#39;</span>).numpy()</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>        true_classes <span class="op">=</span> torch.cat(true_classes).detach().to(<span class="st">&#39;cpu&#39;</span>).numpy()</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> losses, predicted_classes, true_classes</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>):</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>        start_time <span class="op">=</span> time.time()</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>        early_stopping <span class="op">=</span> CustomEarlyStopping(patience<span class="op">=</span><span class="dv">4</span>, min_delta<span class="op">=</span><span class="fl">0.005</span>, path<span class="op">=</span><span class="va">self</span>.path, path_model<span class="op">=</span><span class="va">self</span>.path_model)</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_epochs):</span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Epoch:&#39;</span>, epoch)</span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.train_one_epoch()</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Validation&#39;</span>)</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>            losses, predicted_classes, true_classes <span class="op">=</span> <span class="va">self</span>.validate()</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>            test_accuracy <span class="op">=</span> accuracy_score(true_classes, predicted_classes)</span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.losses[<span class="st">&#39;test&#39;</span>].append(np.mean(losses))</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.accuracies[<span class="st">&#39;test&#39;</span>].append(test_accuracy)</span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a>            clear_output(wait<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&#39;Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>()</span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.plot_training_history()</span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.scheduler:</span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.scheduler.step()</span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a>            early_stopping(test_accuracy, <span class="va">self</span>.model, <span class="va">self</span>.optimizer)</span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> early_stopping.early_stop:</span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&#39;Early Stopping!!!&#39;</span>)</span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a>        end_time <span class="op">=</span> time.time()</span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a>        clear_output(wait<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.time)):</span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a>            train <span class="op">=</span> <span class="st">&#39;test&#39;</span></span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&#39;Epoch: </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">; Loss: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>losses[train][i]<span class="sc">:.4f}</span><span class="ss">; Accuracy: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>accuracies[train][i]<span class="sc">:.4f}</span><span class="ss">; Time: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>time[i]<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Обучение завершено!!!&quot;</span>)</span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Total time: </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Best accuracy: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>get_best_accuracy()<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_training_history(<span class="va">self</span>):</span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a>        len_data <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.losses[<span class="st">&#39;train&#39;</span>])</span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a>        <span class="co"># График функции потерь</span></span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.losses[<span class="st">&#39;train&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb13-139"><a href="#cb13-139" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.losses[<span class="st">&#39;test&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Test Loss&#39;</span>)</span>
<span id="cb13-140"><a href="#cb13-140" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a>        plt.legend()</span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">&#39;Training and Test Loss&#39;</span>)</span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a>        plt.grid(<span class="va">True</span>)</span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a>        <span class="co"># График точности</span></span>
<span id="cb13-147"><a href="#cb13-147" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb13-148"><a href="#cb13-148" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.accuracies[<span class="st">&#39;train&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.accuracies[<span class="st">&#39;test&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Test Accuracy&#39;</span>)</span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>)</span>
<span id="cb13-152"><a href="#cb13-152" aria-hidden="true" tabindex="-1"></a>        plt.legend()</span>
<span id="cb13-153"><a href="#cb13-153" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">&#39;Training and Test Accuracy&#39;</span>)</span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a>        plt.grid(<span class="va">True</span>)</span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a>        plt.tight_layout()</span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb13-157"><a href="#cb13-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-158"><a href="#cb13-158" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_best_accuracy(<span class="va">self</span>):</span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a>        checkpoint <span class="op">=</span> torch.load(<span class="va">self</span>.path)</span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint[<span class="st">&#39;best_accuracy&#39;</span>]</span></code></pre></div>
</div>
<div id="d681bc31" class="cell markdown" id="d681bc31">
<p>В данной работе проведем transfer learning для AlexNet, ResNet34,
MobileNet V2, EfficientNetV2. Так как данные модели обучались ранее на
imagenet с размером 224x224, то и нам придется сделать Resize
изображений. В качестве оптимизатора, попробуем обучить модели с помощью
нового оптимизатора lion и старого доброго adam (<a
href="https://github.com/lucidrains/lion-pytorch"
class="uri">https://github.com/lucidrains/lion-pytorch</a>). Обучим два
типа моделей: с freeze слоев и полным fine tuning.</p>
</div>
<div id="a8542901" class="cell markdown" id="a8542901">
<h3 id="alexnet">AlexNet</h3>
<h4 id="freeze-layers">freeze layers</h4>
</div>
<div id="c69c4ed2" class="cell code" id="c69c4ed2">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AlexNetFreeze(nn.Module):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AlexNetFreeze, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet <span class="op">=</span> models.alexnet( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.alexnet.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>].in_features,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.alexnet(x)</span></code></pre></div>
</div>
<div id="470b3a38" class="cell code" id="470b3a38"
data-outputId="a85d087a-0b98-4f9b-c99a-45bb6ef21352">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> alexnet.to(device)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>summary(alexnet, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/home/gerasim/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() &gt; 0
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 55, 55]          23,296
              ReLU-2           [-1, 64, 55, 55]               0
         MaxPool2d-3           [-1, 64, 27, 27]               0
            Conv2d-4          [-1, 192, 27, 27]         307,392
              ReLU-5          [-1, 192, 27, 27]               0
         MaxPool2d-6          [-1, 192, 13, 13]               0
            Conv2d-7          [-1, 384, 13, 13]         663,936
              ReLU-8          [-1, 384, 13, 13]               0
            Conv2d-9          [-1, 256, 13, 13]         884,992
             ReLU-10          [-1, 256, 13, 13]               0
           Conv2d-11          [-1, 256, 13, 13]         590,080
             ReLU-12          [-1, 256, 13, 13]               0
        MaxPool2d-13            [-1, 256, 6, 6]               0
AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0
          Dropout-15                 [-1, 9216]               0
           Linear-16                 [-1, 4096]      37,752,832
             ReLU-17                 [-1, 4096]               0
          Dropout-18                 [-1, 4096]               0
           Linear-19                 [-1, 4096]      16,781,312
             ReLU-20                 [-1, 4096]               0
           Linear-21                   [-1, 10]          40,970
          AlexNet-22                   [-1, 10]               0
================================================================
Total params: 57,044,810
Trainable params: 40,970
Non-trainable params: 57,003,840
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 8.37
Params size (MB): 217.61
Estimated Total Size (MB): 226.55
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="1fd5498b" class="cell markdown" id="1fd5498b">
<p>По итогу имеем <strong>40 970</strong> обучаемых параметров</p>
</div>
<div id="c563a240" class="cell code" id="c563a240"
data-outputId="c938c460-b6f2-416c-e0f3-205768805ac5">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_lion.train()</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch: 0; Loss: 0.8396; Accuracy: 0.7223; Time: 209.15359735488892
Epoch: 1; Loss: 0.6717; Accuracy: 0.7692; Time: 212.17468214035034
Epoch: 2; Loss: 0.6227; Accuracy: 0.7820; Time: 214.5270071029663
Epoch: 3; Loss: 0.6162; Accuracy: 0.7839; Time: 214.67133474349976
Epoch: 4; Loss: 0.5873; Accuracy: 0.7986; Time: 212.18927597999573
Epoch: 5; Loss: 0.5922; Accuracy: 0.7965; Time: 209.783935546875
Epoch: 6; Loss: 0.5811; Accuracy: 0.8014; Time: 212.50887060165405
Epoch: 7; Loss: 0.5844; Accuracy: 0.7983; Time: 211.83877420425415
Epoch: 8; Loss: 0.5907; Accuracy: 0.7945; Time: 212.74277687072754
Обучение завершено!!!
Total time: 2218.965336084366
Best accuracy: 0.8
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/10a1123d68d8030ab2e8b22949ccf7aca625f9ef.png" /></p>
</div>
</div>
<div id="13b9f57d" class="cell markdown" id="13b9f57d">
<p>Теперь обучим используя AdamW</p>
</div>
<div id="17d4e171" class="cell code" id="17d4e171"
data-outputId="2ff9f1c3-19b1-416c-a18d-851144507216">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_adamw.train()</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch: 0; Loss: 0.9757; Accuracy: 0.6709; Time: 212.4973006248474
Epoch: 1; Loss: 0.8316; Accuracy: 0.7158; Time: 214.3255467414856
Epoch: 2; Loss: 0.7561; Accuracy: 0.7427; Time: 213.65592885017395
Epoch: 3; Loss: 0.7243; Accuracy: 0.7530; Time: 209.85077238082886
Epoch: 4; Loss: 0.6932; Accuracy: 0.7632; Time: 211.70075154304504
Epoch: 5; Loss: 0.6726; Accuracy: 0.7663; Time: 209.98472046852112
Epoch: 6; Loss: 0.6669; Accuracy: 0.7669; Time: 209.35064339637756
Epoch: 7; Loss: 0.6541; Accuracy: 0.7703; Time: 210.0432071685791
Epoch: 8; Loss: 0.6559; Accuracy: 0.7680; Time: 209.7219958305359
Epoch: 9; Loss: 0.6352; Accuracy: 0.7768; Time: 211.03685998916626
Epoch: 10; Loss: 0.6299; Accuracy: 0.7792; Time: 211.90435147285461
Epoch: 11; Loss: 0.6290; Accuracy: 0.7805; Time: 211.6078586578369
Epoch: 12; Loss: 0.6259; Accuracy: 0.7791; Time: 212.1951470375061
Epoch: 13; Loss: 0.6216; Accuracy: 0.7808; Time: 212.9739544391632
Обучение завершено!!!
Total time: 3442.705681324005
Best accuracy: 0.78
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/3bbf0a55bae7b52278af50dcf39e27969b6b8f90.png" /></p>
</div>
</div>
<div id="db584e79" class="cell markdown" id="db584e79">
<p>На первый взгляд можно сказать, что для Lion необходимо гораздо
меньше эпох для полного обучения (9 эпох против 14 у AdamW).</p>
</div>
<div id="afe44d5a" class="cell markdown" id="afe44d5a">
<h4 id="finetuning">finetuning</h4>
</div>
<div id="5ecb5d9f" class="cell code" id="5ecb5d9f">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AlexNet(nn.Module):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AlexNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet <span class="op">=</span> models.alexnet( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>].in_features,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.alexnet(x)</span></code></pre></div>
</div>
<div id="3370103f" class="cell code" id="3370103f"
data-outputId="54834b89-671b-4cc3-b9e7-c744fb8608ec">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> alexnet.to(device)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>summary(alexnet, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 55, 55]          23,296
              ReLU-2           [-1, 64, 55, 55]               0
         MaxPool2d-3           [-1, 64, 27, 27]               0
            Conv2d-4          [-1, 192, 27, 27]         307,392
              ReLU-5          [-1, 192, 27, 27]               0
         MaxPool2d-6          [-1, 192, 13, 13]               0
            Conv2d-7          [-1, 384, 13, 13]         663,936
              ReLU-8          [-1, 384, 13, 13]               0
            Conv2d-9          [-1, 256, 13, 13]         884,992
             ReLU-10          [-1, 256, 13, 13]               0
           Conv2d-11          [-1, 256, 13, 13]         590,080
             ReLU-12          [-1, 256, 13, 13]               0
        MaxPool2d-13            [-1, 256, 6, 6]               0
AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0
          Dropout-15                 [-1, 9216]               0
           Linear-16                 [-1, 4096]      37,752,832
             ReLU-17                 [-1, 4096]               0
          Dropout-18                 [-1, 4096]               0
           Linear-19                 [-1, 4096]      16,781,312
             ReLU-20                 [-1, 4096]               0
           Linear-21                   [-1, 10]          40,970
          AlexNet-22                   [-1, 10]               0
================================================================
Total params: 57,044,810
Trainable params: 57,044,810
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 8.37
Params size (MB): 217.61
Estimated Total Size (MB): 226.55
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="35c6e5e5" class="cell code" id="35c6e5e5"
data-outputId="9812c10a-9c2b-4900-d73b-ba4375bc3df7">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_lion.train()</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch: 0; Loss: 0.4673; Accuracy: 0.8392; Time: 546.8312318325043
Epoch: 1; Loss: 0.4142; Accuracy: 0.8557; Time: 544.9346904754639
Epoch: 2; Loss: 0.3760; Accuracy: 0.8761; Time: 552.4440660476685
Epoch: 3; Loss: 0.3387; Accuracy: 0.8871; Time: 553.7514328956604
Epoch: 4; Loss: 0.3387; Accuracy: 0.8867; Time: 556.442479133606
Epoch: 5; Loss: 0.3264; Accuracy: 0.8884; Time: 559.1123428344727
Epoch: 6; Loss: 0.3101; Accuracy: 0.8952; Time: 564.3866212368011
Epoch: 7; Loss: 0.2962; Accuracy: 0.9040; Time: 572.3000249862671
Epoch: 8; Loss: 0.3028; Accuracy: 0.9042; Time: 598.7421715259552
Epoch: 9; Loss: 0.3065; Accuracy: 0.9063; Time: 603.9759910106659
Epoch: 10; Loss: 0.3010; Accuracy: 0.9079; Time: 609.1872704029083
Epoch: 11; Loss: 0.3097; Accuracy: 0.9106; Time: 649.7767088413239
Epoch: 12; Loss: 0.3113; Accuracy: 0.9093; Time: 670.4722406864166
Epoch: 13; Loss: 0.3250; Accuracy: 0.9135; Time: 677.5675985813141
Epoch: 14; Loss: 0.3077; Accuracy: 0.9154; Time: 702.2224757671356
Epoch: 15; Loss: 0.3118; Accuracy: 0.9160; Time: 700.7054674625397
Epoch: 16; Loss: 0.3175; Accuracy: 0.9162; Time: 722.6734924316406
Epoch: 17; Loss: 0.3273; Accuracy: 0.9181; Time: 735.0313715934753
Epoch: 18; Loss: 0.3224; Accuracy: 0.9176; Time: 730.1248776912689
Epoch: 19; Loss: 0.3338; Accuracy: 0.9187; Time: 792.122171163559
Обучение завершено!!!
Total time: 13379.318495988846
Best accuracy: 0.92
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/e3cea5428c93f585b0d9ad90fa7db4c02d641f00.png" /></p>
</div>
</div>
<div id="704bb3f9" class="cell markdown" id="704bb3f9">
<p>Отлично, fine tuning всех слоев показал прирост на 10+%</p>
</div>
<div id="8585095e" class="cell code" id="8585095e"
data-outputId="76445da2-b69c-494b-c718-c01fa990bb1e">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_adamw.train()</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch: 0; Loss: 0.3768; Accuracy: 0.8705; Time: 555.5730409622192
Epoch: 1; Loss: 0.3264; Accuracy: 0.8881; Time: 555.8441038131714
Epoch: 2; Loss: 0.2911; Accuracy: 0.8989; Time: 543.5752029418945
Epoch: 3; Loss: 0.2766; Accuracy: 0.9069; Time: 551.673885345459
Epoch: 4; Loss: 0.2727; Accuracy: 0.9095; Time: 553.8633761405945
Epoch: 5; Loss: 0.2528; Accuracy: 0.9155; Time: 559.8398458957672
Epoch: 6; Loss: 0.2672; Accuracy: 0.9148; Time: 545.3969268798828
Epoch: 7; Loss: 0.2471; Accuracy: 0.9183; Time: 542.977587223053
Epoch: 8; Loss: 0.2648; Accuracy: 0.9191; Time: 537.3902297019958
Epoch: 9; Loss: 0.2675; Accuracy: 0.9199; Time: 544.6130285263062
Обучение завершено!!!
Total time: 5857.310532808304
Best accuracy: 0.92
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/dd79f319829181c26ef38b9523a8949a1b361f59.png" /></p>
</div>
</div>
<div id="db742166" class="cell markdown" id="db742166">
<p>Как видим, что при fine tuning AdamW сошелся лучше, чем Lion. Была
обучена модель 2012 года, теперь обучим модель 2015 года.</p>
</div>
<div id="27cc72e0" class="cell markdown" id="27cc72e0">
<h3 id="resnet-34">ResNet 34</h3>
</div>
<div id="809f1f94" class="cell code" id="809f1f94">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResNetFreeze(nn.Module):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ResNetFreeze, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34 <span class="op">=</span> models.resnet34( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.resnet34.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34.fc <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.resnet34.fc.in_features,</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.resnet34(x)</span></code></pre></div>
</div>
<div id="4961e918" class="cell code" id="4961e918"
data-outputId="b19241f1-3712-47c1-ead9-0ea24f6e7e04">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> resnet34.to(device)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>summary(resnet34, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>Downloading: &quot;https://download.pytorch.org/models/resnet34-b627a593.pth&quot; to /home/gerasim/.cache/torch/hub/checkpoints/resnet34-b627a593.pth
100%|██████████| 83.3M/83.3M [00:07&lt;00:00, 11.0MB/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19           [-1, 64, 56, 56]          36,864
      BatchNorm2d-20           [-1, 64, 56, 56]             128
             ReLU-21           [-1, 64, 56, 56]               0
           Conv2d-22           [-1, 64, 56, 56]          36,864
      BatchNorm2d-23           [-1, 64, 56, 56]             128
             ReLU-24           [-1, 64, 56, 56]               0
       BasicBlock-25           [-1, 64, 56, 56]               0
           Conv2d-26          [-1, 128, 28, 28]          73,728
      BatchNorm2d-27          [-1, 128, 28, 28]             256
             ReLU-28          [-1, 128, 28, 28]               0
           Conv2d-29          [-1, 128, 28, 28]         147,456
      BatchNorm2d-30          [-1, 128, 28, 28]             256
           Conv2d-31          [-1, 128, 28, 28]           8,192
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 128, 28, 28]         147,456
      BatchNorm2d-36          [-1, 128, 28, 28]             256
             ReLU-37          [-1, 128, 28, 28]               0
           Conv2d-38          [-1, 128, 28, 28]         147,456
      BatchNorm2d-39          [-1, 128, 28, 28]             256
             ReLU-40          [-1, 128, 28, 28]               0
       BasicBlock-41          [-1, 128, 28, 28]               0
           Conv2d-42          [-1, 128, 28, 28]         147,456
      BatchNorm2d-43          [-1, 128, 28, 28]             256
             ReLU-44          [-1, 128, 28, 28]               0
           Conv2d-45          [-1, 128, 28, 28]         147,456
      BatchNorm2d-46          [-1, 128, 28, 28]             256
             ReLU-47          [-1, 128, 28, 28]               0
       BasicBlock-48          [-1, 128, 28, 28]               0
           Conv2d-49          [-1, 128, 28, 28]         147,456
      BatchNorm2d-50          [-1, 128, 28, 28]             256
             ReLU-51          [-1, 128, 28, 28]               0
           Conv2d-52          [-1, 128, 28, 28]         147,456
      BatchNorm2d-53          [-1, 128, 28, 28]             256
             ReLU-54          [-1, 128, 28, 28]               0
       BasicBlock-55          [-1, 128, 28, 28]               0
           Conv2d-56          [-1, 256, 14, 14]         294,912
      BatchNorm2d-57          [-1, 256, 14, 14]             512
             ReLU-58          [-1, 256, 14, 14]               0
           Conv2d-59          [-1, 256, 14, 14]         589,824
      BatchNorm2d-60          [-1, 256, 14, 14]             512
           Conv2d-61          [-1, 256, 14, 14]          32,768
      BatchNorm2d-62          [-1, 256, 14, 14]             512
             ReLU-63          [-1, 256, 14, 14]               0
       BasicBlock-64          [-1, 256, 14, 14]               0
           Conv2d-65          [-1, 256, 14, 14]         589,824
      BatchNorm2d-66          [-1, 256, 14, 14]             512
             ReLU-67          [-1, 256, 14, 14]               0
           Conv2d-68          [-1, 256, 14, 14]         589,824
      BatchNorm2d-69          [-1, 256, 14, 14]             512
             ReLU-70          [-1, 256, 14, 14]               0
       BasicBlock-71          [-1, 256, 14, 14]               0
           Conv2d-72          [-1, 256, 14, 14]         589,824
      BatchNorm2d-73          [-1, 256, 14, 14]             512
             ReLU-74          [-1, 256, 14, 14]               0
           Conv2d-75          [-1, 256, 14, 14]         589,824
      BatchNorm2d-76          [-1, 256, 14, 14]             512
             ReLU-77          [-1, 256, 14, 14]               0
       BasicBlock-78          [-1, 256, 14, 14]               0
           Conv2d-79          [-1, 256, 14, 14]         589,824
      BatchNorm2d-80          [-1, 256, 14, 14]             512
             ReLU-81          [-1, 256, 14, 14]               0
           Conv2d-82          [-1, 256, 14, 14]         589,824
      BatchNorm2d-83          [-1, 256, 14, 14]             512
             ReLU-84          [-1, 256, 14, 14]               0
       BasicBlock-85          [-1, 256, 14, 14]               0
           Conv2d-86          [-1, 256, 14, 14]         589,824
      BatchNorm2d-87          [-1, 256, 14, 14]             512
             ReLU-88          [-1, 256, 14, 14]               0
           Conv2d-89          [-1, 256, 14, 14]         589,824
      BatchNorm2d-90          [-1, 256, 14, 14]             512
             ReLU-91          [-1, 256, 14, 14]               0
       BasicBlock-92          [-1, 256, 14, 14]               0
           Conv2d-93          [-1, 256, 14, 14]         589,824
      BatchNorm2d-94          [-1, 256, 14, 14]             512
             ReLU-95          [-1, 256, 14, 14]               0
           Conv2d-96          [-1, 256, 14, 14]         589,824
      BatchNorm2d-97          [-1, 256, 14, 14]             512
             ReLU-98          [-1, 256, 14, 14]               0
       BasicBlock-99          [-1, 256, 14, 14]               0
          Conv2d-100            [-1, 512, 7, 7]       1,179,648
     BatchNorm2d-101            [-1, 512, 7, 7]           1,024
            ReLU-102            [-1, 512, 7, 7]               0
          Conv2d-103            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-104            [-1, 512, 7, 7]           1,024
          Conv2d-105            [-1, 512, 7, 7]         131,072
     BatchNorm2d-106            [-1, 512, 7, 7]           1,024
            ReLU-107            [-1, 512, 7, 7]               0
      BasicBlock-108            [-1, 512, 7, 7]               0
          Conv2d-109            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-110            [-1, 512, 7, 7]           1,024
            ReLU-111            [-1, 512, 7, 7]               0
          Conv2d-112            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-113            [-1, 512, 7, 7]           1,024
            ReLU-114            [-1, 512, 7, 7]               0
      BasicBlock-115            [-1, 512, 7, 7]               0
          Conv2d-116            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-117            [-1, 512, 7, 7]           1,024
            ReLU-118            [-1, 512, 7, 7]               0
          Conv2d-119            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-120            [-1, 512, 7, 7]           1,024
            ReLU-121            [-1, 512, 7, 7]               0
      BasicBlock-122            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0
          Linear-124                   [-1, 10]           5,130
          ResNet-125                   [-1, 10]               0
================================================================
Total params: 21,289,802
Trainable params: 5,130
Non-trainable params: 21,284,672
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 96.28
Params size (MB): 81.21
Estimated Total Size (MB): 178.07
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="c688aa1a" class="cell code" id="c688aa1a"
data-outputId="a4ef2ff8-ba45-4884-bae6-e0c8b6c4f4fc">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_lion.train()</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch: 0; Loss: 0.8561; Accuracy: 0.7454; Time: 974.3981738090515
Epoch: 1; Loss: 0.5836; Accuracy: 0.8105; Time: 986.9973888397217
Epoch: 2; Loss: 0.5421; Accuracy: 0.8218; Time: 988.0171184539795
Epoch: 3; Loss: 0.5231; Accuracy: 0.8270; Time: 1000.3722767829895
Epoch: 4; Loss: 0.5091; Accuracy: 0.8268; Time: 994.6438500881195
Epoch: 5; Loss: 0.5045; Accuracy: 0.8305; Time: 993.0012767314911
Epoch: 6; Loss: 0.4966; Accuracy: 0.8317; Time: 991.5056455135345
Epoch: 7; Loss: 0.4941; Accuracy: 0.8312; Time: 991.1660633087158
Обучение завершено!!!
Total time: 9409.396390199661
Best accuracy: 0.83
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/849b52a43f1324c8b6de786c794d481e079e4772.png" /></p>
</div>
</div>
<div id="rdkz5PTCgnJK" class="cell code" id="rdkz5PTCgnJK"
data-outputId="d695a67a-43c0-4004-c869-ee6eba8a917c">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_adamw.train()</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.815
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/50ea5dc7c5d73bd93bbf71fabcf6b95f7ddf764b.png" /></p>
</div>
</div>
<div id="9d6ac8f9" class="cell markdown" id="9d6ac8f9">
<p>Тенденция сохраняется, для freeze Lion обучает модели быстрее и лучше
сходится</p>
</div>
<div id="dbfb786b" class="cell markdown" id="dbfb786b">
<h4 id="finetuning">finetuning</h4>
</div>
<div id="11898594" class="cell code" id="&quot;11898594&quot;">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResNet(nn.Module):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ResNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34 <span class="op">=</span> models.resnet34( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34.fc <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.resnet34.fc.in_features,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.resnet34(x)</span></code></pre></div>
</div>
<div id="d36dd991" class="cell code" id="d36dd991"
data-outputId="024fcd78-bda1-410b-dcfd-023384392d4e">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> resnet34.to(device)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>summary(resnet34, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19           [-1, 64, 56, 56]          36,864
      BatchNorm2d-20           [-1, 64, 56, 56]             128
             ReLU-21           [-1, 64, 56, 56]               0
           Conv2d-22           [-1, 64, 56, 56]          36,864
      BatchNorm2d-23           [-1, 64, 56, 56]             128
             ReLU-24           [-1, 64, 56, 56]               0
       BasicBlock-25           [-1, 64, 56, 56]               0
           Conv2d-26          [-1, 128, 28, 28]          73,728
      BatchNorm2d-27          [-1, 128, 28, 28]             256
             ReLU-28          [-1, 128, 28, 28]               0
           Conv2d-29          [-1, 128, 28, 28]         147,456
      BatchNorm2d-30          [-1, 128, 28, 28]             256
           Conv2d-31          [-1, 128, 28, 28]           8,192
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 128, 28, 28]         147,456
      BatchNorm2d-36          [-1, 128, 28, 28]             256
             ReLU-37          [-1, 128, 28, 28]               0
           Conv2d-38          [-1, 128, 28, 28]         147,456
      BatchNorm2d-39          [-1, 128, 28, 28]             256
             ReLU-40          [-1, 128, 28, 28]               0
       BasicBlock-41          [-1, 128, 28, 28]               0
           Conv2d-42          [-1, 128, 28, 28]         147,456
      BatchNorm2d-43          [-1, 128, 28, 28]             256
             ReLU-44          [-1, 128, 28, 28]               0
           Conv2d-45          [-1, 128, 28, 28]         147,456
      BatchNorm2d-46          [-1, 128, 28, 28]             256
             ReLU-47          [-1, 128, 28, 28]               0
       BasicBlock-48          [-1, 128, 28, 28]               0
           Conv2d-49          [-1, 128, 28, 28]         147,456
      BatchNorm2d-50          [-1, 128, 28, 28]             256
             ReLU-51          [-1, 128, 28, 28]               0
           Conv2d-52          [-1, 128, 28, 28]         147,456
      BatchNorm2d-53          [-1, 128, 28, 28]             256
             ReLU-54          [-1, 128, 28, 28]               0
       BasicBlock-55          [-1, 128, 28, 28]               0
           Conv2d-56          [-1, 256, 14, 14]         294,912
      BatchNorm2d-57          [-1, 256, 14, 14]             512
             ReLU-58          [-1, 256, 14, 14]               0
           Conv2d-59          [-1, 256, 14, 14]         589,824
      BatchNorm2d-60          [-1, 256, 14, 14]             512
           Conv2d-61          [-1, 256, 14, 14]          32,768
      BatchNorm2d-62          [-1, 256, 14, 14]             512
             ReLU-63          [-1, 256, 14, 14]               0
       BasicBlock-64          [-1, 256, 14, 14]               0
           Conv2d-65          [-1, 256, 14, 14]         589,824
      BatchNorm2d-66          [-1, 256, 14, 14]             512
             ReLU-67          [-1, 256, 14, 14]               0
           Conv2d-68          [-1, 256, 14, 14]         589,824
      BatchNorm2d-69          [-1, 256, 14, 14]             512
             ReLU-70          [-1, 256, 14, 14]               0
       BasicBlock-71          [-1, 256, 14, 14]               0
           Conv2d-72          [-1, 256, 14, 14]         589,824
      BatchNorm2d-73          [-1, 256, 14, 14]             512
             ReLU-74          [-1, 256, 14, 14]               0
           Conv2d-75          [-1, 256, 14, 14]         589,824
      BatchNorm2d-76          [-1, 256, 14, 14]             512
             ReLU-77          [-1, 256, 14, 14]               0
       BasicBlock-78          [-1, 256, 14, 14]               0
           Conv2d-79          [-1, 256, 14, 14]         589,824
      BatchNorm2d-80          [-1, 256, 14, 14]             512
             ReLU-81          [-1, 256, 14, 14]               0
           Conv2d-82          [-1, 256, 14, 14]         589,824
      BatchNorm2d-83          [-1, 256, 14, 14]             512
             ReLU-84          [-1, 256, 14, 14]               0
       BasicBlock-85          [-1, 256, 14, 14]               0
           Conv2d-86          [-1, 256, 14, 14]         589,824
      BatchNorm2d-87          [-1, 256, 14, 14]             512
             ReLU-88          [-1, 256, 14, 14]               0
           Conv2d-89          [-1, 256, 14, 14]         589,824
      BatchNorm2d-90          [-1, 256, 14, 14]             512
             ReLU-91          [-1, 256, 14, 14]               0
       BasicBlock-92          [-1, 256, 14, 14]               0
           Conv2d-93          [-1, 256, 14, 14]         589,824
      BatchNorm2d-94          [-1, 256, 14, 14]             512
             ReLU-95          [-1, 256, 14, 14]               0
           Conv2d-96          [-1, 256, 14, 14]         589,824
      BatchNorm2d-97          [-1, 256, 14, 14]             512
             ReLU-98          [-1, 256, 14, 14]               0
       BasicBlock-99          [-1, 256, 14, 14]               0
          Conv2d-100            [-1, 512, 7, 7]       1,179,648
     BatchNorm2d-101            [-1, 512, 7, 7]           1,024
            ReLU-102            [-1, 512, 7, 7]               0
          Conv2d-103            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-104            [-1, 512, 7, 7]           1,024
          Conv2d-105            [-1, 512, 7, 7]         131,072
     BatchNorm2d-106            [-1, 512, 7, 7]           1,024
            ReLU-107            [-1, 512, 7, 7]               0
      BasicBlock-108            [-1, 512, 7, 7]               0
          Conv2d-109            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-110            [-1, 512, 7, 7]           1,024
            ReLU-111            [-1, 512, 7, 7]               0
          Conv2d-112            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-113            [-1, 512, 7, 7]           1,024
            ReLU-114            [-1, 512, 7, 7]               0
      BasicBlock-115            [-1, 512, 7, 7]               0
          Conv2d-116            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-117            [-1, 512, 7, 7]           1,024
            ReLU-118            [-1, 512, 7, 7]               0
          Conv2d-119            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-120            [-1, 512, 7, 7]           1,024
            ReLU-121            [-1, 512, 7, 7]               0
      BasicBlock-122            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0
          Linear-124                   [-1, 10]           5,130
          ResNet-125                   [-1, 10]               0
================================================================
Total params: 21,289,802
Trainable params: 21,289,802
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 96.28
Params size (MB): 81.21
Estimated Total Size (MB): 178.07
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="50a1187f" class="cell code" id="50a1187f"
data-outputId="6ea877a9-2fd2-4392-906f-d287e852b79a">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_lion.train()</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9552
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/9ca13975894f45b61ce83477d1be4ee96f3075cc.png" /></p>
</div>
</div>
<div id="81fdfa6b" class="cell code" id="81fdfa6b"
data-outputId="8c34cca8-7d1b-4991-f146-55a12cf300b9">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_adamw.train()</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9637
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/f1f43cbd3e1873dedcc376133ae2b5e447d4da3b.png" /></p>
</div>
</div>
<div id="3b53388e" class="cell markdown" id="3b53388e">
<p>Отлично! Получили почти похожий результат, но <strong>AdamW</strong>
чуть лучше справился с задачей в <strong>96,37%</strong></p>
<p>Теперь посмотрим модель 2018 года</p>
</div>
<div id="50163bab" class="cell markdown" id="50163bab">
<h3 id="mobilenet-v2">MobileNet V2</h3>
</div>
<div id="f3b24814" class="cell code" id="f3b24814">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MobileNetFreeze(nn.Module):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MobileNetFreeze, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2 <span class="op">=</span> models.mobilenet_v2( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.mobilenet_v2.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>].in_features,</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.mobilenet_v2(x)</span></code></pre></div>
</div>
<div id="167d5d70" class="cell code" id="167d5d70"
data-outputId="d032d4cd-8eff-4839-aa3e-57e2ced6ea10">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> mobilenet_v2.to(device)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>summary(mobilenet_v2, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 112, 112]             864
       BatchNorm2d-2         [-1, 32, 112, 112]              64
             ReLU6-3         [-1, 32, 112, 112]               0
            Conv2d-4         [-1, 32, 112, 112]             288
       BatchNorm2d-5         [-1, 32, 112, 112]              64
             ReLU6-6         [-1, 32, 112, 112]               0
            Conv2d-7         [-1, 16, 112, 112]             512
       BatchNorm2d-8         [-1, 16, 112, 112]              32
  InvertedResidual-9         [-1, 16, 112, 112]               0
           Conv2d-10         [-1, 96, 112, 112]           1,536
      BatchNorm2d-11         [-1, 96, 112, 112]             192
            ReLU6-12         [-1, 96, 112, 112]               0
           Conv2d-13           [-1, 96, 56, 56]             864
      BatchNorm2d-14           [-1, 96, 56, 56]             192
            ReLU6-15           [-1, 96, 56, 56]               0
           Conv2d-16           [-1, 24, 56, 56]           2,304
      BatchNorm2d-17           [-1, 24, 56, 56]              48
 InvertedResidual-18           [-1, 24, 56, 56]               0
           Conv2d-19          [-1, 144, 56, 56]           3,456
      BatchNorm2d-20          [-1, 144, 56, 56]             288
            ReLU6-21          [-1, 144, 56, 56]               0
           Conv2d-22          [-1, 144, 56, 56]           1,296
      BatchNorm2d-23          [-1, 144, 56, 56]             288
            ReLU6-24          [-1, 144, 56, 56]               0
           Conv2d-25           [-1, 24, 56, 56]           3,456
      BatchNorm2d-26           [-1, 24, 56, 56]              48
 InvertedResidual-27           [-1, 24, 56, 56]               0
           Conv2d-28          [-1, 144, 56, 56]           3,456
      BatchNorm2d-29          [-1, 144, 56, 56]             288
            ReLU6-30          [-1, 144, 56, 56]               0
           Conv2d-31          [-1, 144, 28, 28]           1,296
      BatchNorm2d-32          [-1, 144, 28, 28]             288
            ReLU6-33          [-1, 144, 28, 28]               0
           Conv2d-34           [-1, 32, 28, 28]           4,608
      BatchNorm2d-35           [-1, 32, 28, 28]              64
 InvertedResidual-36           [-1, 32, 28, 28]               0
           Conv2d-37          [-1, 192, 28, 28]           6,144
      BatchNorm2d-38          [-1, 192, 28, 28]             384
            ReLU6-39          [-1, 192, 28, 28]               0
           Conv2d-40          [-1, 192, 28, 28]           1,728
      BatchNorm2d-41          [-1, 192, 28, 28]             384
            ReLU6-42          [-1, 192, 28, 28]               0
           Conv2d-43           [-1, 32, 28, 28]           6,144
      BatchNorm2d-44           [-1, 32, 28, 28]              64
 InvertedResidual-45           [-1, 32, 28, 28]               0
           Conv2d-46          [-1, 192, 28, 28]           6,144
      BatchNorm2d-47          [-1, 192, 28, 28]             384
            ReLU6-48          [-1, 192, 28, 28]               0
           Conv2d-49          [-1, 192, 28, 28]           1,728
      BatchNorm2d-50          [-1, 192, 28, 28]             384
            ReLU6-51          [-1, 192, 28, 28]               0
           Conv2d-52           [-1, 32, 28, 28]           6,144
      BatchNorm2d-53           [-1, 32, 28, 28]              64
 InvertedResidual-54           [-1, 32, 28, 28]               0
           Conv2d-55          [-1, 192, 28, 28]           6,144
      BatchNorm2d-56          [-1, 192, 28, 28]             384
            ReLU6-57          [-1, 192, 28, 28]               0
           Conv2d-58          [-1, 192, 14, 14]           1,728
      BatchNorm2d-59          [-1, 192, 14, 14]             384
            ReLU6-60          [-1, 192, 14, 14]               0
           Conv2d-61           [-1, 64, 14, 14]          12,288
      BatchNorm2d-62           [-1, 64, 14, 14]             128
 InvertedResidual-63           [-1, 64, 14, 14]               0
           Conv2d-64          [-1, 384, 14, 14]          24,576
      BatchNorm2d-65          [-1, 384, 14, 14]             768
            ReLU6-66          [-1, 384, 14, 14]               0
           Conv2d-67          [-1, 384, 14, 14]           3,456
      BatchNorm2d-68          [-1, 384, 14, 14]             768
            ReLU6-69          [-1, 384, 14, 14]               0
           Conv2d-70           [-1, 64, 14, 14]          24,576
      BatchNorm2d-71           [-1, 64, 14, 14]             128
 InvertedResidual-72           [-1, 64, 14, 14]               0
           Conv2d-73          [-1, 384, 14, 14]          24,576
      BatchNorm2d-74          [-1, 384, 14, 14]             768
            ReLU6-75          [-1, 384, 14, 14]               0
           Conv2d-76          [-1, 384, 14, 14]           3,456
      BatchNorm2d-77          [-1, 384, 14, 14]             768
            ReLU6-78          [-1, 384, 14, 14]               0
           Conv2d-79           [-1, 64, 14, 14]          24,576
      BatchNorm2d-80           [-1, 64, 14, 14]             128
 InvertedResidual-81           [-1, 64, 14, 14]               0
           Conv2d-82          [-1, 384, 14, 14]          24,576
      BatchNorm2d-83          [-1, 384, 14, 14]             768
            ReLU6-84          [-1, 384, 14, 14]               0
           Conv2d-85          [-1, 384, 14, 14]           3,456
      BatchNorm2d-86          [-1, 384, 14, 14]             768
            ReLU6-87          [-1, 384, 14, 14]               0
           Conv2d-88           [-1, 64, 14, 14]          24,576
      BatchNorm2d-89           [-1, 64, 14, 14]             128
 InvertedResidual-90           [-1, 64, 14, 14]               0
           Conv2d-91          [-1, 384, 14, 14]          24,576
      BatchNorm2d-92          [-1, 384, 14, 14]             768
            ReLU6-93          [-1, 384, 14, 14]               0
           Conv2d-94          [-1, 384, 14, 14]           3,456
      BatchNorm2d-95          [-1, 384, 14, 14]             768
            ReLU6-96          [-1, 384, 14, 14]               0
           Conv2d-97           [-1, 96, 14, 14]          36,864
      BatchNorm2d-98           [-1, 96, 14, 14]             192
 InvertedResidual-99           [-1, 96, 14, 14]               0
          Conv2d-100          [-1, 576, 14, 14]          55,296
     BatchNorm2d-101          [-1, 576, 14, 14]           1,152
           ReLU6-102          [-1, 576, 14, 14]               0
          Conv2d-103          [-1, 576, 14, 14]           5,184
     BatchNorm2d-104          [-1, 576, 14, 14]           1,152
           ReLU6-105          [-1, 576, 14, 14]               0
          Conv2d-106           [-1, 96, 14, 14]          55,296
     BatchNorm2d-107           [-1, 96, 14, 14]             192
InvertedResidual-108           [-1, 96, 14, 14]               0
          Conv2d-109          [-1, 576, 14, 14]          55,296
     BatchNorm2d-110          [-1, 576, 14, 14]           1,152
           ReLU6-111          [-1, 576, 14, 14]               0
          Conv2d-112          [-1, 576, 14, 14]           5,184
     BatchNorm2d-113          [-1, 576, 14, 14]           1,152
           ReLU6-114          [-1, 576, 14, 14]               0
          Conv2d-115           [-1, 96, 14, 14]          55,296
     BatchNorm2d-116           [-1, 96, 14, 14]             192
InvertedResidual-117           [-1, 96, 14, 14]               0
          Conv2d-118          [-1, 576, 14, 14]          55,296
     BatchNorm2d-119          [-1, 576, 14, 14]           1,152
           ReLU6-120          [-1, 576, 14, 14]               0
          Conv2d-121            [-1, 576, 7, 7]           5,184
     BatchNorm2d-122            [-1, 576, 7, 7]           1,152
           ReLU6-123            [-1, 576, 7, 7]               0
          Conv2d-124            [-1, 160, 7, 7]          92,160
     BatchNorm2d-125            [-1, 160, 7, 7]             320
InvertedResidual-126            [-1, 160, 7, 7]               0
          Conv2d-127            [-1, 960, 7, 7]         153,600
     BatchNorm2d-128            [-1, 960, 7, 7]           1,920
           ReLU6-129            [-1, 960, 7, 7]               0
          Conv2d-130            [-1, 960, 7, 7]           8,640
     BatchNorm2d-131            [-1, 960, 7, 7]           1,920
           ReLU6-132            [-1, 960, 7, 7]               0
          Conv2d-133            [-1, 160, 7, 7]         153,600
     BatchNorm2d-134            [-1, 160, 7, 7]             320
InvertedResidual-135            [-1, 160, 7, 7]               0
          Conv2d-136            [-1, 960, 7, 7]         153,600
     BatchNorm2d-137            [-1, 960, 7, 7]           1,920
           ReLU6-138            [-1, 960, 7, 7]               0
          Conv2d-139            [-1, 960, 7, 7]           8,640
     BatchNorm2d-140            [-1, 960, 7, 7]           1,920
           ReLU6-141            [-1, 960, 7, 7]               0
          Conv2d-142            [-1, 160, 7, 7]         153,600
     BatchNorm2d-143            [-1, 160, 7, 7]             320
InvertedResidual-144            [-1, 160, 7, 7]               0
          Conv2d-145            [-1, 960, 7, 7]         153,600
     BatchNorm2d-146            [-1, 960, 7, 7]           1,920
           ReLU6-147            [-1, 960, 7, 7]               0
          Conv2d-148            [-1, 960, 7, 7]           8,640
     BatchNorm2d-149            [-1, 960, 7, 7]           1,920
           ReLU6-150            [-1, 960, 7, 7]               0
          Conv2d-151            [-1, 320, 7, 7]         307,200
     BatchNorm2d-152            [-1, 320, 7, 7]             640
InvertedResidual-153            [-1, 320, 7, 7]               0
          Conv2d-154           [-1, 1280, 7, 7]         409,600
     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560
           ReLU6-156           [-1, 1280, 7, 7]               0
         Dropout-157                 [-1, 1280]               0
          Linear-158                   [-1, 10]          12,810
     MobileNetV2-159                   [-1, 10]               0
================================================================
Total params: 2,236,682
Trainable params: 12,810
Non-trainable params: 2,223,872
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 152.86
Params size (MB): 8.53
Estimated Total Size (MB): 161.97
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="5bcec864" class="cell code" id="5bcec864"
data-outputId="e4498dc7-8792-41ef-e79e-f10b88671bec">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_lion.train()</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.7357
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/c510c3e209fc6261ea774c3586c270dd4b44c017.png" /></p>
</div>
</div>
<div id="86a319ff" class="cell code" id="86a319ff"
data-outputId="ebaf9c35-7429-4e39-9543-42ccf1489e46">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_adamw.train()</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.6835
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/696881c65e43edd1682fa7d5f9f6c6a69658ed1a.png" /></p>
</div>
</div>
<div id="736b65b9" class="cell markdown" id="736b65b9">
<p>Получили результат хуже, чем для ResNet</p>
</div>
<div id="8afe5ef3" class="cell code" id="8afe5ef3">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MobileNet(nn.Module):</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MobileNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2 <span class="op">=</span> models.mobilenet_v2( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>].in_features,</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.mobilenet_v2(x)</span></code></pre></div>
</div>
<div id="dd90c437" class="cell code" id="dd90c437"
data-outputId="0f8c1c31-34df-479c-fb05-ad9e26649643">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> mobilenet_v2.to(device)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>summary(mobilenet_v2, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 112, 112]             864
       BatchNorm2d-2         [-1, 32, 112, 112]              64
             ReLU6-3         [-1, 32, 112, 112]               0
            Conv2d-4         [-1, 32, 112, 112]             288
       BatchNorm2d-5         [-1, 32, 112, 112]              64
             ReLU6-6         [-1, 32, 112, 112]               0
            Conv2d-7         [-1, 16, 112, 112]             512
       BatchNorm2d-8         [-1, 16, 112, 112]              32
  InvertedResidual-9         [-1, 16, 112, 112]               0
           Conv2d-10         [-1, 96, 112, 112]           1,536
      BatchNorm2d-11         [-1, 96, 112, 112]             192
            ReLU6-12         [-1, 96, 112, 112]               0
           Conv2d-13           [-1, 96, 56, 56]             864
      BatchNorm2d-14           [-1, 96, 56, 56]             192
            ReLU6-15           [-1, 96, 56, 56]               0
           Conv2d-16           [-1, 24, 56, 56]           2,304
      BatchNorm2d-17           [-1, 24, 56, 56]              48
 InvertedResidual-18           [-1, 24, 56, 56]               0
           Conv2d-19          [-1, 144, 56, 56]           3,456
      BatchNorm2d-20          [-1, 144, 56, 56]             288
            ReLU6-21          [-1, 144, 56, 56]               0
           Conv2d-22          [-1, 144, 56, 56]           1,296
      BatchNorm2d-23          [-1, 144, 56, 56]             288
            ReLU6-24          [-1, 144, 56, 56]               0
           Conv2d-25           [-1, 24, 56, 56]           3,456
      BatchNorm2d-26           [-1, 24, 56, 56]              48
 InvertedResidual-27           [-1, 24, 56, 56]               0
           Conv2d-28          [-1, 144, 56, 56]           3,456
      BatchNorm2d-29          [-1, 144, 56, 56]             288
            ReLU6-30          [-1, 144, 56, 56]               0
           Conv2d-31          [-1, 144, 28, 28]           1,296
      BatchNorm2d-32          [-1, 144, 28, 28]             288
            ReLU6-33          [-1, 144, 28, 28]               0
           Conv2d-34           [-1, 32, 28, 28]           4,608
      BatchNorm2d-35           [-1, 32, 28, 28]              64
 InvertedResidual-36           [-1, 32, 28, 28]               0
           Conv2d-37          [-1, 192, 28, 28]           6,144
      BatchNorm2d-38          [-1, 192, 28, 28]             384
            ReLU6-39          [-1, 192, 28, 28]               0
           Conv2d-40          [-1, 192, 28, 28]           1,728
      BatchNorm2d-41          [-1, 192, 28, 28]             384
            ReLU6-42          [-1, 192, 28, 28]               0
           Conv2d-43           [-1, 32, 28, 28]           6,144
      BatchNorm2d-44           [-1, 32, 28, 28]              64
 InvertedResidual-45           [-1, 32, 28, 28]               0
           Conv2d-46          [-1, 192, 28, 28]           6,144
      BatchNorm2d-47          [-1, 192, 28, 28]             384
            ReLU6-48          [-1, 192, 28, 28]               0
           Conv2d-49          [-1, 192, 28, 28]           1,728
      BatchNorm2d-50          [-1, 192, 28, 28]             384
            ReLU6-51          [-1, 192, 28, 28]               0
           Conv2d-52           [-1, 32, 28, 28]           6,144
      BatchNorm2d-53           [-1, 32, 28, 28]              64
 InvertedResidual-54           [-1, 32, 28, 28]               0
           Conv2d-55          [-1, 192, 28, 28]           6,144
      BatchNorm2d-56          [-1, 192, 28, 28]             384
            ReLU6-57          [-1, 192, 28, 28]               0
           Conv2d-58          [-1, 192, 14, 14]           1,728
      BatchNorm2d-59          [-1, 192, 14, 14]             384
            ReLU6-60          [-1, 192, 14, 14]               0
           Conv2d-61           [-1, 64, 14, 14]          12,288
      BatchNorm2d-62           [-1, 64, 14, 14]             128
 InvertedResidual-63           [-1, 64, 14, 14]               0
           Conv2d-64          [-1, 384, 14, 14]          24,576
      BatchNorm2d-65          [-1, 384, 14, 14]             768
            ReLU6-66          [-1, 384, 14, 14]               0
           Conv2d-67          [-1, 384, 14, 14]           3,456
      BatchNorm2d-68          [-1, 384, 14, 14]             768
            ReLU6-69          [-1, 384, 14, 14]               0
           Conv2d-70           [-1, 64, 14, 14]          24,576
      BatchNorm2d-71           [-1, 64, 14, 14]             128
 InvertedResidual-72           [-1, 64, 14, 14]               0
           Conv2d-73          [-1, 384, 14, 14]          24,576
      BatchNorm2d-74          [-1, 384, 14, 14]             768
            ReLU6-75          [-1, 384, 14, 14]               0
           Conv2d-76          [-1, 384, 14, 14]           3,456
      BatchNorm2d-77          [-1, 384, 14, 14]             768
            ReLU6-78          [-1, 384, 14, 14]               0
           Conv2d-79           [-1, 64, 14, 14]          24,576
      BatchNorm2d-80           [-1, 64, 14, 14]             128
 InvertedResidual-81           [-1, 64, 14, 14]               0
           Conv2d-82          [-1, 384, 14, 14]          24,576
      BatchNorm2d-83          [-1, 384, 14, 14]             768
            ReLU6-84          [-1, 384, 14, 14]               0
           Conv2d-85          [-1, 384, 14, 14]           3,456
      BatchNorm2d-86          [-1, 384, 14, 14]             768
            ReLU6-87          [-1, 384, 14, 14]               0
           Conv2d-88           [-1, 64, 14, 14]          24,576
      BatchNorm2d-89           [-1, 64, 14, 14]             128
 InvertedResidual-90           [-1, 64, 14, 14]               0
           Conv2d-91          [-1, 384, 14, 14]          24,576
      BatchNorm2d-92          [-1, 384, 14, 14]             768
            ReLU6-93          [-1, 384, 14, 14]               0
           Conv2d-94          [-1, 384, 14, 14]           3,456
      BatchNorm2d-95          [-1, 384, 14, 14]             768
            ReLU6-96          [-1, 384, 14, 14]               0
           Conv2d-97           [-1, 96, 14, 14]          36,864
      BatchNorm2d-98           [-1, 96, 14, 14]             192
 InvertedResidual-99           [-1, 96, 14, 14]               0
          Conv2d-100          [-1, 576, 14, 14]          55,296
     BatchNorm2d-101          [-1, 576, 14, 14]           1,152
           ReLU6-102          [-1, 576, 14, 14]               0
          Conv2d-103          [-1, 576, 14, 14]           5,184
     BatchNorm2d-104          [-1, 576, 14, 14]           1,152
           ReLU6-105          [-1, 576, 14, 14]               0
          Conv2d-106           [-1, 96, 14, 14]          55,296
     BatchNorm2d-107           [-1, 96, 14, 14]             192
InvertedResidual-108           [-1, 96, 14, 14]               0
          Conv2d-109          [-1, 576, 14, 14]          55,296
     BatchNorm2d-110          [-1, 576, 14, 14]           1,152
           ReLU6-111          [-1, 576, 14, 14]               0
          Conv2d-112          [-1, 576, 14, 14]           5,184
     BatchNorm2d-113          [-1, 576, 14, 14]           1,152
           ReLU6-114          [-1, 576, 14, 14]               0
          Conv2d-115           [-1, 96, 14, 14]          55,296
     BatchNorm2d-116           [-1, 96, 14, 14]             192
InvertedResidual-117           [-1, 96, 14, 14]               0
          Conv2d-118          [-1, 576, 14, 14]          55,296
     BatchNorm2d-119          [-1, 576, 14, 14]           1,152
           ReLU6-120          [-1, 576, 14, 14]               0
          Conv2d-121            [-1, 576, 7, 7]           5,184
     BatchNorm2d-122            [-1, 576, 7, 7]           1,152
           ReLU6-123            [-1, 576, 7, 7]               0
          Conv2d-124            [-1, 160, 7, 7]          92,160
     BatchNorm2d-125            [-1, 160, 7, 7]             320
InvertedResidual-126            [-1, 160, 7, 7]               0
          Conv2d-127            [-1, 960, 7, 7]         153,600
     BatchNorm2d-128            [-1, 960, 7, 7]           1,920
           ReLU6-129            [-1, 960, 7, 7]               0
          Conv2d-130            [-1, 960, 7, 7]           8,640
     BatchNorm2d-131            [-1, 960, 7, 7]           1,920
           ReLU6-132            [-1, 960, 7, 7]               0
          Conv2d-133            [-1, 160, 7, 7]         153,600
     BatchNorm2d-134            [-1, 160, 7, 7]             320
InvertedResidual-135            [-1, 160, 7, 7]               0
          Conv2d-136            [-1, 960, 7, 7]         153,600
     BatchNorm2d-137            [-1, 960, 7, 7]           1,920
           ReLU6-138            [-1, 960, 7, 7]               0
          Conv2d-139            [-1, 960, 7, 7]           8,640
     BatchNorm2d-140            [-1, 960, 7, 7]           1,920
           ReLU6-141            [-1, 960, 7, 7]               0
          Conv2d-142            [-1, 160, 7, 7]         153,600
     BatchNorm2d-143            [-1, 160, 7, 7]             320
InvertedResidual-144            [-1, 160, 7, 7]               0
          Conv2d-145            [-1, 960, 7, 7]         153,600
     BatchNorm2d-146            [-1, 960, 7, 7]           1,920
           ReLU6-147            [-1, 960, 7, 7]               0
          Conv2d-148            [-1, 960, 7, 7]           8,640
     BatchNorm2d-149            [-1, 960, 7, 7]           1,920
           ReLU6-150            [-1, 960, 7, 7]               0
          Conv2d-151            [-1, 320, 7, 7]         307,200
     BatchNorm2d-152            [-1, 320, 7, 7]             640
InvertedResidual-153            [-1, 320, 7, 7]               0
          Conv2d-154           [-1, 1280, 7, 7]         409,600
     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560
           ReLU6-156           [-1, 1280, 7, 7]               0
         Dropout-157                 [-1, 1280]               0
          Linear-158                   [-1, 10]          12,810
     MobileNetV2-159                   [-1, 10]               0
================================================================
Total params: 2,236,682
Trainable params: 2,236,682
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 152.86
Params size (MB): 8.53
Estimated Total Size (MB): 161.97
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="15e7612a" class="cell code" id="15e7612a"
data-outputId="d387d304-93ab-4441-bb76-257f0e04d99f">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_lion.train()</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9496
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/fa563d861575a2094cce2243039bd67be0b49184.png" /></p>
</div>
</div>
<div id="fe05d719" class="cell code" id="fe05d719"
data-outputId="a104209d-794d-474c-bf4b-4b40701ea4ce">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_adamw.train()</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9389
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/2279f68cf9980182766ffa00779be7c8da835c13.png" /></p>
</div>
</div>
<div id="cdc8e343" class="cell markdown" id="cdc8e343">
<p>Для finetuning мы получили сопоставимый результат с ResNet. Но
обратим внимание, что у ResNet34 было <strong>21 289 802</strong>
обучаемых параметров, в то время как у MobileNetV2 <strong>2 236
682</strong></p>
<p>Далее у нас на очереди модель 2020 года. В данном случае в связи с
тем, что полный finetuning модели занимает несколько часов, то мы обучим
с freeze всех слоев. Единственное изменим слой классификации в первый
раз на линейный слой, а второй раз на</p>
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>nn.Sequential(</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>].in_features, <span class="dv">1024</span>),</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">1024</span>),</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>            nn.PReLU(),</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">1024</span>, num_classes))</span></code></pre></div>
<p>И посмотрим на метрики</p>
</div>
<div id="03bfeeec" class="cell markdown" id="03bfeeec">
<h3 id="efficientnetv2">EfficientNetv2</h3>
</div>
<div id="830beb39" class="cell code" id="830beb39">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EfficientNet(nn.Module):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(EfficientNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m <span class="op">=</span> models.convnext_base(weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.efficientnet_v2_m.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>].in_features,</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.efficientnet_v2_m(x)</span></code></pre></div>
</div>
<div id="082a7dc2" class="cell code" id="082a7dc2"
data-outputId="ced2a68e-acf0-4c92-bca2-ec12473f742c">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m <span class="op">=</span> EfficientNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m <span class="op">=</span> efficientnet_v2_m.to(device)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>summary(efficientnet_v2_m, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 128, 56, 56]           6,272
       LayerNorm2d-2          [-1, 128, 56, 56]             256
            Conv2d-3          [-1, 128, 56, 56]           6,400
           Permute-4          [-1, 56, 56, 128]               0
         LayerNorm-5          [-1, 56, 56, 128]             256
            Linear-6          [-1, 56, 56, 512]          66,048
              GELU-7          [-1, 56, 56, 512]               0
            Linear-8          [-1, 56, 56, 128]          65,664
           Permute-9          [-1, 128, 56, 56]               0
  StochasticDepth-10          [-1, 128, 56, 56]               0
          CNBlock-11          [-1, 128, 56, 56]               0
           Conv2d-12          [-1, 128, 56, 56]           6,400
          Permute-13          [-1, 56, 56, 128]               0
        LayerNorm-14          [-1, 56, 56, 128]             256
           Linear-15          [-1, 56, 56, 512]          66,048
             GELU-16          [-1, 56, 56, 512]               0
           Linear-17          [-1, 56, 56, 128]          65,664
          Permute-18          [-1, 128, 56, 56]               0
  StochasticDepth-19          [-1, 128, 56, 56]               0
          CNBlock-20          [-1, 128, 56, 56]               0
           Conv2d-21          [-1, 128, 56, 56]           6,400
          Permute-22          [-1, 56, 56, 128]               0
        LayerNorm-23          [-1, 56, 56, 128]             256
           Linear-24          [-1, 56, 56, 512]          66,048
             GELU-25          [-1, 56, 56, 512]               0
           Linear-26          [-1, 56, 56, 128]          65,664
          Permute-27          [-1, 128, 56, 56]               0
  StochasticDepth-28          [-1, 128, 56, 56]               0
          CNBlock-29          [-1, 128, 56, 56]               0
      LayerNorm2d-30          [-1, 128, 56, 56]             256
           Conv2d-31          [-1, 256, 28, 28]         131,328
           Conv2d-32          [-1, 256, 28, 28]          12,800
          Permute-33          [-1, 28, 28, 256]               0
        LayerNorm-34          [-1, 28, 28, 256]             512
           Linear-35         [-1, 28, 28, 1024]         263,168
             GELU-36         [-1, 28, 28, 1024]               0
           Linear-37          [-1, 28, 28, 256]         262,400
          Permute-38          [-1, 256, 28, 28]               0
  StochasticDepth-39          [-1, 256, 28, 28]               0
          CNBlock-40          [-1, 256, 28, 28]               0
           Conv2d-41          [-1, 256, 28, 28]          12,800
          Permute-42          [-1, 28, 28, 256]               0
        LayerNorm-43          [-1, 28, 28, 256]             512
           Linear-44         [-1, 28, 28, 1024]         263,168
             GELU-45         [-1, 28, 28, 1024]               0
           Linear-46          [-1, 28, 28, 256]         262,400
          Permute-47          [-1, 256, 28, 28]               0
  StochasticDepth-48          [-1, 256, 28, 28]               0
          CNBlock-49          [-1, 256, 28, 28]               0
           Conv2d-50          [-1, 256, 28, 28]          12,800
          Permute-51          [-1, 28, 28, 256]               0
        LayerNorm-52          [-1, 28, 28, 256]             512
           Linear-53         [-1, 28, 28, 1024]         263,168
             GELU-54         [-1, 28, 28, 1024]               0
           Linear-55          [-1, 28, 28, 256]         262,400
          Permute-56          [-1, 256, 28, 28]               0
  StochasticDepth-57          [-1, 256, 28, 28]               0
          CNBlock-58          [-1, 256, 28, 28]               0
      LayerNorm2d-59          [-1, 256, 28, 28]             512
           Conv2d-60          [-1, 512, 14, 14]         524,800
           Conv2d-61          [-1, 512, 14, 14]          25,600
          Permute-62          [-1, 14, 14, 512]               0
        LayerNorm-63          [-1, 14, 14, 512]           1,024
           Linear-64         [-1, 14, 14, 2048]       1,050,624
             GELU-65         [-1, 14, 14, 2048]               0
           Linear-66          [-1, 14, 14, 512]       1,049,088
          Permute-67          [-1, 512, 14, 14]               0
  StochasticDepth-68          [-1, 512, 14, 14]               0
          CNBlock-69          [-1, 512, 14, 14]               0
           Conv2d-70          [-1, 512, 14, 14]          25,600
          Permute-71          [-1, 14, 14, 512]               0
        LayerNorm-72          [-1, 14, 14, 512]           1,024
           Linear-73         [-1, 14, 14, 2048]       1,050,624
             GELU-74         [-1, 14, 14, 2048]               0
           Linear-75          [-1, 14, 14, 512]       1,049,088
          Permute-76          [-1, 512, 14, 14]               0
  StochasticDepth-77          [-1, 512, 14, 14]               0
          CNBlock-78          [-1, 512, 14, 14]               0
           Conv2d-79          [-1, 512, 14, 14]          25,600
          Permute-80          [-1, 14, 14, 512]               0
        LayerNorm-81          [-1, 14, 14, 512]           1,024
           Linear-82         [-1, 14, 14, 2048]       1,050,624
             GELU-83         [-1, 14, 14, 2048]               0
           Linear-84          [-1, 14, 14, 512]       1,049,088
          Permute-85          [-1, 512, 14, 14]               0
  StochasticDepth-86          [-1, 512, 14, 14]               0
          CNBlock-87          [-1, 512, 14, 14]               0
           Conv2d-88          [-1, 512, 14, 14]          25,600
          Permute-89          [-1, 14, 14, 512]               0
        LayerNorm-90          [-1, 14, 14, 512]           1,024
           Linear-91         [-1, 14, 14, 2048]       1,050,624
             GELU-92         [-1, 14, 14, 2048]               0
           Linear-93          [-1, 14, 14, 512]       1,049,088
          Permute-94          [-1, 512, 14, 14]               0
  StochasticDepth-95          [-1, 512, 14, 14]               0
          CNBlock-96          [-1, 512, 14, 14]               0
           Conv2d-97          [-1, 512, 14, 14]          25,600
          Permute-98          [-1, 14, 14, 512]               0
        LayerNorm-99          [-1, 14, 14, 512]           1,024
          Linear-100         [-1, 14, 14, 2048]       1,050,624
            GELU-101         [-1, 14, 14, 2048]               0
          Linear-102          [-1, 14, 14, 512]       1,049,088
         Permute-103          [-1, 512, 14, 14]               0
 StochasticDepth-104          [-1, 512, 14, 14]               0
         CNBlock-105          [-1, 512, 14, 14]               0
          Conv2d-106          [-1, 512, 14, 14]          25,600
         Permute-107          [-1, 14, 14, 512]               0
       LayerNorm-108          [-1, 14, 14, 512]           1,024
          Linear-109         [-1, 14, 14, 2048]       1,050,624
            GELU-110         [-1, 14, 14, 2048]               0
          Linear-111          [-1, 14, 14, 512]       1,049,088
         Permute-112          [-1, 512, 14, 14]               0
 StochasticDepth-113          [-1, 512, 14, 14]               0
         CNBlock-114          [-1, 512, 14, 14]               0
          Conv2d-115          [-1, 512, 14, 14]          25,600
         Permute-116          [-1, 14, 14, 512]               0
       LayerNorm-117          [-1, 14, 14, 512]           1,024
          Linear-118         [-1, 14, 14, 2048]       1,050,624
            GELU-119         [-1, 14, 14, 2048]               0
          Linear-120          [-1, 14, 14, 512]       1,049,088
         Permute-121          [-1, 512, 14, 14]               0
 StochasticDepth-122          [-1, 512, 14, 14]               0
         CNBlock-123          [-1, 512, 14, 14]               0
          Conv2d-124          [-1, 512, 14, 14]          25,600
         Permute-125          [-1, 14, 14, 512]               0
       LayerNorm-126          [-1, 14, 14, 512]           1,024
          Linear-127         [-1, 14, 14, 2048]       1,050,624
            GELU-128         [-1, 14, 14, 2048]               0
          Linear-129          [-1, 14, 14, 512]       1,049,088
         Permute-130          [-1, 512, 14, 14]               0
 StochasticDepth-131          [-1, 512, 14, 14]               0
         CNBlock-132          [-1, 512, 14, 14]               0
          Conv2d-133          [-1, 512, 14, 14]          25,600
         Permute-134          [-1, 14, 14, 512]               0
       LayerNorm-135          [-1, 14, 14, 512]           1,024
          Linear-136         [-1, 14, 14, 2048]       1,050,624
            GELU-137         [-1, 14, 14, 2048]               0
          Linear-138          [-1, 14, 14, 512]       1,049,088
         Permute-139          [-1, 512, 14, 14]               0
 StochasticDepth-140          [-1, 512, 14, 14]               0
         CNBlock-141          [-1, 512, 14, 14]               0
          Conv2d-142          [-1, 512, 14, 14]          25,600
         Permute-143          [-1, 14, 14, 512]               0
       LayerNorm-144          [-1, 14, 14, 512]           1,024
          Linear-145         [-1, 14, 14, 2048]       1,050,624
            GELU-146         [-1, 14, 14, 2048]               0
          Linear-147          [-1, 14, 14, 512]       1,049,088
         Permute-148          [-1, 512, 14, 14]               0
 StochasticDepth-149          [-1, 512, 14, 14]               0
         CNBlock-150          [-1, 512, 14, 14]               0
          Conv2d-151          [-1, 512, 14, 14]          25,600
         Permute-152          [-1, 14, 14, 512]               0
       LayerNorm-153          [-1, 14, 14, 512]           1,024
          Linear-154         [-1, 14, 14, 2048]       1,050,624
            GELU-155         [-1, 14, 14, 2048]               0
          Linear-156          [-1, 14, 14, 512]       1,049,088
         Permute-157          [-1, 512, 14, 14]               0
 StochasticDepth-158          [-1, 512, 14, 14]               0
         CNBlock-159          [-1, 512, 14, 14]               0
          Conv2d-160          [-1, 512, 14, 14]          25,600
         Permute-161          [-1, 14, 14, 512]               0
       LayerNorm-162          [-1, 14, 14, 512]           1,024
          Linear-163         [-1, 14, 14, 2048]       1,050,624
            GELU-164         [-1, 14, 14, 2048]               0
          Linear-165          [-1, 14, 14, 512]       1,049,088
         Permute-166          [-1, 512, 14, 14]               0
 StochasticDepth-167          [-1, 512, 14, 14]               0
         CNBlock-168          [-1, 512, 14, 14]               0
          Conv2d-169          [-1, 512, 14, 14]          25,600
         Permute-170          [-1, 14, 14, 512]               0
       LayerNorm-171          [-1, 14, 14, 512]           1,024
          Linear-172         [-1, 14, 14, 2048]       1,050,624
            GELU-173         [-1, 14, 14, 2048]               0
          Linear-174          [-1, 14, 14, 512]       1,049,088
         Permute-175          [-1, 512, 14, 14]               0
 StochasticDepth-176          [-1, 512, 14, 14]               0
         CNBlock-177          [-1, 512, 14, 14]               0
          Conv2d-178          [-1, 512, 14, 14]          25,600
         Permute-179          [-1, 14, 14, 512]               0
       LayerNorm-180          [-1, 14, 14, 512]           1,024
          Linear-181         [-1, 14, 14, 2048]       1,050,624
            GELU-182         [-1, 14, 14, 2048]               0
          Linear-183          [-1, 14, 14, 512]       1,049,088
         Permute-184          [-1, 512, 14, 14]               0
 StochasticDepth-185          [-1, 512, 14, 14]               0
         CNBlock-186          [-1, 512, 14, 14]               0
          Conv2d-187          [-1, 512, 14, 14]          25,600
         Permute-188          [-1, 14, 14, 512]               0
       LayerNorm-189          [-1, 14, 14, 512]           1,024
          Linear-190         [-1, 14, 14, 2048]       1,050,624
            GELU-191         [-1, 14, 14, 2048]               0
          Linear-192          [-1, 14, 14, 512]       1,049,088
         Permute-193          [-1, 512, 14, 14]               0
 StochasticDepth-194          [-1, 512, 14, 14]               0
         CNBlock-195          [-1, 512, 14, 14]               0
          Conv2d-196          [-1, 512, 14, 14]          25,600
         Permute-197          [-1, 14, 14, 512]               0
       LayerNorm-198          [-1, 14, 14, 512]           1,024
          Linear-199         [-1, 14, 14, 2048]       1,050,624
            GELU-200         [-1, 14, 14, 2048]               0
          Linear-201          [-1, 14, 14, 512]       1,049,088
         Permute-202          [-1, 512, 14, 14]               0
 StochasticDepth-203          [-1, 512, 14, 14]               0
         CNBlock-204          [-1, 512, 14, 14]               0
          Conv2d-205          [-1, 512, 14, 14]          25,600
         Permute-206          [-1, 14, 14, 512]               0
       LayerNorm-207          [-1, 14, 14, 512]           1,024
          Linear-208         [-1, 14, 14, 2048]       1,050,624
            GELU-209         [-1, 14, 14, 2048]               0
          Linear-210          [-1, 14, 14, 512]       1,049,088
         Permute-211          [-1, 512, 14, 14]               0
 StochasticDepth-212          [-1, 512, 14, 14]               0
         CNBlock-213          [-1, 512, 14, 14]               0
          Conv2d-214          [-1, 512, 14, 14]          25,600
         Permute-215          [-1, 14, 14, 512]               0
       LayerNorm-216          [-1, 14, 14, 512]           1,024
          Linear-217         [-1, 14, 14, 2048]       1,050,624
            GELU-218         [-1, 14, 14, 2048]               0
          Linear-219          [-1, 14, 14, 512]       1,049,088
         Permute-220          [-1, 512, 14, 14]               0
 StochasticDepth-221          [-1, 512, 14, 14]               0
         CNBlock-222          [-1, 512, 14, 14]               0
          Conv2d-223          [-1, 512, 14, 14]          25,600
         Permute-224          [-1, 14, 14, 512]               0
       LayerNorm-225          [-1, 14, 14, 512]           1,024
          Linear-226         [-1, 14, 14, 2048]       1,050,624
            GELU-227         [-1, 14, 14, 2048]               0
          Linear-228          [-1, 14, 14, 512]       1,049,088
         Permute-229          [-1, 512, 14, 14]               0
 StochasticDepth-230          [-1, 512, 14, 14]               0
         CNBlock-231          [-1, 512, 14, 14]               0
          Conv2d-232          [-1, 512, 14, 14]          25,600
         Permute-233          [-1, 14, 14, 512]               0
       LayerNorm-234          [-1, 14, 14, 512]           1,024
          Linear-235         [-1, 14, 14, 2048]       1,050,624
            GELU-236         [-1, 14, 14, 2048]               0
          Linear-237          [-1, 14, 14, 512]       1,049,088
         Permute-238          [-1, 512, 14, 14]               0
 StochasticDepth-239          [-1, 512, 14, 14]               0
         CNBlock-240          [-1, 512, 14, 14]               0
          Conv2d-241          [-1, 512, 14, 14]          25,600
         Permute-242          [-1, 14, 14, 512]               0
       LayerNorm-243          [-1, 14, 14, 512]           1,024
          Linear-244         [-1, 14, 14, 2048]       1,050,624
            GELU-245         [-1, 14, 14, 2048]               0
          Linear-246          [-1, 14, 14, 512]       1,049,088
         Permute-247          [-1, 512, 14, 14]               0
 StochasticDepth-248          [-1, 512, 14, 14]               0
         CNBlock-249          [-1, 512, 14, 14]               0
          Conv2d-250          [-1, 512, 14, 14]          25,600
         Permute-251          [-1, 14, 14, 512]               0
       LayerNorm-252          [-1, 14, 14, 512]           1,024
          Linear-253         [-1, 14, 14, 2048]       1,050,624
            GELU-254         [-1, 14, 14, 2048]               0
          Linear-255          [-1, 14, 14, 512]       1,049,088
         Permute-256          [-1, 512, 14, 14]               0
 StochasticDepth-257          [-1, 512, 14, 14]               0
         CNBlock-258          [-1, 512, 14, 14]               0
          Conv2d-259          [-1, 512, 14, 14]          25,600
         Permute-260          [-1, 14, 14, 512]               0
       LayerNorm-261          [-1, 14, 14, 512]           1,024
          Linear-262         [-1, 14, 14, 2048]       1,050,624
            GELU-263         [-1, 14, 14, 2048]               0
          Linear-264          [-1, 14, 14, 512]       1,049,088
         Permute-265          [-1, 512, 14, 14]               0
 StochasticDepth-266          [-1, 512, 14, 14]               0
         CNBlock-267          [-1, 512, 14, 14]               0
          Conv2d-268          [-1, 512, 14, 14]          25,600
         Permute-269          [-1, 14, 14, 512]               0
       LayerNorm-270          [-1, 14, 14, 512]           1,024
          Linear-271         [-1, 14, 14, 2048]       1,050,624
            GELU-272         [-1, 14, 14, 2048]               0
          Linear-273          [-1, 14, 14, 512]       1,049,088
         Permute-274          [-1, 512, 14, 14]               0
 StochasticDepth-275          [-1, 512, 14, 14]               0
         CNBlock-276          [-1, 512, 14, 14]               0
          Conv2d-277          [-1, 512, 14, 14]          25,600
         Permute-278          [-1, 14, 14, 512]               0
       LayerNorm-279          [-1, 14, 14, 512]           1,024
          Linear-280         [-1, 14, 14, 2048]       1,050,624
            GELU-281         [-1, 14, 14, 2048]               0
          Linear-282          [-1, 14, 14, 512]       1,049,088
         Permute-283          [-1, 512, 14, 14]               0
 StochasticDepth-284          [-1, 512, 14, 14]               0
         CNBlock-285          [-1, 512, 14, 14]               0
          Conv2d-286          [-1, 512, 14, 14]          25,600
         Permute-287          [-1, 14, 14, 512]               0
       LayerNorm-288          [-1, 14, 14, 512]           1,024
          Linear-289         [-1, 14, 14, 2048]       1,050,624
            GELU-290         [-1, 14, 14, 2048]               0
          Linear-291          [-1, 14, 14, 512]       1,049,088
         Permute-292          [-1, 512, 14, 14]               0
 StochasticDepth-293          [-1, 512, 14, 14]               0
         CNBlock-294          [-1, 512, 14, 14]               0
          Conv2d-295          [-1, 512, 14, 14]          25,600
         Permute-296          [-1, 14, 14, 512]               0
       LayerNorm-297          [-1, 14, 14, 512]           1,024
          Linear-298         [-1, 14, 14, 2048]       1,050,624
            GELU-299         [-1, 14, 14, 2048]               0
          Linear-300          [-1, 14, 14, 512]       1,049,088
         Permute-301          [-1, 512, 14, 14]               0
 StochasticDepth-302          [-1, 512, 14, 14]               0
         CNBlock-303          [-1, 512, 14, 14]               0
     LayerNorm2d-304          [-1, 512, 14, 14]           1,024
          Conv2d-305           [-1, 1024, 7, 7]       2,098,176
          Conv2d-306           [-1, 1024, 7, 7]          51,200
         Permute-307           [-1, 7, 7, 1024]               0
       LayerNorm-308           [-1, 7, 7, 1024]           2,048
          Linear-309           [-1, 7, 7, 4096]       4,198,400
            GELU-310           [-1, 7, 7, 4096]               0
          Linear-311           [-1, 7, 7, 1024]       4,195,328
         Permute-312           [-1, 1024, 7, 7]               0
 StochasticDepth-313           [-1, 1024, 7, 7]               0
         CNBlock-314           [-1, 1024, 7, 7]               0
          Conv2d-315           [-1, 1024, 7, 7]          51,200
         Permute-316           [-1, 7, 7, 1024]               0
       LayerNorm-317           [-1, 7, 7, 1024]           2,048
          Linear-318           [-1, 7, 7, 4096]       4,198,400
            GELU-319           [-1, 7, 7, 4096]               0
          Linear-320           [-1, 7, 7, 1024]       4,195,328
         Permute-321           [-1, 1024, 7, 7]               0
 StochasticDepth-322           [-1, 1024, 7, 7]               0
         CNBlock-323           [-1, 1024, 7, 7]               0
          Conv2d-324           [-1, 1024, 7, 7]          51,200
         Permute-325           [-1, 7, 7, 1024]               0
       LayerNorm-326           [-1, 7, 7, 1024]           2,048
          Linear-327           [-1, 7, 7, 4096]       4,198,400
            GELU-328           [-1, 7, 7, 4096]               0
          Linear-329           [-1, 7, 7, 1024]       4,195,328
         Permute-330           [-1, 1024, 7, 7]               0
 StochasticDepth-331           [-1, 1024, 7, 7]               0
         CNBlock-332           [-1, 1024, 7, 7]               0
AdaptiveAvgPool2d-333           [-1, 1024, 1, 1]               0
     LayerNorm2d-334           [-1, 1024, 1, 1]           2,048
         Flatten-335                 [-1, 1024]               0
          Linear-336                   [-1, 10]          10,250
        ConvNeXt-337                   [-1, 10]               0
================================================================
Total params: 87,558,666
Trainable params: 10,250
Non-trainable params: 87,548,416
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 548.21
Params size (MB): 334.01
Estimated Total Size (MB): 882.80
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="57a2630d" class="cell code" id="57a2630d"
data-outputId="667f6394-6a2f-4e0c-c304-bf6d2d32a92d">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>efficientnet_v2_m,</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_lion.train()</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9484
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/b19c3a5e11f9a57931e82fd1179f73ba9da150f5.png" /></p>
</div>
</div>
<div id="b5a3b4a7" class="cell code" id="b5a3b4a7">
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EfficientNetV2(nn.Module):</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(EfficientNetV2, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m <span class="op">=</span> models.convnext_base(weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.efficientnet_v2_m.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>] <span class="op">=</span> nn.Sequential(</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>].in_features, <span class="dv">1024</span>),</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">1024</span>),</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>            nn.PReLU(),</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">1024</span>, num_classes))</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.efficientnet_v2_m(x)</span></code></pre></div>
</div>
<div id="f5f2f565" class="cell code" id="f5f2f565"
data-outputId="70fe27a3-76fb-4f37-b298-55a56d50fbfb">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m_v2 <span class="op">=</span> EfficientNetV2(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m_v2 <span class="op">=</span> efficientnet_v2_m_v2.to(device)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>summary(efficientnet_v2_m_v2, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 128, 56, 56]           6,272
       LayerNorm2d-2          [-1, 128, 56, 56]             256
            Conv2d-3          [-1, 128, 56, 56]           6,400
           Permute-4          [-1, 56, 56, 128]               0
         LayerNorm-5          [-1, 56, 56, 128]             256
            Linear-6          [-1, 56, 56, 512]          66,048
              GELU-7          [-1, 56, 56, 512]               0
            Linear-8          [-1, 56, 56, 128]          65,664
           Permute-9          [-1, 128, 56, 56]               0
  StochasticDepth-10          [-1, 128, 56, 56]               0
          CNBlock-11          [-1, 128, 56, 56]               0
           Conv2d-12          [-1, 128, 56, 56]           6,400
          Permute-13          [-1, 56, 56, 128]               0
        LayerNorm-14          [-1, 56, 56, 128]             256
           Linear-15          [-1, 56, 56, 512]          66,048
             GELU-16          [-1, 56, 56, 512]               0
           Linear-17          [-1, 56, 56, 128]          65,664
          Permute-18          [-1, 128, 56, 56]               0
  StochasticDepth-19          [-1, 128, 56, 56]               0
          CNBlock-20          [-1, 128, 56, 56]               0
           Conv2d-21          [-1, 128, 56, 56]           6,400
          Permute-22          [-1, 56, 56, 128]               0
        LayerNorm-23          [-1, 56, 56, 128]             256
           Linear-24          [-1, 56, 56, 512]          66,048
             GELU-25          [-1, 56, 56, 512]               0
           Linear-26          [-1, 56, 56, 128]          65,664
          Permute-27          [-1, 128, 56, 56]               0
  StochasticDepth-28          [-1, 128, 56, 56]               0
          CNBlock-29          [-1, 128, 56, 56]               0
      LayerNorm2d-30          [-1, 128, 56, 56]             256
           Conv2d-31          [-1, 256, 28, 28]         131,328
           Conv2d-32          [-1, 256, 28, 28]          12,800
          Permute-33          [-1, 28, 28, 256]               0
        LayerNorm-34          [-1, 28, 28, 256]             512
           Linear-35         [-1, 28, 28, 1024]         263,168
             GELU-36         [-1, 28, 28, 1024]               0
           Linear-37          [-1, 28, 28, 256]         262,400
          Permute-38          [-1, 256, 28, 28]               0
  StochasticDepth-39          [-1, 256, 28, 28]               0
          CNBlock-40          [-1, 256, 28, 28]               0
           Conv2d-41          [-1, 256, 28, 28]          12,800
          Permute-42          [-1, 28, 28, 256]               0
        LayerNorm-43          [-1, 28, 28, 256]             512
           Linear-44         [-1, 28, 28, 1024]         263,168
             GELU-45         [-1, 28, 28, 1024]               0
           Linear-46          [-1, 28, 28, 256]         262,400
          Permute-47          [-1, 256, 28, 28]               0
  StochasticDepth-48          [-1, 256, 28, 28]               0
          CNBlock-49          [-1, 256, 28, 28]               0
           Conv2d-50          [-1, 256, 28, 28]          12,800
          Permute-51          [-1, 28, 28, 256]               0
        LayerNorm-52          [-1, 28, 28, 256]             512
           Linear-53         [-1, 28, 28, 1024]         263,168
             GELU-54         [-1, 28, 28, 1024]               0
           Linear-55          [-1, 28, 28, 256]         262,400
          Permute-56          [-1, 256, 28, 28]               0
  StochasticDepth-57          [-1, 256, 28, 28]               0
          CNBlock-58          [-1, 256, 28, 28]               0
      LayerNorm2d-59          [-1, 256, 28, 28]             512
           Conv2d-60          [-1, 512, 14, 14]         524,800
           Conv2d-61          [-1, 512, 14, 14]          25,600
          Permute-62          [-1, 14, 14, 512]               0
        LayerNorm-63          [-1, 14, 14, 512]           1,024
           Linear-64         [-1, 14, 14, 2048]       1,050,624
             GELU-65         [-1, 14, 14, 2048]               0
           Linear-66          [-1, 14, 14, 512]       1,049,088
          Permute-67          [-1, 512, 14, 14]               0
  StochasticDepth-68          [-1, 512, 14, 14]               0
          CNBlock-69          [-1, 512, 14, 14]               0
           Conv2d-70          [-1, 512, 14, 14]          25,600
          Permute-71          [-1, 14, 14, 512]               0
        LayerNorm-72          [-1, 14, 14, 512]           1,024
           Linear-73         [-1, 14, 14, 2048]       1,050,624
             GELU-74         [-1, 14, 14, 2048]               0
           Linear-75          [-1, 14, 14, 512]       1,049,088
          Permute-76          [-1, 512, 14, 14]               0
  StochasticDepth-77          [-1, 512, 14, 14]               0
          CNBlock-78          [-1, 512, 14, 14]               0
           Conv2d-79          [-1, 512, 14, 14]          25,600
          Permute-80          [-1, 14, 14, 512]               0
        LayerNorm-81          [-1, 14, 14, 512]           1,024
           Linear-82         [-1, 14, 14, 2048]       1,050,624
             GELU-83         [-1, 14, 14, 2048]               0
           Linear-84          [-1, 14, 14, 512]       1,049,088
          Permute-85          [-1, 512, 14, 14]               0
  StochasticDepth-86          [-1, 512, 14, 14]               0
          CNBlock-87          [-1, 512, 14, 14]               0
           Conv2d-88          [-1, 512, 14, 14]          25,600
          Permute-89          [-1, 14, 14, 512]               0
        LayerNorm-90          [-1, 14, 14, 512]           1,024
           Linear-91         [-1, 14, 14, 2048]       1,050,624
             GELU-92         [-1, 14, 14, 2048]               0
           Linear-93          [-1, 14, 14, 512]       1,049,088
          Permute-94          [-1, 512, 14, 14]               0
  StochasticDepth-95          [-1, 512, 14, 14]               0
          CNBlock-96          [-1, 512, 14, 14]               0
           Conv2d-97          [-1, 512, 14, 14]          25,600
          Permute-98          [-1, 14, 14, 512]               0
        LayerNorm-99          [-1, 14, 14, 512]           1,024
          Linear-100         [-1, 14, 14, 2048]       1,050,624
            GELU-101         [-1, 14, 14, 2048]               0
          Linear-102          [-1, 14, 14, 512]       1,049,088
         Permute-103          [-1, 512, 14, 14]               0
 StochasticDepth-104          [-1, 512, 14, 14]               0
         CNBlock-105          [-1, 512, 14, 14]               0
          Conv2d-106          [-1, 512, 14, 14]          25,600
         Permute-107          [-1, 14, 14, 512]               0
       LayerNorm-108          [-1, 14, 14, 512]           1,024
          Linear-109         [-1, 14, 14, 2048]       1,050,624
            GELU-110         [-1, 14, 14, 2048]               0
          Linear-111          [-1, 14, 14, 512]       1,049,088
         Permute-112          [-1, 512, 14, 14]               0
 StochasticDepth-113          [-1, 512, 14, 14]               0
         CNBlock-114          [-1, 512, 14, 14]               0
          Conv2d-115          [-1, 512, 14, 14]          25,600
         Permute-116          [-1, 14, 14, 512]               0
       LayerNorm-117          [-1, 14, 14, 512]           1,024
          Linear-118         [-1, 14, 14, 2048]       1,050,624
            GELU-119         [-1, 14, 14, 2048]               0
          Linear-120          [-1, 14, 14, 512]       1,049,088
         Permute-121          [-1, 512, 14, 14]               0
 StochasticDepth-122          [-1, 512, 14, 14]               0
         CNBlock-123          [-1, 512, 14, 14]               0
          Conv2d-124          [-1, 512, 14, 14]          25,600
         Permute-125          [-1, 14, 14, 512]               0
       LayerNorm-126          [-1, 14, 14, 512]           1,024
          Linear-127         [-1, 14, 14, 2048]       1,050,624
            GELU-128         [-1, 14, 14, 2048]               0
          Linear-129          [-1, 14, 14, 512]       1,049,088
         Permute-130          [-1, 512, 14, 14]               0
 StochasticDepth-131          [-1, 512, 14, 14]               0
         CNBlock-132          [-1, 512, 14, 14]               0
          Conv2d-133          [-1, 512, 14, 14]          25,600
         Permute-134          [-1, 14, 14, 512]               0
       LayerNorm-135          [-1, 14, 14, 512]           1,024
          Linear-136         [-1, 14, 14, 2048]       1,050,624
            GELU-137         [-1, 14, 14, 2048]               0
          Linear-138          [-1, 14, 14, 512]       1,049,088
         Permute-139          [-1, 512, 14, 14]               0
 StochasticDepth-140          [-1, 512, 14, 14]               0
         CNBlock-141          [-1, 512, 14, 14]               0
          Conv2d-142          [-1, 512, 14, 14]          25,600
         Permute-143          [-1, 14, 14, 512]               0
       LayerNorm-144          [-1, 14, 14, 512]           1,024
          Linear-145         [-1, 14, 14, 2048]       1,050,624
            GELU-146         [-1, 14, 14, 2048]               0
          Linear-147          [-1, 14, 14, 512]       1,049,088
         Permute-148          [-1, 512, 14, 14]               0
 StochasticDepth-149          [-1, 512, 14, 14]               0
         CNBlock-150          [-1, 512, 14, 14]               0
          Conv2d-151          [-1, 512, 14, 14]          25,600
         Permute-152          [-1, 14, 14, 512]               0
       LayerNorm-153          [-1, 14, 14, 512]           1,024
          Linear-154         [-1, 14, 14, 2048]       1,050,624
            GELU-155         [-1, 14, 14, 2048]               0
          Linear-156          [-1, 14, 14, 512]       1,049,088
         Permute-157          [-1, 512, 14, 14]               0
 StochasticDepth-158          [-1, 512, 14, 14]               0
         CNBlock-159          [-1, 512, 14, 14]               0
          Conv2d-160          [-1, 512, 14, 14]          25,600
         Permute-161          [-1, 14, 14, 512]               0
       LayerNorm-162          [-1, 14, 14, 512]           1,024
          Linear-163         [-1, 14, 14, 2048]       1,050,624
            GELU-164         [-1, 14, 14, 2048]               0
          Linear-165          [-1, 14, 14, 512]       1,049,088
         Permute-166          [-1, 512, 14, 14]               0
 StochasticDepth-167          [-1, 512, 14, 14]               0
         CNBlock-168          [-1, 512, 14, 14]               0
          Conv2d-169          [-1, 512, 14, 14]          25,600
         Permute-170          [-1, 14, 14, 512]               0
       LayerNorm-171          [-1, 14, 14, 512]           1,024
          Linear-172         [-1, 14, 14, 2048]       1,050,624
            GELU-173         [-1, 14, 14, 2048]               0
          Linear-174          [-1, 14, 14, 512]       1,049,088
         Permute-175          [-1, 512, 14, 14]               0
 StochasticDepth-176          [-1, 512, 14, 14]               0
         CNBlock-177          [-1, 512, 14, 14]               0
          Conv2d-178          [-1, 512, 14, 14]          25,600
         Permute-179          [-1, 14, 14, 512]               0
       LayerNorm-180          [-1, 14, 14, 512]           1,024
          Linear-181         [-1, 14, 14, 2048]       1,050,624
            GELU-182         [-1, 14, 14, 2048]               0
          Linear-183          [-1, 14, 14, 512]       1,049,088
         Permute-184          [-1, 512, 14, 14]               0
 StochasticDepth-185          [-1, 512, 14, 14]               0
         CNBlock-186          [-1, 512, 14, 14]               0
          Conv2d-187          [-1, 512, 14, 14]          25,600
         Permute-188          [-1, 14, 14, 512]               0
       LayerNorm-189          [-1, 14, 14, 512]           1,024
          Linear-190         [-1, 14, 14, 2048]       1,050,624
            GELU-191         [-1, 14, 14, 2048]               0
          Linear-192          [-1, 14, 14, 512]       1,049,088
         Permute-193          [-1, 512, 14, 14]               0
 StochasticDepth-194          [-1, 512, 14, 14]               0
         CNBlock-195          [-1, 512, 14, 14]               0
          Conv2d-196          [-1, 512, 14, 14]          25,600
         Permute-197          [-1, 14, 14, 512]               0
       LayerNorm-198          [-1, 14, 14, 512]           1,024
          Linear-199         [-1, 14, 14, 2048]       1,050,624
            GELU-200         [-1, 14, 14, 2048]               0
          Linear-201          [-1, 14, 14, 512]       1,049,088
         Permute-202          [-1, 512, 14, 14]               0
 StochasticDepth-203          [-1, 512, 14, 14]               0
         CNBlock-204          [-1, 512, 14, 14]               0
          Conv2d-205          [-1, 512, 14, 14]          25,600
         Permute-206          [-1, 14, 14, 512]               0
       LayerNorm-207          [-1, 14, 14, 512]           1,024
          Linear-208         [-1, 14, 14, 2048]       1,050,624
            GELU-209         [-1, 14, 14, 2048]               0
          Linear-210          [-1, 14, 14, 512]       1,049,088
         Permute-211          [-1, 512, 14, 14]               0
 StochasticDepth-212          [-1, 512, 14, 14]               0
         CNBlock-213          [-1, 512, 14, 14]               0
          Conv2d-214          [-1, 512, 14, 14]          25,600
         Permute-215          [-1, 14, 14, 512]               0
       LayerNorm-216          [-1, 14, 14, 512]           1,024
          Linear-217         [-1, 14, 14, 2048]       1,050,624
            GELU-218         [-1, 14, 14, 2048]               0
          Linear-219          [-1, 14, 14, 512]       1,049,088
         Permute-220          [-1, 512, 14, 14]               0
 StochasticDepth-221          [-1, 512, 14, 14]               0
         CNBlock-222          [-1, 512, 14, 14]               0
          Conv2d-223          [-1, 512, 14, 14]          25,600
         Permute-224          [-1, 14, 14, 512]               0
       LayerNorm-225          [-1, 14, 14, 512]           1,024
          Linear-226         [-1, 14, 14, 2048]       1,050,624
            GELU-227         [-1, 14, 14, 2048]               0
          Linear-228          [-1, 14, 14, 512]       1,049,088
         Permute-229          [-1, 512, 14, 14]               0
 StochasticDepth-230          [-1, 512, 14, 14]               0
         CNBlock-231          [-1, 512, 14, 14]               0
          Conv2d-232          [-1, 512, 14, 14]          25,600
         Permute-233          [-1, 14, 14, 512]               0
       LayerNorm-234          [-1, 14, 14, 512]           1,024
          Linear-235         [-1, 14, 14, 2048]       1,050,624
            GELU-236         [-1, 14, 14, 2048]               0
          Linear-237          [-1, 14, 14, 512]       1,049,088
         Permute-238          [-1, 512, 14, 14]               0
 StochasticDepth-239          [-1, 512, 14, 14]               0
         CNBlock-240          [-1, 512, 14, 14]               0
          Conv2d-241          [-1, 512, 14, 14]          25,600
         Permute-242          [-1, 14, 14, 512]               0
       LayerNorm-243          [-1, 14, 14, 512]           1,024
          Linear-244         [-1, 14, 14, 2048]       1,050,624
            GELU-245         [-1, 14, 14, 2048]               0
          Linear-246          [-1, 14, 14, 512]       1,049,088
         Permute-247          [-1, 512, 14, 14]               0
 StochasticDepth-248          [-1, 512, 14, 14]               0
         CNBlock-249          [-1, 512, 14, 14]               0
          Conv2d-250          [-1, 512, 14, 14]          25,600
         Permute-251          [-1, 14, 14, 512]               0
       LayerNorm-252          [-1, 14, 14, 512]           1,024
          Linear-253         [-1, 14, 14, 2048]       1,050,624
            GELU-254         [-1, 14, 14, 2048]               0
          Linear-255          [-1, 14, 14, 512]       1,049,088
         Permute-256          [-1, 512, 14, 14]               0
 StochasticDepth-257          [-1, 512, 14, 14]               0
         CNBlock-258          [-1, 512, 14, 14]               0
          Conv2d-259          [-1, 512, 14, 14]          25,600
         Permute-260          [-1, 14, 14, 512]               0
       LayerNorm-261          [-1, 14, 14, 512]           1,024
          Linear-262         [-1, 14, 14, 2048]       1,050,624
            GELU-263         [-1, 14, 14, 2048]               0
          Linear-264          [-1, 14, 14, 512]       1,049,088
         Permute-265          [-1, 512, 14, 14]               0
 StochasticDepth-266          [-1, 512, 14, 14]               0
         CNBlock-267          [-1, 512, 14, 14]               0
          Conv2d-268          [-1, 512, 14, 14]          25,600
         Permute-269          [-1, 14, 14, 512]               0
       LayerNorm-270          [-1, 14, 14, 512]           1,024
          Linear-271         [-1, 14, 14, 2048]       1,050,624
            GELU-272         [-1, 14, 14, 2048]               0
          Linear-273          [-1, 14, 14, 512]       1,049,088
         Permute-274          [-1, 512, 14, 14]               0
 StochasticDepth-275          [-1, 512, 14, 14]               0
         CNBlock-276          [-1, 512, 14, 14]               0
          Conv2d-277          [-1, 512, 14, 14]          25,600
         Permute-278          [-1, 14, 14, 512]               0
       LayerNorm-279          [-1, 14, 14, 512]           1,024
          Linear-280         [-1, 14, 14, 2048]       1,050,624
            GELU-281         [-1, 14, 14, 2048]               0
          Linear-282          [-1, 14, 14, 512]       1,049,088
         Permute-283          [-1, 512, 14, 14]               0
 StochasticDepth-284          [-1, 512, 14, 14]               0
         CNBlock-285          [-1, 512, 14, 14]               0
          Conv2d-286          [-1, 512, 14, 14]          25,600
         Permute-287          [-1, 14, 14, 512]               0
       LayerNorm-288          [-1, 14, 14, 512]           1,024
          Linear-289         [-1, 14, 14, 2048]       1,050,624
            GELU-290         [-1, 14, 14, 2048]               0
          Linear-291          [-1, 14, 14, 512]       1,049,088
         Permute-292          [-1, 512, 14, 14]               0
 StochasticDepth-293          [-1, 512, 14, 14]               0
         CNBlock-294          [-1, 512, 14, 14]               0
          Conv2d-295          [-1, 512, 14, 14]          25,600
         Permute-296          [-1, 14, 14, 512]               0
       LayerNorm-297          [-1, 14, 14, 512]           1,024
          Linear-298         [-1, 14, 14, 2048]       1,050,624
            GELU-299         [-1, 14, 14, 2048]               0
          Linear-300          [-1, 14, 14, 512]       1,049,088
         Permute-301          [-1, 512, 14, 14]               0
 StochasticDepth-302          [-1, 512, 14, 14]               0
         CNBlock-303          [-1, 512, 14, 14]               0
     LayerNorm2d-304          [-1, 512, 14, 14]           1,024
          Conv2d-305           [-1, 1024, 7, 7]       2,098,176
          Conv2d-306           [-1, 1024, 7, 7]          51,200
         Permute-307           [-1, 7, 7, 1024]               0
       LayerNorm-308           [-1, 7, 7, 1024]           2,048
          Linear-309           [-1, 7, 7, 4096]       4,198,400
            GELU-310           [-1, 7, 7, 4096]               0
          Linear-311           [-1, 7, 7, 1024]       4,195,328
         Permute-312           [-1, 1024, 7, 7]               0
 StochasticDepth-313           [-1, 1024, 7, 7]               0
         CNBlock-314           [-1, 1024, 7, 7]               0
          Conv2d-315           [-1, 1024, 7, 7]          51,200
         Permute-316           [-1, 7, 7, 1024]               0
       LayerNorm-317           [-1, 7, 7, 1024]           2,048
          Linear-318           [-1, 7, 7, 4096]       4,198,400
            GELU-319           [-1, 7, 7, 4096]               0
          Linear-320           [-1, 7, 7, 1024]       4,195,328
         Permute-321           [-1, 1024, 7, 7]               0
 StochasticDepth-322           [-1, 1024, 7, 7]               0
         CNBlock-323           [-1, 1024, 7, 7]               0
          Conv2d-324           [-1, 1024, 7, 7]          51,200
         Permute-325           [-1, 7, 7, 1024]               0
       LayerNorm-326           [-1, 7, 7, 1024]           2,048
          Linear-327           [-1, 7, 7, 4096]       4,198,400
            GELU-328           [-1, 7, 7, 4096]               0
          Linear-329           [-1, 7, 7, 1024]       4,195,328
         Permute-330           [-1, 1024, 7, 7]               0
 StochasticDepth-331           [-1, 1024, 7, 7]               0
         CNBlock-332           [-1, 1024, 7, 7]               0
AdaptiveAvgPool2d-333           [-1, 1024, 1, 1]               0
     LayerNorm2d-334           [-1, 1024, 1, 1]           2,048
         Flatten-335                 [-1, 1024]               0
         Dropout-336                 [-1, 1024]               0
          Linear-337                 [-1, 1024]       1,049,600
     BatchNorm1d-338                 [-1, 1024]           2,048
           PReLU-339                 [-1, 1024]               1
         Dropout-340                 [-1, 1024]               0
          Linear-341                   [-1, 10]          10,250
        ConvNeXt-342                   [-1, 10]               0
================================================================
Total params: 88,610,315
Trainable params: 1,061,899
Non-trainable params: 87,548,416
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 548.25
Params size (MB): 338.02
Estimated Total Size (MB): 886.85
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div id="cfca25e3" class="cell code" id="cfca25e3"
data-outputId="c3f52e8b-fd67-4b5a-d868-89a4a80d521a">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_v2_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>efficientnet_v2_m_v2,</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_v2_lion.train()</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_v2_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9455
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/8db968a7243c38687a31b03890a714ad49f6347e.png" /></p>
</div>
</div>
<div id="69ecf96b" class="cell markdown" id="69ecf96b">
<p>Практически одинаковые результаты были получены, за исключением того
случая, где мы усложнили слой классификации. В этот раз модель уже с
первой эпохи показала результат в 0.94, в то время как первой модели
потребовалось около 3 эпох.</p>
<p>Дополнительно, эксперименты с аугментацией данных могут улучшить
результаты. Вероятно, модель является достаточно мощной для данного
датасета, что подтверждается низким значением функции потерь.</p>
</div>
<div id="64d5fbec" class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:807}"
id="64d5fbec" data-outputId="921c21c9-4954-4522-eafd-29a57d8302cd">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Alexnet Lion с freeze слоев&#39;</span>, <span class="st">&#39;Alexnet Adamw с freeze слоев&#39;</span>, <span class="st">&#39;Alexnet Lion finetuning&#39;</span>, <span class="st">&#39;Alexnet Adamw finetuning&#39;</span>,</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Resnet34 Lion с freeze слоев&#39;</span>, <span class="st">&#39;Resnet34 Adamw с freeze слоев&#39;</span>, <span class="st">&#39;Resnet34 Lion finetuning&#39;</span>, <span class="st">&#39;Resnet34 Adamw finetuning&#39;</span>,</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;MobileNet V2 Lion с freeze слоев&#39;</span>, <span class="st">&#39;MobileNet V2 Adamw с freeze слоев&#39;</span>, <span class="st">&#39;MobileNet V2 Lion finetuning&#39;</span>, <span class="st">&#39;MobileNet V2 Adamw finetuning&#39;</span>,</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;EfficientNetv2 Lion simpleclassifier слоев&#39;</span>, <span class="st">&#39;EfficientNetv2 Lion hardclassifierслоев&#39;</span></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>accuracies <span class="op">=</span> [</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.8014</span>, <span class="fl">0.7808</span>, <span class="fl">0.9187</span>, <span class="fl">0.9199</span>,</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.8284</span>, <span class="fl">0.815</span>, <span class="fl">0.9552</span>, <span class="fl">0.9637</span>,</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.7357</span>, <span class="fl">0.6835</span>, <span class="fl">0.9496</span>, <span class="fl">0.9389</span>,</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.9484</span>, <span class="fl">0.9455</span></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>sorted_indices <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">range</span>(<span class="bu">len</span>(accuracies)), key<span class="op">=</span><span class="kw">lambda</span> k: accuracies[k], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>models_sorted <span class="op">=</span> [models[i] <span class="cf">for</span> i <span class="kw">in</span> sorted_indices]</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>accuracies_sorted <span class="op">=</span> [accuracies[i] <span class="cf">for</span> i <span class="kw">in</span> sorted_indices]</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(models_sorted, accuracies_sorted, color<span class="op">=</span>[<span class="st">&#39;pink&#39;</span>, <span class="st">&#39;purple&#39;</span>])</span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, accuracy <span class="kw">in</span> <span class="bu">zip</span>(bars, accuracies_sorted):</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>    plt.text(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.01</span>, <span class="ss">f&#39;</span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>, ha<span class="op">=</span><span class="st">&#39;center&#39;</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Модели&#39;</span>)</span>
<span id="cb69-27"><a href="#cb69-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Точность&#39;</span>)</span>
<span id="cb69-28"><a href="#cb69-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Сравнение точности различных моделей (отсортировано)&#39;</span>)</span>
<span id="cb69-29"><a href="#cb69-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-30"><a href="#cb69-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-31"><a href="#cb69-31" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb69-32"><a href="#cb69-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_b67c4239736145229a94e8f76e8fc4ec/653d9953b03f50640cffd12180e2d182571e990f.png" /></p>
</div>
</div>
<div id="78892a20" class="cell markdown" id="78892a20">
<p>Исходя из графика, мы видим следующие результаты точности для
различных моделей:</p>
<ol>
<li><p><strong>Resnet34 Adamw finetuning</strong> демонстрирует самую
высокую точность (0.9637) среди всех моделей, когда используется Adamw
для fine-tuning.</p></li>
<li><p><strong>Resnet34 Lion finetuning</strong> и
<strong>EfficientNetv2 Lion simpleclassifier слоев</strong> также
показывают высокую точность (0.9552 и 0.9484 соответственно) после
fine-tuning.</p></li>
<li><p>Модели <strong>Alexnet Lion finetuning</strong> и <strong>Alexnet
Adamw finetuning</strong> имеют более низкую, но все равно впечатляющую
точность после fine-tuning (0.9056 и 0.9244 соответственно).</p></li>
<li><p>Среди моделей с замороженными слоями, <strong>Resnet34 Lion с
freeze слоев</strong> и <strong>Alexnet Lion с freeze слоев</strong>
демонстрируют более высокую точность (0.8284 и 0.8021 соответственно) по
сравнению с аналогичными моделями с использованием Adamw.</p></li>
<li><p>Также в данной работе опробовали новый оптимайзер Lion, который
порой показывал довольно высокую скорость, как обучения, так и
точности.</p></li>
</ol>
<p>В данной работе рассмотрели модели с 2012 по 2020 год, можно сказать,
что есть тенденция на уменьшения кол-во параметров для более высокой
скорости работы моделей. Мы заметили как ResNet34 и MobileNetV2 показали
почти одни и те же результаты, только разница в обучаемых параметрах
была в 10 раз.</p>
</div>
</body>
</html>
