{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from numpy import typing as npt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "def one_hot(Y: npt.NDArray[np.float32]) -> npt.NDArray[np.float32]:\n",
    "    one_hot_Y = np.zeros((Y.size, 10))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    return one_hot_Y\n",
    "\n",
    "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "x = (x/255).astype('float32')\n",
    "x = x.to_numpy()\n",
    "\n",
    "y = np.array(list(map(int, y)))\n",
    "y = one_hot(y)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item_num = 1090\n",
    "\n",
    "\n",
    "plt.imshow(x_train[item_num].reshape((28,28)), cmap='gray')\n",
    "plt.title(f\"{np.where(y_train[item_num] == 1)[0][0]}\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork():\n",
    "    def __init__(\n",
    "            self,\n",
    "            sizes: list[int],\n",
    "            epochs: int=10,\n",
    "            batch_size:int=64,\n",
    "            l_rate: float=0.01,\n",
    "        ):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.l_rate = l_rate\n",
    "\n",
    "        self.params = self.initialization()\n",
    "\n",
    "    def ReLU(\n",
    "            self,\n",
    "            x: npt.NDArray[np.float32], \n",
    "            derivative: bool=False\n",
    "    ) -> np.ndarray:\n",
    "        \n",
    "        if derivative:\n",
    "            return x > 0\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def softmax(\n",
    "            self,\n",
    "            x: npt.NDArray[np.float32],\n",
    "            axis: int=-1,\n",
    "    ) -> npt.NDArray[np.float32]:\n",
    "\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=axis, keepdims=True)\n",
    "        \n",
    "    def initialization(self) -> dict[str, npt.NDArray[np.float32]]:\n",
    "\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        output_layer=self.sizes[2]\n",
    "\n",
    "        params = {\n",
    "            'W1':np.random.randn(input_layer, hidden_1) * np.sqrt(1. / hidden_1),\n",
    "            'b1': np.random.randn(1, hidden_1) * np.sqrt(1. / hidden_1),\n",
    "\n",
    "            'W2':np.random.randn(hidden_1, output_layer) * np.sqrt(1. / output_layer),\n",
    "            'b2': np.random.randn(1, output_layer) * np.sqrt(1. / hidden_1),\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "    def forward_pass(\n",
    "            self,\n",
    "            x_train: npt.NDArray[np.float32],\n",
    "    ) -> npt.NDArray[np.float32]:\n",
    "\n",
    "        self.params['A0'] = x_train\n",
    "        \n",
    "        self.params['Z1'] = self.params['A0'] @ self.params[\"W1\"]  + self.params['b1']\n",
    "        self.params['A1'] = self.ReLU(self.params['Z1'])\n",
    "\n",
    "        self.params['Z2'] = self.params['A1'] @ self.params[\"W2\"]  + self.params['b2']\n",
    "        self.params['A2'] = self.softmax(self.params['Z2'])\n",
    "\n",
    "        return self.params['A2']\n",
    "\n",
    "    def backward_pass(\n",
    "            self,\n",
    "            y_train: npt.NDArray[np.float32],\n",
    "            output: npt.NDArray[np.float32],\n",
    "    ) -> dict[str, npt.NDArray[np.float32]]:\n",
    "\n",
    "        change_w = {}\n",
    "\n",
    "        dZ2 = (output - y_train) \n",
    "\n",
    "        change_w['W2'] = (self.params['A1'].T) @ dZ2  * 1 / y_train.shape[0]\n",
    "        change_w['b2'] =  np.sum(dZ2) * 1 / y_train.shape[0]\n",
    "\n",
    "        dZ1 = 1 / y_train.shape[0] * dZ2 @ self.params['W2'].T * self.ReLU(self.params['Z1'], derivative=True)\n",
    "        \n",
    "        change_w['W1'] = self.params['A0'].T @ (dZ1)\n",
    "        change_w['b1'] =  np.sum(dZ1)\n",
    "\n",
    "        return change_w\n",
    "\n",
    "    def update_params(self, change_w: dict[str, npt.NDArray[np.float32]]) -> None:\n",
    "\n",
    "        self.params[\"W1\"] -= self.l_rate * change_w['W1']\n",
    "        self.params[\"W2\"] -= self.l_rate * change_w['W2']\n",
    "        self.params[\"b1\"] -= self.l_rate * change_w['b1']\n",
    "        self.params[\"b2\"] -= self.l_rate * change_w['b2']\n",
    "\n",
    "    def get_accuracy(\n",
    "            self,\n",
    "            predictions: npt.NDArray[np.float32],\n",
    "            Y: npt.NDArray[np.float32]\n",
    "    ) -> float:\n",
    "\n",
    "        return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "    def train(\n",
    "            self,\n",
    "            x_train: npt.NDArray[np.float32],\n",
    "            y_train: npt.NDArray[np.float32],\n",
    "            x_val: npt.NDArray[np.float32],\n",
    "            y_val: npt.NDArray[np.float32],\n",
    "    ) -> None:\n",
    "\n",
    "        start_time = time.time()\n",
    "        num_batch_per_ephoc = x_train.shape[0] // self.batch_size\n",
    "\n",
    "        if num_batch_per_ephoc != x_train.shape[0] / self.batch_size:\n",
    "            num_batch_per_ephoc += 1\n",
    "            \n",
    "        for iteration in range(self.epochs):            \n",
    "            output_accum = []\n",
    "            for batch_number in range(num_batch_per_ephoc):\n",
    "\n",
    "                x_curr = x_train[self.batch_size * batch_number : self.batch_size * (batch_number+1)]\n",
    "                y_curr = y_train[self.batch_size * batch_number : self.batch_size * (batch_number+1)]\n",
    "\n",
    "                output = self.forward_pass(x_curr)\n",
    "                output_accum.extend(np.argmax(output, axis= 1))\n",
    "\n",
    "                changes = self.backward_pass(y_curr, output)\n",
    "\n",
    "                self.update_params(changes)\n",
    "            \n",
    "            accuracy = self.get_accuracy(np.array(output_accum), np.argmax(y_train, axis= 1))\n",
    "\n",
    "            print(f'Epoch: {iteration+1}, Time Spent: {time.time() - start_time:.2f}s, Train accuracy: {accuracy:.3f}')\n",
    "\n",
    "        preds_val = self.forward_pass(x_val)\n",
    "\n",
    "        print(f\"\\nTest accuracy: {self.get_accuracy(np.argmax(preds_val , axis= 1), np.argmax(y_val, axis= 1)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 2.30s, Train accuracy: 0.926\n",
      "Epoch: 2, Time Spent: 4.60s, Train accuracy: 0.967\n",
      "Epoch: 3, Time Spent: 6.80s, Train accuracy: 0.976\n",
      "Epoch: 4, Time Spent: 9.06s, Train accuracy: 0.982\n",
      "Epoch: 5, Time Spent: 11.32s, Train accuracy: 0.986\n",
      "Epoch: 6, Time Spent: 13.96s, Train accuracy: 0.989\n",
      "Epoch: 7, Time Spent: 16.34s, Train accuracy: 0.991\n",
      "Epoch: 8, Time Spent: 18.69s, Train accuracy: 0.993\n",
      "Epoch: 9, Time Spent: 20.99s, Train accuracy: 0.994\n",
      "Epoch: 10, Time Spent: 23.54s, Train accuracy: 0.995\n",
      "Epoch: 11, Time Spent: 25.97s, Train accuracy: 0.996\n",
      "Epoch: 12, Time Spent: 28.39s, Train accuracy: 0.997\n",
      "Epoch: 13, Time Spent: 30.69s, Train accuracy: 0.998\n",
      "Epoch: 14, Time Spent: 33.12s, Train accuracy: 0.998\n",
      "Epoch: 15, Time Spent: 35.45s, Train accuracy: 0.999\n",
      "Epoch: 16, Time Spent: 37.75s, Train accuracy: 0.999\n",
      "Epoch: 17, Time Spent: 40.21s, Train accuracy: 0.999\n",
      "Epoch: 18, Time Spent: 42.62s, Train accuracy: 0.999\n",
      "Epoch: 19, Time Spent: 44.98s, Train accuracy: 0.999\n",
      "Epoch: 20, Time Spent: 47.26s, Train accuracy: 0.999\n",
      "\n",
      "Test accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "dnn = DeepNeuralNetwork(sizes=[784, 300, 10], epochs=20, batch_size=64, l_rate=0.1)\n",
    "dnn.train(x_train, y_train, x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
