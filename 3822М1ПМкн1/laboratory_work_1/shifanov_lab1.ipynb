{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2854e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4624750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow-intel==2.15.0->tensorflow)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     -------------------------------------- 61.0/61.0 kB 540.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 15.8/15.8 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b299d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with batch size 64\n",
      "========================================\n",
      "Epoch 1/10, Loss: 0.9525, Accuracy: 0.7896\n",
      "Epoch 2/10, Loss: 0.4008, Accuracy: 0.8915\n",
      "Epoch 3/10, Loss: 0.3118, Accuracy: 0.9145\n",
      "Epoch 4/10, Loss: 0.2637, Accuracy: 0.9269\n",
      "Epoch 5/10, Loss: 0.2351, Accuracy: 0.9338\n",
      "Epoch 6/10, Loss: 0.2118, Accuracy: 0.9398\n",
      "Epoch 7/10, Loss: 0.1963, Accuracy: 0.9451\n",
      "Epoch 8/10, Loss: 0.1800, Accuracy: 0.9494\n",
      "Epoch 9/10, Loss: 0.1700, Accuracy: 0.9517\n",
      "Epoch 10/10, Loss: 0.1592, Accuracy: 0.9542\n"
     ]
    }
   ],
   "source": [
    "# Метод реализации активационной функции relu\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Метод реализации активационной функции softmax\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# Метод расчета кросс-энтропии\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    epsilon = 1e-15\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    cross_entropy = -np.sum(targets * np.log(predictions + 1e-9)) / N\n",
    "    return cross_entropy\n",
    "\n",
    "# Метод реализации One-Hot Encoding\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    num_samples = len(labels)\n",
    "    one_hot_targets = np.zeros((num_samples, num_classes))\n",
    "    one_hot_targets[np.arange(num_samples), labels] = 1\n",
    "    return one_hot_targets\n",
    "\n",
    "# Метод реализации обучения нейронной сети\n",
    "def train_neural_network(X, y, hidden_size, output_size, learning_rate, num_epochs, batch_size):\n",
    "    input_size = X.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # Инициализация весов\n",
    "    weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "    biases_hidden = np.zeros((1, hidden_size))\n",
    "    weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "    biases_output = np.zeros((1, output_size))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Перемешивание данных\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            # Получение пачки данных\n",
    "            batch_indices = indices[batch_start:batch_start + batch_size]\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "\n",
    "            # Прямой проход\n",
    "            hidden_layer_input = np.dot(X_batch, weights_input_hidden) + biases_hidden\n",
    "            hidden_layer_output = relu(hidden_layer_input)\n",
    "            output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
    "            output_layer_output = softmax(output_layer_input)\n",
    "\n",
    "            # Расчет ошибки\n",
    "            loss = cross_entropy_loss(output_layer_output, y_batch)\n",
    "            total_loss += loss\n",
    "\n",
    "            # Расчет accuracy\n",
    "            predictions = np.argmax(output_layer_output, axis=1)\n",
    "            true_labels = np.argmax(y_batch, axis=1)\n",
    "            correct_predictions += np.sum(predictions == true_labels)\n",
    "\n",
    "            # Обратный проход (обновление весов)\n",
    "            output_error = output_layer_output - y_batch\n",
    "            hidden_error = np.dot(output_error, weights_hidden_output.T) * (hidden_layer_output > 0)\n",
    "\n",
    "            weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
    "            biases_output -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "            weights_input_hidden -= learning_rate * np.dot(X_batch.T, hidden_error)\n",
    "            biases_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "        average_loss = total_loss / (num_samples / batch_size)\n",
    "        accuracy = correct_predictions / num_samples\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return weights_input_hidden, biases_hidden, weights_hidden_output, biases_output\n",
    "\n",
    "# Загрузка данных MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Преобразование изображений в одномерные векторы и нормализация значений\n",
    "X_train = X_train.reshape((X_train.shape[0], -1)) / 255.0\n",
    "X_test = X_test.reshape((X_test.shape[0], -1)) / 255.0\n",
    "\n",
    "# Преобразование меток классов в One-Hot Encoding формат\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Параметры нейронной сети\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "min_batch_size = 64\n",
    "max_batch_size = 64\n",
    "\n",
    "\n",
    "# Обучение сети с разными размерами пачек данных\n",
    "for batch_size in range(min_batch_size, max_batch_size + 1, 8):\n",
    "    print(f\"\\nTraining with batch size {batch_size}\\n{'=' * 40}\")\n",
    "    train_neural_network(X_train, y_train_one_hot, hidden_size, output_size, learning_rate, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8cf47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with batch size 8\n",
      "========================================\n",
      "Epoch 1/20, Loss: 1.6119, Accuracy: 0.4661\n",
      "Epoch 2/20, Loss: 1.3162, Accuracy: 0.5621\n",
      "Epoch 3/20, Loss: 1.2197, Accuracy: 0.5809\n",
      "Epoch 4/20, Loss: 1.3396, Accuracy: 0.5141\n",
      "Epoch 5/20, Loss: 1.2252, Accuracy: 0.5753\n",
      "Epoch 6/20, Loss: 1.1956, Accuracy: 0.5837\n",
      "Epoch 7/20, Loss: 1.2230, Accuracy: 0.5706\n",
      "Epoch 8/20, Loss: 1.2312, Accuracy: 0.5571\n",
      "Epoch 9/20, Loss: 1.2683, Accuracy: 0.5437\n",
      "Epoch 10/20, Loss: 1.2319, Accuracy: 0.5586\n",
      "Epoch 11/20, Loss: 1.2986, Accuracy: 0.5218\n",
      "Epoch 12/20, Loss: 1.2609, Accuracy: 0.5353\n",
      "Epoch 13/20, Loss: 1.2520, Accuracy: 0.5321\n",
      "Epoch 14/20, Loss: 1.2299, Accuracy: 0.5475\n",
      "Epoch 15/20, Loss: 1.2864, Accuracy: 0.5186\n",
      "Epoch 16/20, Loss: 1.2169, Accuracy: 0.5514\n",
      "Epoch 17/20, Loss: 1.3043, Accuracy: 0.5140\n",
      "Epoch 18/20, Loss: 1.2482, Accuracy: 0.5359\n",
      "Epoch 19/20, Loss: 1.3363, Accuracy: 0.4946\n",
      "Epoch 20/20, Loss: 1.2949, Accuracy: 0.5172\n",
      "\n",
      "Training with batch size 16\n",
      "========================================\n",
      "Epoch 1/20, Loss: 1.9941, Accuracy: 0.2769\n",
      "Epoch 2/20, Loss: 1.8528, Accuracy: 0.3045\n",
      "Epoch 3/20, Loss: 1.7491, Accuracy: 0.3487\n",
      "Epoch 4/20, Loss: 1.8089, Accuracy: 0.3123\n",
      "Epoch 5/20, Loss: 1.9000, Accuracy: 0.2690\n",
      "Epoch 6/20, Loss: 1.9024, Accuracy: 0.2662\n",
      "Epoch 7/20, Loss: 1.8278, Accuracy: 0.2984\n",
      "Epoch 8/20, Loss: 1.8430, Accuracy: 0.2831\n",
      "Epoch 9/20, Loss: 1.7791, Accuracy: 0.3139\n",
      "Epoch 10/20, Loss: 1.6938, Accuracy: 0.3535\n",
      "Epoch 11/20, Loss: 1.8820, Accuracy: 0.2678\n",
      "Epoch 12/20, Loss: 1.8501, Accuracy: 0.2828\n",
      "Epoch 13/20, Loss: 1.9654, Accuracy: 0.2302\n",
      "Epoch 14/20, Loss: 2.0024, Accuracy: 0.2173\n",
      "Epoch 15/20, Loss: 1.9824, Accuracy: 0.2278\n",
      "Epoch 16/20, Loss: 1.9560, Accuracy: 0.2364\n",
      "Epoch 17/20, Loss: 1.9455, Accuracy: 0.2367\n",
      "Epoch 18/20, Loss: 1.9475, Accuracy: 0.2371\n",
      "Epoch 19/20, Loss: 1.9447, Accuracy: 0.2348\n",
      "Epoch 20/20, Loss: 1.9415, Accuracy: 0.2368\n",
      "\n",
      "Training with batch size 24\n",
      "========================================\n",
      "Epoch 1/20, Loss: 2.0032, Accuracy: 0.2633\n",
      "Epoch 2/20, Loss: 1.8743, Accuracy: 0.2964\n",
      "Epoch 3/20, Loss: 1.8365, Accuracy: 0.3053\n",
      "Epoch 4/20, Loss: 1.8201, Accuracy: 0.3194\n",
      "Epoch 5/20, Loss: 1.7611, Accuracy: 0.3388\n",
      "Epoch 6/20, Loss: 1.7711, Accuracy: 0.3238\n",
      "Epoch 7/20, Loss: 1.8009, Accuracy: 0.3118\n",
      "Epoch 8/20, Loss: 1.6738, Accuracy: 0.3628\n",
      "Epoch 9/20, Loss: 1.6750, Accuracy: 0.3653\n",
      "Epoch 10/20, Loss: 1.7915, Accuracy: 0.3162\n",
      "Epoch 11/20, Loss: 1.8174, Accuracy: 0.3000\n",
      "Epoch 12/20, Loss: 1.7646, Accuracy: 0.3238\n",
      "Epoch 13/20, Loss: 1.8348, Accuracy: 0.2913\n",
      "Epoch 14/20, Loss: 1.9066, Accuracy: 0.2607\n",
      "Epoch 15/20, Loss: 1.8733, Accuracy: 0.2722\n",
      "Epoch 16/20, Loss: 1.8798, Accuracy: 0.2732\n",
      "Epoch 17/20, Loss: 1.8399, Accuracy: 0.2810\n",
      "Epoch 18/20, Loss: 1.9263, Accuracy: 0.2501\n",
      "Epoch 19/20, Loss: 1.8586, Accuracy: 0.2748\n",
      "Epoch 20/20, Loss: 1.8366, Accuracy: 0.2806\n",
      "\n",
      "Training with batch size 32\n",
      "========================================\n",
      "Epoch 1/20, Loss: 2.0637, Accuracy: 0.2498\n",
      "Epoch 2/20, Loss: 2.0192, Accuracy: 0.2240\n",
      "Epoch 3/20, Loss: 1.9637, Accuracy: 0.2506\n",
      "Epoch 4/20, Loss: 1.9169, Accuracy: 0.2567\n",
      "Epoch 5/20, Loss: 1.9878, Accuracy: 0.2288\n",
      "Epoch 6/20, Loss: 1.9960, Accuracy: 0.2372\n",
      "Epoch 7/20, Loss: 2.1422, Accuracy: 0.1787\n",
      "Epoch 8/20, Loss: 2.0800, Accuracy: 0.2053\n",
      "Epoch 9/20, Loss: 2.0488, Accuracy: 0.2174\n",
      "Epoch 10/20, Loss: 2.0548, Accuracy: 0.2085\n",
      "Epoch 11/20, Loss: 2.2585, Accuracy: 0.1320\n",
      "Epoch 12/20, Loss: 2.2886, Accuracy: 0.1185\n",
      "Epoch 13/20, Loss: 2.3059, Accuracy: 0.1115\n",
      "Epoch 14/20, Loss: 2.3063, Accuracy: 0.1142\n",
      "Epoch 15/20, Loss: 2.3138, Accuracy: 0.1093\n",
      "Epoch 16/20, Loss: 2.3168, Accuracy: 0.1048\n",
      "Epoch 17/20, Loss: 2.3162, Accuracy: 0.1062\n",
      "Epoch 18/20, Loss: 2.3200, Accuracy: 0.1078\n",
      "Epoch 19/20, Loss: 2.3198, Accuracy: 0.1063\n",
      "Epoch 20/20, Loss: 2.3166, Accuracy: 0.1056\n",
      "\n",
      "Training with batch size 40\n",
      "========================================\n",
      "Epoch 1/20, Loss: 2.1604, Accuracy: 0.2450\n",
      "Epoch 2/20, Loss: 1.9641, Accuracy: 0.2509\n",
      "Epoch 3/20, Loss: 1.9848, Accuracy: 0.2347\n",
      "Epoch 4/20, Loss: 2.0895, Accuracy: 0.1931\n",
      "Epoch 5/20, Loss: 2.0958, Accuracy: 0.1988\n",
      "Epoch 6/20, Loss: 2.0577, Accuracy: 0.2135\n",
      "Epoch 7/20, Loss: 2.0156, Accuracy: 0.2158\n",
      "Epoch 8/20, Loss: 2.0129, Accuracy: 0.2166\n",
      "Epoch 9/20, Loss: 2.0536, Accuracy: 0.2034\n",
      "Epoch 10/20, Loss: 2.0335, Accuracy: 0.2105\n",
      "Epoch 11/20, Loss: 2.1120, Accuracy: 0.1921\n",
      "Epoch 12/20, Loss: 2.1502, Accuracy: 0.1701\n",
      "Epoch 13/20, Loss: 2.1024, Accuracy: 0.1867\n",
      "Epoch 14/20, Loss: 2.1480, Accuracy: 0.1682\n",
      "Epoch 15/20, Loss: 2.2862, Accuracy: 0.1207\n",
      "Epoch 16/20, Loss: 2.2904, Accuracy: 0.1169\n",
      "Epoch 17/20, Loss: 2.2771, Accuracy: 0.1223\n",
      "Epoch 18/20, Loss: 2.2503, Accuracy: 0.1334\n",
      "Epoch 19/20, Loss: 2.2578, Accuracy: 0.1295\n",
      "Epoch 20/20, Loss: 2.2506, Accuracy: 0.1339\n",
      "\n",
      "Training with batch size 48\n",
      "========================================\n",
      "Epoch 1/20, Loss: 2.3274, Accuracy: 0.1517\n",
      "Epoch 2/20, Loss: 2.1779, Accuracy: 0.1667\n",
      "Epoch 3/20, Loss: 2.1842, Accuracy: 0.1610\n",
      "Epoch 4/20, Loss: 2.2943, Accuracy: 0.1183\n",
      "Epoch 5/20, Loss: 2.2589, Accuracy: 0.1365\n",
      "Epoch 6/20, Loss: 2.2769, Accuracy: 0.1267\n",
      "Epoch 7/20, Loss: 2.2828, Accuracy: 0.1221\n",
      "Epoch 8/20, Loss: 2.2573, Accuracy: 0.1313\n",
      "Epoch 9/20, Loss: 2.2574, Accuracy: 0.1324\n",
      "Epoch 10/20, Loss: 2.3093, Accuracy: 0.1091\n",
      "Epoch 11/20, Loss: 2.2732, Accuracy: 0.1267\n",
      "Epoch 12/20, Loss: 2.3051, Accuracy: 0.1134\n",
      "Epoch 13/20, Loss: 2.3090, Accuracy: 0.1109\n",
      "Epoch 14/20, Loss: 2.3045, Accuracy: 0.1139\n",
      "Epoch 15/20, Loss: 2.3255, Accuracy: 0.1046\n",
      "Epoch 16/20, Loss: 2.3271, Accuracy: 0.1031\n",
      "Epoch 17/20, Loss: 2.3162, Accuracy: 0.1107\n",
      "Epoch 18/20, Loss: 2.2861, Accuracy: 0.1232\n",
      "Epoch 19/20, Loss: 2.3004, Accuracy: 0.1142\n",
      "Epoch 20/20, Loss: 2.3101, Accuracy: 0.1099\n",
      "\n",
      "Training with batch size 56\n",
      "========================================\n",
      "Epoch 1/20, Loss: 2.3181, Accuracy: 0.1701\n",
      "Epoch 2/20, Loss: 2.2028, Accuracy: 0.1591\n",
      "Epoch 3/20, Loss: 2.0996, Accuracy: 0.1926\n",
      "Epoch 4/20, Loss: 2.2273, Accuracy: 0.1466\n",
      "Epoch 5/20, Loss: 2.2647, Accuracy: 0.1318\n",
      "Epoch 6/20, Loss: 2.2677, Accuracy: 0.1332\n",
      "Epoch 7/20, Loss: 2.3251, Accuracy: 0.1085\n",
      "Epoch 8/20, Loss: 2.3204, Accuracy: 0.1080\n",
      "Epoch 9/20, Loss: 2.3045, Accuracy: 0.1143\n",
      "Epoch 10/20, Loss: 2.2952, Accuracy: 0.1170\n",
      "Epoch 11/20, Loss: 2.3216, Accuracy: 0.1054\n",
      "Epoch 12/20, Loss: 2.3311, Accuracy: 0.1021\n",
      "Epoch 13/20, Loss: 2.3302, Accuracy: 0.1020\n",
      "Epoch 14/20, Loss: 2.3199, Accuracy: 0.1066\n",
      "Epoch 15/20, Loss: 2.2733, Accuracy: 0.1254\n",
      "Epoch 16/20, Loss: 2.2555, Accuracy: 0.1329\n",
      "Epoch 17/20, Loss: 2.2950, Accuracy: 0.1193\n",
      "Epoch 18/20, Loss: 2.3330, Accuracy: 0.1018\n",
      "Epoch 19/20, Loss: 2.3216, Accuracy: 0.1083\n",
      "Epoch 20/20, Loss: 2.3148, Accuracy: 0.1148\n",
      "\n",
      "Training with batch size 64\n",
      "========================================\n",
      "Epoch 1/20, Loss: 2.4655, Accuracy: 0.1041\n",
      "Epoch 2/20, Loss: 2.3328, Accuracy: 0.1047\n",
      "Epoch 3/20, Loss: 2.3352, Accuracy: 0.1007\n",
      "Epoch 4/20, Loss: 2.2938, Accuracy: 0.1246\n",
      "Epoch 5/20, Loss: 2.3219, Accuracy: 0.1100\n",
      "Epoch 6/20, Loss: 2.3358, Accuracy: 0.1029\n",
      "Epoch 7/20, Loss: 2.3331, Accuracy: 0.1041\n",
      "Epoch 8/20, Loss: 2.3369, Accuracy: 0.1006\n",
      "Epoch 9/20, Loss: 2.3354, Accuracy: 0.1040\n",
      "Epoch 10/20, Loss: 2.3355, Accuracy: 0.1008\n",
      "Epoch 11/20, Loss: 2.3357, Accuracy: 0.1013\n",
      "Epoch 12/20, Loss: 2.3366, Accuracy: 0.1047\n",
      "Epoch 13/20, Loss: 2.3350, Accuracy: 0.1024\n",
      "Epoch 14/20, Loss: 2.3355, Accuracy: 0.1042\n",
      "Epoch 15/20, Loss: 2.3372, Accuracy: 0.1011\n",
      "Epoch 16/20, Loss: 2.3360, Accuracy: 0.1009\n",
      "Epoch 17/20, Loss: 2.3371, Accuracy: 0.1011\n",
      "Epoch 18/20, Loss: 2.3366, Accuracy: 0.1008\n",
      "Epoch 19/20, Loss: 2.3376, Accuracy: 0.1011\n",
      "Epoch 20/20, Loss: 2.3351, Accuracy: 0.1026\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Метод реализации активационной функции relu\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Метод реализации активационной функции softmax\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# Метод расчета кросс-энтропии\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    epsilon = 1e-15\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    cross_entropy = -np.sum(targets * np.log(predictions + 1e-9)) / N\n",
    "    return cross_entropy\n",
    "\n",
    "# Метод реализации One-Hot Encoding\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    num_samples = len(labels)\n",
    "    one_hot_targets = np.zeros((num_samples, num_classes))\n",
    "    one_hot_targets[np.arange(num_samples), labels] = 1\n",
    "    return one_hot_targets\n",
    "\n",
    "# Метод реализации обучения нейронной сети\n",
    "def train_neural_network(X, y, hidden_size, output_size, learning_rate, num_epochs, batch_size):\n",
    "    input_size = X.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # Инициализация весов\n",
    "    weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "    biases_hidden = np.zeros((1, hidden_size))\n",
    "    weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "    biases_output = np.zeros((1, output_size))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Перемешивание данных\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            # Получение пачки данных\n",
    "            batch_indices = indices[batch_start:batch_start + batch_size]\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "\n",
    "            # Прямой проход\n",
    "            hidden_layer_input = np.dot(X_batch, weights_input_hidden) + biases_hidden\n",
    "            hidden_layer_output = relu(hidden_layer_input)\n",
    "            output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
    "            output_layer_output = softmax(output_layer_input)\n",
    "\n",
    "            # Расчет ошибки\n",
    "            loss = cross_entropy_loss(output_layer_output, y_batch)\n",
    "            total_loss += loss\n",
    "\n",
    "            # Расчет accuracy\n",
    "            predictions = np.argmax(output_layer_output, axis=1)\n",
    "            true_labels = np.argmax(y_batch, axis=1)\n",
    "            correct_predictions += np.sum(predictions == true_labels)\n",
    "\n",
    "            # Обратный проход (обновление весов)\n",
    "            output_error = output_layer_output - y_batch\n",
    "            hidden_error = np.dot(output_error, weights_hidden_output.T) * (hidden_layer_output > 0)\n",
    "\n",
    "            weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
    "            biases_output -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "            weights_input_hidden -= learning_rate * np.dot(X_batch.T, hidden_error)\n",
    "            biases_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "        average_loss = total_loss / (num_samples / batch_size)\n",
    "        accuracy = correct_predictions / num_samples\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return weights_input_hidden, biases_hidden, weights_hidden_output, biases_output\n",
    "\n",
    "# Загрузка данных MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Преобразование изображений в одномерные векторы и нормализация значений\n",
    "X_train = X_train.reshape((X_train.shape[0], -1)) / 255.0\n",
    "X_test = X_test.reshape((X_test.shape[0], -1)) / 255.0\n",
    "\n",
    "# Преобразование меток классов в One-Hot Encoding формат\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Параметры нейронной сети\n",
    "hidden_size = 300\n",
    "output_size = 10\n",
    "learning_rate = 0.1\n",
    "num_epochs = 20\n",
    "min_batch_size = 8\n",
    "max_batch_size = 64\n",
    "\n",
    "\n",
    "# Обучение сети с разными размерами пачек данных\n",
    "for batch_size in range(min_batch_size, max_batch_size + 1, 8):\n",
    "    print(f\"\\nTraining with batch size {batch_size}\\n{'=' * 40}\")\n",
    "    train_neural_network(X_train, y_train_one_hot, hidden_size, output_size, learning_rate, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57887b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
