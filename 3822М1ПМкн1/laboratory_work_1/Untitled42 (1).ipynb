{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2854e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b299d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with batch size 64\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.1697, Accuracy: 0.8206\n",
      "Epoch 2/10, Loss: 0.3778, Accuracy: 0.9018\n",
      "Epoch 3/10, Loss: 0.2814, Accuracy: 0.9217\n",
      "Epoch 4/10, Loss: 0.2298, Accuracy: 0.9350\n",
      "Epoch 5/10, Loss: 0.1946, Accuracy: 0.9441\n",
      "Epoch 6/10, Loss: 0.1756, Accuracy: 0.9485\n",
      "Epoch 7/10, Loss: 0.1552, Accuracy: 0.9543\n",
      "Epoch 8/10, Loss: 0.1413, Accuracy: 0.9579\n",
      "Epoch 9/10, Loss: 0.1306, Accuracy: 0.9603\n",
      "Epoch 10/10, Loss: 0.1186, Accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "# Метод реализации активационной функции relu\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Метод реализации активационной функции softmax\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# Метод расчета кросс-энтропии\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    epsilon = 1e-15\n",
    "    predictions = np.clip(predictions, epsilon, 1.0)  \n",
    "    N = predictions.shape[0]\n",
    "    cross_entropy = -np.sum(targets * np.log(predictions)) / N  \n",
    "    return cross_entropy\n",
    "\n",
    "# Метод реализации One-Hot Encoding\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    num_samples = len(labels)\n",
    "    one_hot_targets = np.zeros((num_samples, num_classes))\n",
    "    one_hot_targets[np.arange(num_samples), labels] = 1\n",
    "    return one_hot_targets\n",
    "\n",
    "# Метод реализации обучения нейронной сети\n",
    "def train_neural_network(X, y, hidden_size, output_size, learning_rate, num_epochs, batch_size):\n",
    "    input_size = X.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # Инициализация весов\n",
    "    weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "    biases_hidden = np.zeros((1, hidden_size))\n",
    "    weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "    biases_output = np.zeros((1, output_size))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Перемешивание данных\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            # Получение пачки данных\n",
    "            batch_indices = indices[batch_start:batch_start + batch_size]\n",
    "            X_batch = X[batch_indices]\n",
    "            y_batch = y[batch_indices]\n",
    "\n",
    "            # Прямой проход\n",
    "            hidden_layer_input = np.dot(X_batch, weights_input_hidden) + biases_hidden\n",
    "            hidden_layer_output = relu(hidden_layer_input)\n",
    "            output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
    "            output_layer_output = softmax(output_layer_input)\n",
    "\n",
    "            # Расчет ошибки\n",
    "            loss = cross_entropy_loss(output_layer_output, y_batch)\n",
    "            total_loss += loss\n",
    "\n",
    "            # Расчет accuracy\n",
    "            predictions = np.argmax(output_layer_output, axis=1)\n",
    "            true_labels = np.argmax(y_batch, axis=1)\n",
    "            correct_predictions += np.sum(predictions == true_labels)\n",
    "\n",
    "            # Обратный проход (обновление весов)\n",
    "            output_error = output_layer_output - y_batch\n",
    "            hidden_error = np.dot(output_error, weights_hidden_output.T) * (hidden_layer_output > 0)\n",
    "\n",
    "            weights_hidden_output -= learning_rate * np.dot(hidden_layer_output.T, output_error)\n",
    "            biases_output -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "            weights_input_hidden -= learning_rate * np.dot(X_batch.T, hidden_error)\n",
    "            biases_hidden -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "        average_loss = total_loss / (num_samples / batch_size)\n",
    "        accuracy = correct_predictions / num_samples\n",
    "\n",
    "        print(f\"Epoch {epoch+ 1}/{num_epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return weights_input_hidden, biases_hidden, weights_hidden_output, biases_output\n",
    "\n",
    "# Загрузка данных MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Преобразование изображений в одномерные векторы и нормализация значений\n",
    "X_train = X_train.reshape((X_train.shape[0], -1)) / 255.0\n",
    "X_test = X_test.reshape((X_test.shape[0], -1)) / 255.0\n",
    "\n",
    "# Преобразование меток классов в One-Hot Encoding формат\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Параметры нейронной сети\n",
    "hidden_size = 300\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "min_batch_size = 64\n",
    "max_batch_size = 64\n",
    "\n",
    "\n",
    "# Обучение сети с разными размерами пачек данных\n",
    "for batch_size in range(min_batch_size, max_batch_size + 1, 8):\n",
    "    print(f\"\\nTraining with batch size {batch_size}\\n{'=' * 40}\")\n",
    "    train_neural_network(X_train, y_train_one_hot, hidden_size, output_size, learning_rate, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57887b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with batch size 8\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.4488, Accuracy: 0.8840\n",
      "Epoch 2/10, Loss: 0.3669, Accuracy: 0.9274\n",
      "Epoch 3/10, Loss: 0.2401, Accuracy: 0.9448\n",
      "Epoch 4/10, Loss: 0.1752, Accuracy: 0.9561\n",
      "Epoch 5/10, Loss: 0.1349, Accuracy: 0.9641\n",
      "Epoch 6/10, Loss: 0.1062, Accuracy: 0.9705\n",
      "Epoch 7/10, Loss: 0.0878, Accuracy: 0.9749\n",
      "Epoch 8/10, Loss: 0.0729, Accuracy: 0.9780\n",
      "Epoch 9/10, Loss: 0.0596, Accuracy: 0.9820\n",
      "Epoch 10/10, Loss: 0.0506, Accuracy: 0.9844\n",
      "\n",
      "Training with batch size 16\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.3739, Accuracy: 0.8754\n",
      "Epoch 2/10, Loss: 0.3486, Accuracy: 0.9252\n",
      "Epoch 3/10, Loss: 0.2301, Accuracy: 0.9441\n",
      "Epoch 4/10, Loss: 0.1735, Accuracy: 0.9555\n",
      "Epoch 5/10, Loss: 0.1364, Accuracy: 0.9634\n",
      "Epoch 6/10, Loss: 0.1097, Accuracy: 0.9691\n",
      "Epoch 7/10, Loss: 0.0915, Accuracy: 0.9738\n",
      "Epoch 8/10, Loss: 0.0746, Accuracy: 0.9780\n",
      "Epoch 9/10, Loss: 0.0645, Accuracy: 0.9806\n",
      "Epoch 10/10, Loss: 0.0552, Accuracy: 0.9833\n",
      "\n",
      "Training with batch size 24\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.3171, Accuracy: 0.8705\n",
      "Epoch 2/10, Loss: 0.3442, Accuracy: 0.9251\n",
      "Epoch 3/10, Loss: 0.2325, Accuracy: 0.9424\n",
      "Epoch 4/10, Loss: 0.1771, Accuracy: 0.9533\n",
      "Epoch 5/10, Loss: 0.1420, Accuracy: 0.9600\n",
      "Epoch 6/10, Loss: 0.1181, Accuracy: 0.9654\n",
      "Epoch 7/10, Loss: 0.0976, Accuracy: 0.9705\n",
      "Epoch 8/10, Loss: 0.0852, Accuracy: 0.9744\n",
      "Epoch 9/10, Loss: 0.0724, Accuracy: 0.9780\n",
      "Epoch 10/10, Loss: 0.0648, Accuracy: 0.9798\n",
      "\n",
      "Training with batch size 32\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.2603, Accuracy: 0.8592\n",
      "Epoch 2/10, Loss: 0.3494, Accuracy: 0.9175\n",
      "Epoch 3/10, Loss: 0.2386, Accuracy: 0.9375\n",
      "Epoch 4/10, Loss: 0.1885, Accuracy: 0.9489\n",
      "Epoch 5/10, Loss: 0.1547, Accuracy: 0.9568\n",
      "Epoch 6/10, Loss: 0.1307, Accuracy: 0.9623\n",
      "Epoch 7/10, Loss: 0.1136, Accuracy: 0.9667\n",
      "Epoch 8/10, Loss: 0.0982, Accuracy: 0.9704\n",
      "Epoch 9/10, Loss: 0.0868, Accuracy: 0.9732\n",
      "Epoch 10/10, Loss: 0.0771, Accuracy: 0.9765\n",
      "\n",
      "Training with batch size 40\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.2427, Accuracy: 0.8517\n",
      "Epoch 2/10, Loss: 0.3481, Accuracy: 0.9174\n",
      "Epoch 3/10, Loss: 0.2432, Accuracy: 0.9364\n",
      "Epoch 4/10, Loss: 0.1938, Accuracy: 0.9468\n",
      "Epoch 5/10, Loss: 0.1575, Accuracy: 0.9553\n",
      "Epoch 6/10, Loss: 0.1339, Accuracy: 0.9608\n",
      "Epoch 7/10, Loss: 0.1139, Accuracy: 0.9658\n",
      "Epoch 8/10, Loss: 0.1010, Accuracy: 0.9688\n",
      "Epoch 9/10, Loss: 0.0887, Accuracy: 0.9714\n",
      "Epoch 10/10, Loss: 0.0783, Accuracy: 0.9755\n",
      "\n",
      "Training with batch size 48\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.1631, Accuracy: 0.8238\n",
      "Epoch 2/10, Loss: 0.3726, Accuracy: 0.9051\n",
      "Epoch 3/10, Loss: 0.2713, Accuracy: 0.9270\n",
      "Epoch 4/10, Loss: 0.2198, Accuracy: 0.9399\n",
      "Epoch 5/10, Loss: 0.1878, Accuracy: 0.9476\n",
      "Epoch 6/10, Loss: 0.1674, Accuracy: 0.9523\n",
      "Epoch 7/10, Loss: 0.1485, Accuracy: 0.9571\n",
      "Epoch 8/10, Loss: 0.1340, Accuracy: 0.9613\n",
      "Epoch 9/10, Loss: 0.1224, Accuracy: 0.9640\n",
      "Epoch 10/10, Loss: 0.1116, Accuracy: 0.9674\n",
      "\n",
      "Training with batch size 56\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.2195, Accuracy: 0.8412\n",
      "Epoch 2/10, Loss: 0.3737, Accuracy: 0.9114\n",
      "Epoch 3/10, Loss: 0.2662, Accuracy: 0.9316\n",
      "Epoch 4/10, Loss: 0.2101, Accuracy: 0.9417\n",
      "Epoch 5/10, Loss: 0.1748, Accuracy: 0.9511\n",
      "Epoch 6/10, Loss: 0.1489, Accuracy: 0.9572\n",
      "Epoch 7/10, Loss: 0.1287, Accuracy: 0.9625\n",
      "Epoch 8/10, Loss: 0.1129, Accuracy: 0.9666\n",
      "Epoch 9/10, Loss: 0.1009, Accuracy: 0.9698\n",
      "Epoch 10/10, Loss: 0.0923, Accuracy: 0.9726\n",
      "\n",
      "Training with batch size 64\n",
      "========================================\n",
      "Epoch 1/10, Loss: 1.1717, Accuracy: 0.8155\n",
      "Epoch 2/10, Loss: 0.3862, Accuracy: 0.9011\n",
      "Epoch 3/10, Loss: 0.2942, Accuracy: 0.9201\n",
      "Epoch 4/10, Loss: 0.2488, Accuracy: 0.9304\n",
      "Epoch 5/10, Loss: 0.2108, Accuracy: 0.9397\n",
      "Epoch 6/10, Loss: 0.1893, Accuracy: 0.9444\n",
      "Epoch 7/10, Loss: 0.1715, Accuracy: 0.9498\n",
      "Epoch 8/10, Loss: 0.1562, Accuracy: 0.9537\n",
      "Epoch 9/10, Loss: 0.1459, Accuracy: 0.9574\n",
      "Epoch 10/10, Loss: 0.1340, Accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "# Параметры нейронной сети\n",
    "hidden_size = 300\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "min_batch_size = 8\n",
    "max_batch_size = 64\n",
    "\n",
    "\n",
    "# Обучение сети с разными размерами пачек данных\n",
    "for batch_size in range(min_batch_size, max_batch_size + 1, 8):\n",
    "    print(f\"\\nTraining with batch size {batch_size}\\n{'=' * 40}\")\n",
    "    train_neural_network(X_train, y_train_one_hot, hidden_size, output_size, learning_rate, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9419b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
